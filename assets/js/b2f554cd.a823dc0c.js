"use strict";(self.webpackChunkcentrifugal_dev=self.webpackChunkcentrifugal_dev||[]).push([[1477],{10:function(e){e.exports=JSON.parse('{"blogPosts":[{"id":"/2022/07/19/centrifugo-v4-released","metadata":{"permalink":"/blog/2022/07/19/centrifugo-v4-released","editUrl":"https://github.com/centrifugal/centrifugal.dev/edit/main/blog/2022-07-19-centrifugo-v4-released.md","source":"@site/blog/2022-07-19-centrifugo-v4-released.md","title":"Centrifugo v4 released \u2013 a little revolution","description":"Centrifugo v4 released \u2013 providing optimized client protocol, modern WebSocket emulation layer, improved channel security, and redesigned client SDK behavior. It also comes with a couple of cutting-edge technologies to experiment with such as HTTP/3 and WebTransport.","date":"2022-07-19T00:00:00.000Z","formattedDate":"July 19, 2022","tags":[{"label":"centrifugo","permalink":"/blog/tags/centrifugo"},{"label":"release","permalink":"/blog/tags/release"}],"readingTime":21.16,"hasTruncateMarker":true,"authors":[{"name":"Centrifugal team","title":"Let the Centrifugal force be with you","imageURL":"/img/logo_animated.svg"}],"frontMatter":{"title":"Centrifugo v4 released \u2013 a little revolution","tags":["centrifugo","release"],"description":"Centrifugo v4 released \u2013 providing optimized client protocol, modern WebSocket emulation layer, improved channel security, and redesigned client SDK behavior. It also comes with a couple of cutting-edge technologies to experiment with such as HTTP/3 and WebTransport.","author":"Centrifugal team","authorTitle":"Let the Centrifugal force be with you","authorImageURL":"/img/logo_animated.svg","image":"/img/v4.jpg","hide_table_of_contents":false},"nextItem":{"title":"Building a multi-room chat application with Laravel and Centrifugo","permalink":"/blog/2021/12/14/laravel-multi-room-chat-tutorial"}},"content":"![Centrifuge](/img/v4.jpg)\\n\\nToday we are excited to announce the next generation of Centrifugo \u2013 Centrifugo v4. The release takes Centrifugo to the next level in terms of client protocol performance, WebSocket fallback simplicity, SDK ecosystem and channel security model. It also comes with a couple of cutting-edge technologies to experiment with such as HTTP/3 and WebTransport.\\n\\n\x3c!--truncate--\x3e\\n\\n:::info About Centrifugo\\n\\nIf you\'ve never heard of Centrifugo before, it\'s an open-source scalable real-time messaging server written in Go language. Centrifugo can instantly deliver messages to application online users connected over supported transports (WebSocket, HTTP-streaming, SSE/EventSource, GRPC, SockJS). Centrifugo has the concept of a channel \u2013 so it\'s a user-facing PUB/SUB server.\\n\\nCentrifugo is language-agnostic and can be used to build chat apps, live comments, multiplayer games, real-time data visualizations, collaborative tools, etc. in combination with any backend. It is well suited for modern architectures and allows decoupling the business logic from the real-time transport layer.\\n\\nSeveral official client SDKs for browser and mobile development wrap the bidirectional protocol. In addition, Centrifugo supports a unidirectional approach for simple use cases with no SDK dependency.\\n\\n:::\\n\\n## Centrifugo v3 flashbacks\\n\\nLet\'s start from looking back a bit. Centrifugo v3 was released last year. It had a great list of improvements \u2013 like unidirectional transports support (EventSource, HTTP-streaming and GRPC), GRPC transport for proxy, history iteration API, faster JSON protocol, super-fast but experimental Tarantool engine implementation, and others.\\n\\nDuring the Centrifugo v3 lifecycle we added even more JSON protocol optimizations and introduced a granular proxy mode. Experimental Tarantool engine has also evolved a bit.\\n\\nBut Centrifugo v3 did not contain anything... let\'s say **revolutional**. Revolutional for Centrifugo itself, community, or even the entire field of open-source real-time messaging.\\n\\nWith this release, we feel that we bring innovation to the ecosystem. Now let\'s talk about it and introduce all the major things of the brand new v4 release.\\n\\n<video width=\\"100%\\" loop=\\"true\\" autoplay=\\"autoplay\\" muted controls=\\"\\" src=\\"/img/v4_logo.mp4\\"></video>\\n\\n## Unified client SDK API\\n\\nThe most challenging part of Centrifugo project is not a server itself. Client SDKs are the hardest part of the ecosystem. We try to time additional improvements to the SDKs with each major release of the server. But this time the SDKs are the centerpiece of the v4 release.\\n\\nCentrifugo uses bidirectional asynchronous protocol between client and server. On top of this protocol SDK provides a request-response over an asynchronous connection, reconnection logic, subscription management and multiplexing, timeout and error handling, ping-pong, token refresh, etc. Some of these things are not that trivial to implement. And all this should be implemented in different programming languages. As you may know, we have official real-time SDKs in Javascript, Dart, Swift, Java and Go.\\n\\nWhile implementing the same protocol and same functions, all SDKs behaved slightly differently. That was the result of the missing SDK specification. Without a strict SDK spec, it was hard to document things, hard to explain the exact details of the real-time SDK behavior. What we did earlier in the Centrifugo documentation \u2013 was pointing users to specific SDK Github repo to look for behaviour details.\\n\\nThe coolest thing about Centrifugo v4 is the next generation SDK API. We now have a [client SDK API specification](/docs/transports/client_api). It\'s a source of truth for SDKs behavior which try to follow the spec closely.\\n\\nThe new SDK API is the result of several iterations and reflections on possible states, transitions, token refresh mechanism, etc. Users in our Telegram group may remember how it all started:\\n\\n![Centrifugo scheme](/img/states_prototype.jpg)\\n\\nAnd after several iterations these prototypes turned into working mechanisms with well-defined behaviour:\\n\\n![Centrifugo scheme](/img/client_state.png)\\n\\nA few things that have been revised from the ground up:\\n\\n* Client states, transitions, events\\n* Subscription states, transitions, events\\n* Connection and subscription token refresh behavior\\n* Ping-pong behavior (see details below)\\n* Resubscribe logic (SDKs can now resubscribe with backoff)\\n* Error handling\\n* Unified backoff behavior (based on [full jitter technique](https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/)) \\n\\nWe now also have a separation between temporary and non-temporary protocol errors \u2013 this allows us to handle subscription internal server errors on the SDK level, making subscriptions more resilient, with automatic resubscriptions, and to ensure individual subscription failures do not affect the entire connection.\\n\\nThe mechanics described in the client SDK API specification are now implemented in all of our official SDKs. The SDKs now support all major client protocol features that currently exist. We believe this is a big step forward for the Centrifugo ecosystem and community.\\n\\n## Modern WebSocket emulation in Javascript\\n\\nWebSocket is supported almost everywhere these days. But there is a case that we believe is the last one preventing users to connect over WebSocket - corporate proxies. With the root certificate installed on employee computer machines, these proxies can block WebSocket traffic, even if it\'s wrapped in a TLS layer. That\'s really annoying, and often developers choose to not support clients connecting from such \\"broken\\" environments at all.\\n\\nPrior to v4, Centrifugo users could use the SockJS polyfill library to fill this gap.\\n\\nSockJS is great software \u2013 stable and field proven. It is still used by some huge real-time messaging players out there to polyfill the WebSocket transport.\\n\\nBut SockJS is an extra frontend dependency with a bunch of legacy transports, and [the future of it is unknown](https://github.com/sockjs/sockjs-client/issues/592).\\n\\nSockJS comes with a notable overhead \u2013 it\'s an aditional protocol wrapper, consumes more memory per connection on a server (at least when using SockJS-Go library \u2013 the only choice for implementing SockJS server in Go language these days). When using SockJS, Centrifugo users were losing the ability to use our main pure WebSocket transport because SockJS uses its own WebSocket implementation on a server side.\\n\\nSockJS does not support binary data transfer \u2013 only JSON format can be used with it. As you know, our main WebSocket transport works fine with binary in case of using Protobuf protocol format. So with SockJS we don\'t have fallback for WebSocket with a binary data transfer.\\n\\nAnd finally, if you want to use SockJS with a distributed backend, you must enable sticky session support on the load-balancer level. This way you can point requests from the client to the server to the correct server node \u2013 the one which maintains a persistent unidirectional HTTP connection.\\n\\nWe danced around the idea of replacing SockJS for a long time. But only now we are ready to provide our alternative to it \u2013 meet Centrifugo own **bidirectional emulation layer**. It\'s based on two additional transports:\\n\\n* HTTP-streaming (using modern browser [ReadableStream API](https://developer.mozilla.org/en-US/docs/Web/API/ReadableStream) in JavaScript, supports both binary Protobuf and JSON transfer)\\n* Eventsource (Server-Sent Events, SSE) \u2013 while a bit older choice and works with JSON only EventSource transport is loved by many developers, so we implemented bidirectional emulation with it too.\\n\\nSo when the fallback is used, you always have a real-time, persistent connection in server -> to -> client direction. Requests in client -> to -> server direction are regular HTTP \u2013 similar to how SockJS works. But our bidirectional emulation layer does not require sticky sessions \u2013 Centrifugo can proxy client-to-server requests to the correct node in the cluster. **Having sticky sessions is an optimization** for Centrifugo bidirectional emulation layer, **not a requirement**. We believe that this is a game changer for our users \u2013 no need to bother about proper load balancing, especially since in most cases 95% or even more users will be able to connect using the WebSocket transport.\\n\\nHere is a simplified diagram of how it works:\\n\\n![Scheme](/img/emulation_scheme.png)\\n\\nThe bidirectional emulation layer is only supported by the Javascript SDK (`centrifuge-js`) \u2013 as we think fallbacks mostly make sense for browsers. If we find use cases where other SDKs can benefit from HTTP based transport \u2013 we can expand on them later.\\n\\nLet\'s look at example of using this feature from the Javascript side. To use fallbacks, all you need to do is to set up a list of desired transports with endpoints:\\n\\n```javascript\\nconst transports = [\\n    {\\n        transport: \'websocket\',\\n        endpoint: \'wss://your_centrifugo.com/connection/websocket\'\\n    },\\n    {\\n        transport: \'http_stream\',\\n        endpoint: \'https://your_centrifugo.com/connection/http_stream\'\\n    },\\n    {\\n        transport: \'sse\',\\n        endpoint: \'https://your_centrifugo.com/connection/sse\'\\n    }\\n];\\nconst centrifuge = new Centrifuge(transports);\\ncentrifuge.connect()\\n```\\n\\n:::note\\n\\nWe are using explicit transport endpoints in the above example due to the fact that transport endpoints can be configured separately in Centrifugo \u2013 there is no single entry point for all transports. Like the one in Socket.IO or SockJS when developer can only point client to the base address. In Centrifugo case, we are requesting an explicit transport/endpoint configuration from the SDK user.\\n\\n:::\\n\\nBy the way, a few advantages of HTTP-based transport over WebSocket:\\n\\n* Sessions can be automatically multiplexed within a single connection by the browser when the server is running over HTTP/2, while with WebSocket browsers open a separate connection in each browser tab\\n* Better compression support (may be enabled on load balancer level)\\n* WebSocket requires special configuration in some load balancers to get started (ex. Nginx)\\n\\nSockJS is still supported by Centrifugo and `centrifuge-js`, but it\'s now DEPRECATED.\\n\\n## No layering in client protocol\\n\\nNot only the API of client SDK has changed, but also the format of Centrifugo protocol messages. New format is more human-readable (in JSON case, of course), has a more compact ping message size (more on that below).\\n\\nThe client protocol is now one-shot encode/decode compatible. Previously, Centrifugo protocol had a layered structure and we had to encode some messages before appending them to the top-level message. Or decode two or three times to unwrap the message envelope. To achieve good performance when encoding and decoding client protocol messages, Centrifugo had to use various optimization techniques \u2013 like buffer memory pools, byte slice memory pools.\\n\\nBy restructuring the message format, we were able to avoid layering, which allowed us to slightly increase the performance of encoding/decoding without additional optimization tricks.\\n\\n![Scheme](/img/avoid_protocol_nesting.png)\\n\\nWe also simplified the [client protocol](/docs/transports/client_protocol) documentation overview a bit.\\n\\n## Redesigned PING-PONG\\n\\nIn many cases in practice (when dealing with persistent connections like WebSocket), pings and pongs are the most dominant types of messages passed between client and server. Your application may have many concurrent connections, but only a few of them receive the useful payload. But at the same time, we still need to send pings and respond with pongs. Thus, optimizing the ping-pong process can significantly reduce server resource usage.\\n\\nOne optimization comes from the revised PING-PONG behaviour. Previous versions of Centrifugo and SDKs sent ping/pong in both \\"client->to->server\\" and \\"server->to->client\\" directions (for WebSocket transport). This allowed finding non-active connections on both client and server sides.\\n\\nIn Centrifugo v4 we only send pings from a server to a client and expect pong from a client. On the client-side, we have a timer which fires if there hasn\'t been a ping from the server within the configured time, so we still have a way to detect closed connections.\\n\\nSending pings only in one direction results in 2 times less ping-pong messages - and this should be really noticable for Centrifugo installations with thousands of concurrent connections. In our experiments with 10k connections, server CPU usage was reduced by 30% compared to Centrifugo v3.\\n\\n![Scheme](/img/ping_pong_v3_v4.png)\\n\\nPings and pongs are application-level messages. Ping is just an empty asynchronous reply \u2013 for example in JSON case it\'s a 2-byte message: `{}`. Pong is an empty command \u2013 also, `{}` in JSON case. Having application-level pings from the server also allows unifying the PING format for all unidirectional transports.\\n\\nAnother improvement is that Centrifugo now randomizes the time it sends first ping to the client (but no longer than the configured ping interval). This allows to spread ping-pongs in time, providing a smoother CPU profile, especially after a massive reconnect scenario.\\n\\n## Secure by default channel namespaces\\n\\nData security and privacy are more important than ever in today\'s world. And as Centrifugo becomes more popular and widely used, the need to be `secure by default` only increases. \\n\\nPreviously, by default, clients could subcribe to all channels in a namespace (except private channels, which are now revised \u2013 see details below). It was possible to use `\\"protected\\": true` option to make namespace protected, but we are not sure if everyone did that. This is extra configuration and additional knowledge on how Centrifugo works.\\n\\nAlso, a common confusion we ran into: if server-side subscriptions were dictated by a connection JWT, many users would expect client-side subscriptions to those channels to not work. But without the `protected` option enabled, this was not the case.\\n\\nIn Centrifugo v4, by default, it is not possible to subscribe to a channel in a namespace. The namespace must be configured to allow subscriptions from clients, or token authorization must be used. There are a bunch of new namespace options to tune the namespace behavior. Also the ability to provide a regular expression for channels in the namespace.\\n\\nThe new permission-related channel option names better reflect the purpose of the option. For example, compare `\\"publish\\": true` and `\\"allow_publish_for_client\\": true`. The second one is more readable and provides a better understanding of the effect once turned on.\\n\\nCentrifugo is now more strict when checking channel name. Only ASCII symbols allowed \u2013 it was already mentioned in docs before, but wasn\'t actually enforced. Now we are fixing this.\\n\\nWe understand that these changes will make running Centrifugo more of a challenge, especially when all you want is a public access to all the channels without worrying too much about permissions. It\'s still possible to achieve, but now the intent must be expicitly expressed in the config.\\n\\nCheck out the updated documentation about [channels and namespaces](/docs/server/channels). Our v4 migration guide contains an **automatic converter** for channel namespace options.\\n\\n## Private channel concept revised\\n\\nA private channel is a special channel starting with `$` that could not be subscribed to without a subscription JWT. Prior to v4, having a known prefix allowed us to distinguish between public channels and private channels. But since namespaces are now non-public by default, this distinction is not really important.\\n\\nThis means 2 things:\\n\\n* it\'s now possible to subscribe to any channel by having a valid subscription JWT (not just those that start with `$`)\\n* channels beginning with `$` can only be subscribed with a subscription JWT, even if they belong to a namespace where subscriptions allowed for all clients. This is for security compatibility between v3 and v4.\\n\\nAnother notable change in a subscription JWT \u2013 `client` claim is now DEPRECATED. There is no need to put it in the subscription token anymore. Centrifugo supports it only for backwards compatibility, but it will be completely removed in the future releases.\\n\\nThe reason we\'re removing `client` claim is actually interesting. Due to the fact that `client` claim was a required part of the subscription JWT applications could run into a situation where during the [massive reconnect scenario](/blog/2020/11/12/scaling-websocket#massive-reconnect) (say, million connections reconnect) many requests for new subscription tokens can be generated because the subscription token must contain the client ID generated by Centrifugo for the new connection. That could make it unusually hard for the application backend to handle the load. With a connection JWT we had no such problem \u2013 as connections could simply reuse the previous token to reconnect to Centrifugo.\\n\\nNow the subscription token behaves just like the connection token, so we get a scalable solution for token-based subscriptions as well.\\n\\nWhat\'s more, this change paved the way for another big improvement...\\n\\n## Optimistic subscriptions\\n\\nThe improvement we just mentioned is called optimistic subscriptions. If any of you are familiar with the [QUIC](https://en.wikipedia.org/wiki/QUIC) protocol, then optimistic subscriptions are somewhat similar to the 0-RTT feature in QUIC. The idea is simple \u2013 we can include subscription commands to the first frame sent to the server.\\n\\nPreviously, we sent subscriptions only after receiving a successful Connect Reply to a Connect Command from a server. But with the new changes in token behaviour, it seems so logical to put subscribe commands within the initial connect frame. Especially since Centrifugo protocol always supported batching of commands. Even token-based subscriptions can now be included into the initial frame during reconnect process, since the previous token can be reused now.\\n\\n![](/img/optimistic_subs.png)\\n\\nThe benefit is awesome \u2013 in most scenarios, we save one RTT of latency when connecting to Centrifugo and subscribing to channels (which is actually the most common way to use Centrifugo). While not visible on localhost, this is pretty important in real-life. And this is less syscalls for the server after all, resulting in less CPU usage.\\n\\nOptimistic subscriptions are also great for bidirectional emulation with HTTP, as they avoid the long path of proxying a request to the correct Centrifugo node when connecting.\\n\\nOptimistic subscriptions are now only part of `centrifuge-js`. At some point, we plan to roll out this important optimization to all other client SDKs.\\n\\n## Channel capabilities\\n\\nThe channel capabilities feature is introduced as part of [Centrifugo PRO](/docs/pro/overview). Initially, we aimed to make it a part of the OSS version. But the lack of feedback on this feature made us nervous it\'s really needed. So adding it to PRO, where we still have room to evaluate the idea, seemed like the safer decision at the moment.\\n\\nCentrifugo allows configuring channel permissions on a per-namespace level. When creating a new real-time feature, it is recommended to create a new namespace for it and configure permissions. But to achieve a better channel permission control within a namespace the Channel capabilities can be used now.\\n\\nThe channel capability feature provides a possibility to set capabilities on an individual connection basis, or an individual channel subscription basis.\\n\\nFor example, in a connection JWT developers can set sth like:\\n\\n```json\\n{\\n    \\"caps\\": [\\n        {\\n            \\"channels\\": [\\"news\\", \\"user_42\\"],\\n            \\"allow\\": [\\"sub\\"]\\n        }\\n    ]\\n}\\n```\\n\\nAnd this tells Centrifugo that the connection is able to subscribe on channels `news` or `user_42` using client-side subscriptionsat any time while the connection is active. Centrifugo also supports wildcard and regex channel matches.\\n\\nSubscription JWT can provide capabilities for the channel too, so permissions may be controlled on an individual subscription basis, ex. the ability to publish and call history API may be expressed with `allow` claim in subscription JWT:\\n\\n```json\\n{\\n    \\"allow\\": [\\"pub\\", \\"hst\\"]\\n}\\n```\\n\\nRead more about this mechanism in [Channel capabilities](/docs/pro/capabilities) chapter.\\n\\n## Better connections API\\n\\nAnother addition to Centrifugo PRO is the improved [connection API](/docs/pro/connections). Previously, we could only return all connections from a specific user. \\n\\nThe API now supports filtering all connections: by user ID, by subscribed channel, by additional meta information attached to the connection.\\n\\nThe filtering works by user ID or with a help of [CEL expressions](https://opensource.google/projects/cel) (Common Expression Language). CEL expressions provide a developer-friendly, fast and secure (as they are not Turing-complete) way to evaluate some conditions. They are used in some Google services (ex. Firebase), in Envoy RBAC configuration, etc. If you\'ve never seen it before \u2013 take a look, cool project. We are also evaluating how to use CEL expressions for a dynamic and efficient channel permission checks, but that\'s an early story.\\n\\nThe `connections` API call result contains more useful information: a list of client\'s active channels, information about the tokens used to connect and subscribe, meta information attached to the connection.\\n\\n## Optimized Redis engine\\n\\nOne more story which landed to the PRO version for now is the optimized Redis Engine. The optimized version allocates less memory (thus you can expect a reduced CPU usage for the Centrifugo node) and supports [sharded PUB/SUB](https://redis.io/docs/manual/pubsub/#sharded-pubsub) in Redis Cluster (introduced recently as part of Redis v7). You can read what we have in [Optimized Redis engine](/docs/pro/redis_engine) docs.\\n\\n## Javascript client moved to TypeScript\\n\\nIt\'s no secret that `centrifuge-js` is the most popular SDK in the Centrifugo ecosystem. We put additional love to it \u2013 and `centrifuge-js` is now fully written in Typescript \u2764\ufe0f\\n\\nThis was a long awaited improvement, and it finally happened! The entire public API is strictly typed. The cool thing is that even `EventEmitter` events and event handlers are the subject to type checks - this should drastically simplify and speedup development and also help to reduce error possibility.\\n\\n## Experimenting with HTTP/3\\n\\nCentrifugo v4 has an **experimental** [HTTP/3](https://en.wikipedia.org/wiki/HTTP/3) support. Once TLS is enabled and `\\"http3\\": true` option is set all the endpoints on an external port will be served by a HTTP/3 server based on [lucas-clemente/quic-go](https://github.com/lucas-clemente/quic-go) implementation.\\n\\nIt\'s worth noting that WebSocket will still use HTTP/1.1 for its Upgrade request (there is an interesting IETF draft BTW about [Bootstrapping WebSockets with HTTP/3](https://www.ietf.org/archive/id/draft-ietf-httpbis-h3-websockets-02.html)). But HTTP-streaming and EventSource should work just fine with HTTP/3.\\n\\nHTTP/3 does not currently work with our ACME autocert TLS - i.e. you need to explicitly provide paths to cert and key files [as described here](/docs/server/tls#using-crt-and-key-files).\\n\\n## Experimenting with WebTransport\\n\\nHaving HTTP/3 on board allowed us to make one more thing. Some of you may remember the post [Experimenting with QUIC and WebTransport](/blog/2020/10/16/experimenting-with-quic-transport) published in our blog before. We danced around the idea to add [WebTransport](https://web.dev/webtransport/) to Centrifugo since then. [WebTransport IETF specification](https://datatracker.ietf.org/doc/draft-ietf-webtrans-http3/) is still a draft, it changed a lot since our first blog post about it. But WebTransport object is already part of Chrome (since v97) and things seem to be very close to the release.\\n\\nSo we added experimental WebTransport support to Centrifugo v4. This is made possible with the help of the [marten-seemann/webtransport-go](https://github.com/marten-seemann/webtransport-go) library.\\n\\nTo use WebTransport you need to run HTTP/3 experimental server and enable WebTransport endpoint with `\\"webtransport\\": true` option in the configuration. Then you can connect to that endpoint using `centrifuge-js`. For example, let\'s enable WebTransport and use WebSocket as a fallback option:\\n\\n```javascript\\nconst transports = [\\n    {\\n        transport: \'webtransport\',\\n        endpoint: \'https://your_centrifugo.com/connection/webtransport\'\\n    },\\n    {\\n        transport: \'websocket\',\\n        endpoint: \'wss://your_centrifugo.com/connection/websocket\'\\n    }\\n];\\nconst centrifuge = new Centrifuge(transports);\\ncentrifuge.connect()\\n```\\n\\nNote, that we are using secure schemes here \u2013 `https://` and `wss://`. While in WebSocket case you could opt for non-TLS communication, in HTTP/3 and specifically WebTransport non-TLS communication is simply not supported by the specification.\\n\\nIn Centrifugo case, we utilize the bidirectional reliable stream of WebTransport to pass our protocol between client and server. Both JSON and Protobuf communication formats are supported. There are some issues with the proper passing of the disconnect advice in some cases, otherwise it\'s fully functional.\\n\\nObviously, due to the limited WebTransport support in browsers at the moment, possible breaking changes in the WebTransport specification we can not recommended it for production usage for now. At some point in the future, it may become a reasonable alternative to WebSocket, now we are more confident that Centrifugo will be able to provide a proper support of it.\\n\\n## Migration guide\\n\\nThe [migration guide](/docs/getting-started/migration_v4) contains steps to upgrade your Centrifugo from version 3 to version 4. While there are many changes in the v4 release, it should be possible to migrate to Centrifugo v4 without changing the code on the client side at all. And then, after updating the server, gradually update the client-side to the latest version of the stack.\\n\\n## Conclusion\\n\\n![](/img/bg_cat.jpg)\\n\\nTo sum it up, here are some benefits of Centrifugo v4:\\n\\n* unified experience thoughout application frontend environments\\n* an optimized protocol which is generally faster, more compact and human-readable in JSON case, provides more resilient behavior for subscriptions\\n* revised channel namespace security model, more granular permission control\\n* more efficient and flexible use of subscription tokens\\n* better initial latency \u2013 thanks to optimistic subscriptions and the ability to pre-create subscription tokens (as the `client` claim not needed anymore)\\n* the ability to use more efficient WebSocket bidirectional emulation in the browser without having to worry about sticky sessions, unless you want to optimize the real-time infrastructure\\n\\nThat\'s it. We now begin the era of v4 and it is going to be awesome, no doubt.\\n\\n## Join community\\n\\nThe release contains many changes that strongly affect developing with Centrifugo. And of course you may have some questions or issues regarding new or changed concepts. Join our communities in Telegram (the most active) and Discord:\\n\\n[![Join the chat at https://t.me/joinchat/ABFVWBE0AhkyyhREoaboXQ](https://img.shields.io/badge/Telegram-Group-orange?style=flat&logo=telegram)](https://t.me/joinchat/ABFVWBE0AhkyyhREoaboXQ) &nbsp;[![Join the chat at https://discord.gg/tYgADKx](https://img.shields.io/discord/719186998686122046?style=flat&label=Discord&logo=discord)](https://discord.gg/tYgADKx)\\n\\nEnjoy Centrifugo v4, and let the Centrifugal force be with you.\\n\\n## Special thanks\\n\\nThe refactoring of client SDKs and introducing unified behavior based on the common spec was the hardest part of Centrifugo v4 release. Many thanks to [Vitaly Puzrin](https://github.com/puzrin) (who is the author of several popular open-source libraries such as [markdown-it](https://github.com/markdown-it/markdown-it), [fontello](https://github.com/fontello/fontello), and others). We had a series of super productive sessions with him on client SDK API design. Some great ideas emerged from these sessions and the result seems like a huge step forward for Centrifugal projects.\\n\\nAlso, thanks to [Anton Silischev](https://github.com/silischev) who helped a lot with WebTransport prototypes earlier this year, so we could quickly adopt WebTransport for v4.\\n\\n:::tip\\n\\nAs some of you know, Centrifugo server is built on top of the [Centrifuge](https://github.com/centrifugal/centrifuge) library for Go. Most of the optimizations and improvements described here are now also part of Centrifuge library.\\n\\nWith its new unified SDK behavior and bidirectional emulation layer, it seems a solid alternative to Socket.IO in the Go language ecosystem.\\n\\nIn some cases, Centrifuge library can be a more flexible solution than Centrifugo, since Centrifugo (as a standalone server) dictates some mechanics and rules that must be followed. In the case of Centrifugo, the business logic must live on the application backend side, with Centrifuge library it can be kept closer to the real-time transport layer.\\n\\n:::\\n\\n:::note Attributions\\n\\nThis post used images from freepik.com: [background](https://www.freepik.com/free-vector/abstract-background-consisting-colorful-arcs-illustration_14803794.htm#&position=5&from_view=author) by [liuzishan](https://www.freepik.com/author/liuzishan). Also [image](https://www.freepik.com/free-vector/abstract-black-circles-layers-dark-background-paper-cut_17303270.htm) by [kenshinstock](https://www.freepik.com/author/kenshinstock).\\n\\n:::"},{"id":"/2021/12/14/laravel-multi-room-chat-tutorial","metadata":{"permalink":"/blog/2021/12/14/laravel-multi-room-chat-tutorial","editUrl":"https://github.com/centrifugal/centrifugal.dev/edit/main/blog/2021-12-14-laravel-multi-room-chat-tutorial.md","source":"@site/blog/2021-12-14-laravel-multi-room-chat-tutorial.md","title":"Building a multi-room chat application with Laravel and Centrifugo","description":"In this tutorial, we are integrating Laravel framework with Centrifugo real-time messaging server to make a multi-room chat application.","date":"2021-12-14T00:00:00.000Z","formattedDate":"December 14, 2021","tags":[{"label":"centrifugo","permalink":"/blog/tags/centrifugo"},{"label":"tutorial","permalink":"/blog/tags/tutorial"},{"label":"laravel","permalink":"/blog/tags/laravel"},{"label":"php","permalink":"/blog/tags/php"}],"readingTime":10.55,"hasTruncateMarker":true,"authors":[{"name":"Anton Silischev","title":"Centrifugo contributor","imageURL":"https://github.com/silischev.png"}],"frontMatter":{"title":"Building a multi-room chat application with Laravel and Centrifugo","tags":["centrifugo","tutorial","laravel","php"],"description":"In this tutorial, we are integrating Laravel framework with Centrifugo real-time messaging server to make a multi-room chat application.","author":"Anton Silischev","authorTitle":"Centrifugo contributor","authorImageURL":"https://github.com/silischev.png","image":"/img/laravel_centrifugo.jpg","hide_table_of_contents":false},"prevItem":{"title":"Centrifugo v4 released \u2013 a little revolution","permalink":"/blog/2022/07/19/centrifugo-v4-released"},"nextItem":{"title":"Centrifugo integration with Django \u2013 building a basic chat application","permalink":"/blog/2021/11/04/integrating-with-django-building-chat-application"}},"content":"![Image](/img/laravel_centrifugo.jpg)\\n\\nIn this tutorial, we will create a multi-room chat server using [Laravel framework](https://laravel.com/) and [Centrifugo](https://centrifugal.dev/) real-time messaging server.\\n\\nAuthenticated users of our chat app will be able to create new chat rooms, join existing rooms and instantly communicate inside rooms with the help of Centrifugo WebSocket real-time transport.\\n\\n\x3c!--truncate--\x3e\\n\\n## Application overview\\n\\nThe result will look like this:\\n\\n<video width=\\"100%\\" controls>\\n  <source src=\\"/img/laravel_chat_demo.mp4\\" type=\\"video/mp4\\" />\\n  Sorry, your browser doesn\'t support embedded video.\\n</video>\\n\\nFor the backend, we are using Laravel (version 8.65) as one of the most popular PHP frameworks. Centrifugo v3 will accept WebSocket client connections. And we will implement an integration layer between Laravel and Centrifugo.\\n\\nFor CSS styles we are using recently released Bootstrap 5. Also, some vanilla JS instead of frameworks like React/Vue/whatever to make frontend Javascript code simple \u2013 so most developers out there could understand the mechanics. \\n\\nWe are also using a bit old-fashioned server rendering here where server renders templates for different room routes (URLs) \u2013 i.e. our app is not a SPA app \u2013 mostly for the same reasons: to keep example short and let reader focus on Centrifugo and Laravel integration parts.\\n\\nTo generate fake user avatars we are requesting images from https://robohash.org/ which can generate unique robot puctures based on some input string (username in our case). Robots like to chat with each other!\\n\\n<img src=\\"https://robohash.org/1.png\\" width=\\"30%\\" />\\n<img src=\\"https://robohash.org/2.png\\" width=\\"30%\\" />\\n<img src=\\"https://robohash.org/4.png\\" width=\\"30%\\" />\\n<br /><br /><br />\\n\\n:::tip\\n\\nWe also have some ideas on further possible app improvements at the end of this post.\\n\\n:::\\n\\n## Why integrate Laravel with Centrifugo?\\n\\nWhy would Laravel developers want to integrate a project with Centrifugo for real-time messaging functionality? That\'s a good question. There are several points which could be a good motivation:\\n\\n* Centrifugo is [open-source](https://github.com/centrifugal/centrifugo) and **self-hosted**. So you can run it on your own infrastructure. Popular Laravel real-time broadcasting intergrations (Pusher and Ably) are paid cloud solutions. At scale Centrifugo will cost you less than cloud solutions. Of course cloud solutions do not require additional server setup \u2013 but everything is a trade-off right? So you should decide for youself.\\n* Centrifugo is fast and scales well. It has an optimized Redis Engine with client-side sharding and Redis Cluster support. Centrifugo can also scale with KeyDB, Nats, or Tarantool. So it\'s possible to handle millions of connections distributed over different Centrifugo nodes.\\n* Centrifugo provides a variety of features out-of-the-box \u2013 some of them are unique, especially for self-hosted real-time servers that scale to many nodes (like fast message history cache, or maintaining single user connection, both client-side and server-side subscriptions, etc).\\n* Centrifugo is lightweight, single binary server which works as a separate service \u2013 it can be a universal tool in the developer\'s pocket, can migrate with you from one project to another, no matter what programming language or framework is used for business logic.\\n\\nHope this makes sense as a good motivation to give Centrifugo a try in your Laravel project. Let\'s get started!\\n\\n## Setup and start a project\\n\\nFor the convenience of working with the example, we [wrapped the end result into docker compose](https://github.com/centrifugal/examples/blob/master/v3/php_laravel_chat_tutorial/docker-compose.yml).\\n\\nTo start the app clone [examples repo](https://github.com/centrifugal/examples), cd into `v3/php_laravel_chat_tutorial` directory and run:\\n\\n```bash\\ndocker compose up\\n```\\n\\nAt the first launch, the necessary images will be downloaded (will take some time and network bytes). When the main service is started, you should see something like this in container logs:\\n\\n```\\n...\\napp           | Database seeding completed successfully.\\napp           | [10-Dec-2021 12:25:05] NOTICE: fpm is running, pid 112\\napp           | [10-Dec-2021 12:25:05] NOTICE: ready to handle connections\\n```\\n\\nThen go to [http://localhost/](http://localhost/) \u2013 you should see:\\n\\n![Image](/img/laravel_main_page.jpg)\\n\\nRegister (using some fake credentials) or sign up \u2013 and proceed to the chat rooms.\\n\\nPay attention to the [configuration](https://github.com/centrifugal/examples/tree/master/v3/php_laravel_chat_tutorial/docker/conf) of Centrifugo and Nginx. Also, on [entrypoint](https://github.com/centrifugal/examples/blob/master/v3/php_laravel_chat_tutorial/docker/entrypoints/app.sh) which does some things:\\n\\n- dependencies are installed via composer\\n- copying settings from .env.example\\n- db migrations are performed and the necessary npm packages are installed\\n- php-fpm starts\\n\\n## Application structure\\n\\nWe assume you already familar with Laravel concepts, so we will just point you to some core aspects of the Laravel application structure and will pay more attention to Centrifugo integration parts.\\n\\n### Environment settings\\n\\nAfter the first launch of the application, all settings will be copied from the file [`.env.example`](https://github.com/centrifugal/examples/blob/master/v3/php_laravel_chat_tutorial/app/.env.example) to `.env`. Next, we will take a closer look at some settings.\\n\\n### Database migrations and models\\n\\nYou can view the database structure [here](https://github.com/centrifugal/examples/tree/master/v3/php_laravel_chat_tutorial/app/database/migrations).\\n\\nWe will use the following tables which will be then translated to the application models:\\n\\n- Laravel standard user authentication tables. See https://laravel.com/docs/8.x/authentication. In the service we are using Laravel Breeze. For more information [see official docs](https://laravel.com/docs/8.x/starter-kits#laravel-breeze).\\n- [rooms](https://github.com/centrifugal/examples/blob/master/v3/php_laravel_chat_tutorial/app/database/migrations/2021_11_21_000001_create_rooms_table.php) table. Basically - describes different rooms in the app every user can create.\\n- rooms [many-to-many relation](https://github.com/centrifugal/examples/blob/master/v3/php_laravel_chat_tutorial/app/database/migrations/2021_11_21_000002_create_users_rooms_table.php) to users. Allows to add users into rooms when `join` button clicked or automatically upon room creation.\\n- [messages](https://github.com/centrifugal/examples/blob/master/v3/php_laravel_chat_tutorial/app/database/migrations/2021_11_21_000003_create_messages_table.php). Keeps message history in rooms.\\n\\n### Broadcasting\\n\\nFor broadcasting we are using [laravel-centrifugo](https://github.com/denis660/laravel-centrifugo) library. It helps to simplify interaction between Laravel and Centrifugo by providing some convenient wrappers.\\n\\nStep-by-step configuration can be viewed in the [readme](https://github.com/denis660/laravel-centrifugo) file of this library.\\n\\nPay attention to the `CENTRIFUGO_API_KEY` setting. It is used to send API requests from Laravel to Centrifugo and must match in `.env` and `centrifugo.json` files. And we also telling `laravel-centrifugo` the URL of Centrifugo. That\'s all we need to configure for this example app.\\n\\nSee more information about Laravel broadcasting [here](https://laravel.com/docs/8.x/broadcasting).\\n\\n:::tip\\n\\nAs an alternative to `laravel-centrifugo`, you can use [phpcent](https://github.com/centrifugal/phpcent) \u2013 it\'s an official generic API client which allows publishing to Centrifugo HTTP API. But it does know nothing about Laravel broadcasting specifics.\\n\\n:::\\n\\n### Interaction with Centrifugo\\n\\nWhen user opens a chat app it connects to Centrifugo over WebSocket transport.\\n\\nLet\'s take a closer look at Centrifugo server configuration file we use for this example app:\\n\\n```json\\n{\\n  \\"port\\": 8000,\\n  \\"engine\\": \\"memory\\",\\n  \\"api_key\\": \\"some-long-api-key-which-you-should-keep-secret\\",\\n  \\"allowed_origins\\": [\\n    \\"http://localhost\\",\\n  ],\\n  \\"proxy_connect_endpoint\\": \\"http://nginx/centrifugo/connect/\\",\\n  \\"proxy_http_headers\\": [\\n    \\"Cookie\\"\\n  ],\\n  \\"namespaces\\": [\\n    {\\n      \\"name\\": \\"personal\\"\\n    }\\n  ]\\n}\\n```\\n\\nThis configuration defines a connect proxy endpoint which is targeting Nginx and then proxied to Laravel. Centrifugo will proxy `Cookie` header of WebSocket HTTP Upgrade requests to Laravel \u2013 this allows using native Laravel authentication.\\n\\nWe also defined a `\\"personal\\"` namespace \u2013 we will subscribe each user to a personal channel in this namespace inside connect proxy handler. Using namespaces for different real-time features is one of Centrifugo best-practices.\\n\\nAllowed origins must be properly set to prevent [cross-site WebSocket connection hijacking](https://christian-schneider.net/CrossSiteWebSocketHijacking.html).\\n\\n### Connect proxy controller\\n\\nTo use native Laravel user authentication middlewares, we will use [Centrifugo proxy feature](https://centrifugal.dev/docs/server/proxy).\\n\\nWhen user connects to Centrifugo it\'s connection attempt will be transformed into HTTP request from Centrifugo to Laravel and will hit the [connect proxy controller](https://github.com/centrifugal/examples/blob/master/v3/php_laravel_chat_tutorial/app/app/Http/Controllers/CentrifugoProxyController.php):\\n\\n```php\\nclass CentrifugoProxyController extends Controller\\n{\\n    public function connect()\\n    {\\n        return new JsonResponse([\\n            \'result\' => [\\n                \'user\' => (string) Auth::user()->id,\\n                \'channels\' => [\\"personal:#\\".Auth::user()->id],\\n            ]\\n        ]);\\n    }\\n}\\n```\\n\\nThis controller [protected by auth middleware](https://github.com/centrifugal/examples/blob/master/v3/php_laravel_chat_tutorial/app/routes/api.php).\\n\\nSince Centrifugo proxies `Cookie` header of initial WebSocket HTTP Upgrade request Laravel auth layer will work just fine. So in a controller you already has access to the current authenticated user.\\n\\nIn the response from controller we tell Centrifugo the ID of connecting user and subscribe user to its personal channel (using [user-limited channel](https://centrifugal.dev/docs/server/channels#user-channel-boundary-) feature of Centrifugo). Returning a channel in such way will subscribe user to it using [server-side subscriptions](https://centrifugal.dev/docs/server/server_subs) mechanism.\\n\\n:::tip\\n\\nNote, that in our chat app we are using a single personal channel for each user to receive real-time updates from all rooms. We are not creating separate subscriptions for each room user joined too. This will allow us to scale more easily in the future, and basically the only viable solution in case of room list pagination in chat application like this. It does not mean you can not combine personal user channels and separate room channels for different tasks though.\\n\\nSome additional tips can be found in [Centrifugo FAQ](https://centrifugal.dev/docs/faq/index#what-about-best-practices-with-the-number-of-channels).\\n\\n:::\\n\\n### Room controller\\n\\nIn [RoomController](https://github.com/centrifugal/examples/blob/master/v3/php_laravel_chat_tutorial/app/app/Http/Controllers/RoomController.php) we perform various actions with rooms:\\n\\n* displaying rooms\\n* create rooms\\n* join users to rooms\\n* publish messages\\n\\nWhen we publish a message in a room, we send a message to the personal channel of all users joined to the room using the [`broadcast` method of Centrifugo API](https://centrifugal.dev/docs/server/server_api#broadcast). It allows publishing the same message into many channels. \\n\\n```php\\n$message = Message::create([\\n    \'sender_id\' => Auth::user()->id,\\n    \'message\' => $requestData[\\"message\\"],\\n    \'room_id\' => $id,\\n]);\\n\\n$room = Room::with(\'users\')->find($id);\\n\\n$channels = [];\\nforeach ($room->users as $user) {\\n    $channels[] = \\"personal:#\\" . $user->id;\\n}\\n\\n$this->centrifugo->broadcast($channels, [\\n    \\"text\\" => $message->message,\\n    \\"createdAt\\" => $message->created_at->toDateTimeString(),\\n    \\"roomId\\" => $id,\\n    \\"senderId\\" => Auth::user()->id,\\n    \\"senderName\\" => Auth::user()->name,\\n]);\\n```\\n\\nWe also add some fields to the published message which will be used when dynamically displaying a message coming from a WebSocket connection (see [Client side](#client-side) below).\\n\\n### Client side\\n\\nOur chat is basically a one page with some variations dependng on the current route. So we use [a single view](https://github.com/centrifugal/examples/blob/master/v3/php_laravel_chat_tutorial/app/resources/views/rooms/index.blade.php) for the entire chat app.\\n\\nOn the page we have a form for creating rooms. The user who created the room automatically joins it upon creation. Other users need to join manually (using `join` button in the room).\\n\\nWhen sending a message (using the chat room message input), we make an AJAX request that hits `RoomController` shown above. A message saved into the database and then broadcasted to all users who joined this room. Here is a code that processes sending on ENTER:\\n\\n```js\\nmessageInput.onkeyup = function(e) {\\n    if (e.keyCode === 13) {\\n        e.preventDefault();\\n        const message = messageInput.value;\\n        if (!message) {\\n            return;\\n        }\\n        const xhttp = new XMLHttpRequest();\\n        xhttp.open(\\"POST\\", \\"/rooms/\\" + roomId + \\"/publish\\");\\n        xhttp.setRequestHeader(\\"X-CSRF-TOKEN\\", csrfToken);\\n        xhttp.send(JSON.stringify({\\n            message: message\\n        }));\\n        messageInput.value = \'\';\\n    }\\n};\\n```\\n\\nAfter the message is processed on the server and broadcasted to Centrifugo it instantly comes to client-side. To receive the message we are connecting to Centrifugo WebSocket endpoint and wait for a message in the `publish` event handler:\\n\\n```js\\nconst url = \\"ws://\\" + window.location.host + \\"/connection/websocket\\";\\nconst centrifuge = new Centrifuge(url);\\n\\ncentrifuge.on(\'connect\', function(ctx) {\\n    console.log(\\"connected to Centrifugo\\", ctx);\\n});\\n\\ncentrifuge.on(\'disconnect\', function(ctx) {\\n    console.log(\\"disconnected from Centrifugo\\", ctx);\\n});\\n\\ncentrifuge.on(\'publish\', function(ctx) {\\n    if (ctx.data.roomId.toString() === currentRoomId) {\\n        addMessage(ctx.data);\\n        scrollToLastMessage();\\n    }\\n    addRoomLastMessage(ctx.data);\\n});\\n\\ncentrifuge.connect();\\n```\\n\\nWe are using [centrifuge-js](https://github.com/centrifugal/centrifuge-js) client connector library to communicate with Centrifugo. This client abstracts away bidirectional asynchronous protocol complexity for us providing a simple way to listen connect, disconnect events and communicate with a server in various ways.\\n\\nIn publish event handler we check whether the message belongs to the room the user is currently in. If yes, then we add it to the message history of the room. We also add this message to the room in the list on the left as the last chat message in room. If necessary, we crop the text for normal display.\\n\\n:::tip\\n\\nIn our example we only subscribe each user to a single channel, but user can be subscribed to several server-side channels. To distinguish between them use `ctx.channel` inside publish event handler.\\n\\n:::\\n\\nAnd that\'s it! We went through all the main parts of the integration.\\n\\n## Possible improvements\\n\\nAs promised, here is a list with several possible app improvements:\\n\\n* Transform to a single page app, use productive Javascript frameworks like React or VueJS instead of vanilla JS.\\n* Add message read statuses - as soon as one of the chat participants read the message mark it read in the database.\\n* Introduce user-to-user chats.\\n* Support pagination for the message history, maybe for chat room list also.\\n* Don\'t show all rooms in the system \u2013 add functionality to search room by name.\\n* Horizontal scaling (using multiple nodes of Centrifugo, for example with [Redis Engine](https://centrifugal.dev/docs/server/engines#redis-engine)) \u2013 mostly one line in Centrifugo config if you have Redis running.\\n* Gracefully handle temporary disconnects by loading missed messages from the database or Centrifugo channel history cache.\\n* Optionally replace connect proxy with [JWT authentication](https://centrifugal.dev/docs/server/authentication) to reduce HTTP calls from Centrifugo to Laravel. This may drastically reduce resources for Laravel backend at scale.\\n* Try using [Centrifugo RPC proxy](https://centrifugal.dev/docs/server/proxy#rpc-proxy) feature to use WebSocket connection for message publish instead of issuing AJAX request.\\n\\n## Conclusion\\n\\nWe built a chat app with Laravel and Centrifugo. While there is still an area for improvements, this example is not really the basic. It\'s already valuable in the current form and may be transformed into part of your production system with minimal tweaks.\\n\\nHope you enjoyed this tutorial. If you have any questions after reading \u2013 join our [community channels](/docs/getting-started/introduction#join-community). We touched only part of Centrifugo concepts here \u2013 take a look at detailed Centrifugo docs nearby. And let the Centrifugal force be with you!"},{"id":"/2021/11/04/integrating-with-django-building-chat-application","metadata":{"permalink":"/blog/2021/11/04/integrating-with-django-building-chat-application","editUrl":"https://github.com/centrifugal/centrifugal.dev/edit/main/blog/2021-11-04-integrating-with-django-building-chat-application.md","source":"@site/blog/2021-11-04-integrating-with-django-building-chat-application.md","title":"Centrifugo integration with Django \u2013 building a basic chat application","description":"In this tutorial, we are integrating Django with Centrifugo to make a basic chat application. We are using Centrifugo proxy feature to proxy WebSocket connection events to a Django backend.","date":"2021-11-04T00:00:00.000Z","formattedDate":"November 4, 2021","tags":[{"label":"centrifugo","permalink":"/blog/tags/centrifugo"},{"label":"tutorial","permalink":"/blog/tags/tutorial"},{"label":"django","permalink":"/blog/tags/django"}],"readingTime":15.49,"hasTruncateMarker":true,"authors":[{"name":"Alexander Emelin","title":"Ex-Pythonista","imageURL":"https://github.com/FZambia.png"}],"frontMatter":{"title":"Centrifugo integration with Django \u2013 building a basic chat application","tags":["centrifugo","tutorial","django"],"description":"In this tutorial, we are integrating Django with Centrifugo to make a basic chat application. We are using Centrifugo proxy feature to proxy WebSocket connection events to a Django backend.","author":"Alexander Emelin","authorTitle":"Ex-Pythonista","authorImageURL":"https://github.com/FZambia.png","image":"/img/django_tutorial.jpg","hide_table_of_contents":false},"prevItem":{"title":"Building a multi-room chat application with Laravel and Centrifugo","permalink":"/blog/2021/12/14/laravel-multi-room-chat-tutorial"},"nextItem":{"title":"Centrifugo integration with NodeJS tutorial","permalink":"/blog/2021/10/18/integrating-with-nodejs"}},"content":"![Centrifuge](/img/django_tutorial.jpg)\\n\\nIn this tutorial, we will create a basic chat server using the [Django framework](https://www.djangoproject.com/) and [Centrifugo](https://centrifugal.dev/). Our chat application will have two pages:\\n\\n1. A page that lets you type the name of a chat room to join.\\n1. A room view that lets you see messages posted in a chat room you joined.\\n\\nThe room view will use a WebSocket to communicate with the Django server (with help from Centrifugo) and listen for any messages that are published to the room channel.\\n\\n\x3c!--truncate--\x3e\\n\\nThe result will look like this:\\n\\n![demo](/img/django_chat.gif)\\n\\n:::tip\\n\\nSome of you will notice that this tutorial looks very similar to [Chat app tutorial of Django Channels](https://channels.readthedocs.io/en/stable/tutorial/index.html). This is intentional to let Pythonistas already familiar with Django Channels feel how Centrifugo compares to Channels in terms of the integration process.\\n\\n:::\\n\\n## Why integrate Django with Centrifugo\\n\\nWhy would Django developers want to integrate a project with Centrifugo for real-time messaging functionality? This is a good question especially since there is a popular Django Channels project which solves the same task.\\n\\nI found several points which could be a good motivation:\\n\\n* Centrifugo is fast and scales well. We have an optimized Redis Engine with client-side sharding and Redis Cluster support. Centrifugo can also scale with KeyDB, Nats, or Tarantool. So it\'s possible to handle millions of connections distributed over different server nodes.\\n* Centrifugo provides a variety of features out-of-the-box \u2013 some of them are unique, especially for real-time servers that scale to many nodes. Check out our doc!\\n* With Centrifugo you don\'t need to rewrite the existing application to introduce real-time messaging features to your users.\\n* Centrifugo works as a separate service \u2013 so can be a universal tool in the developer\'s pocket, can migrate from one project to another, no matter what programming language or framework is used for business logic.\\n\\n## Prerequisites\\n\\nWe assume that you are already familiar with basic Django concepts. If not take a look at the official [Django tutorial](https://docs.djangoproject.com/en/stable/intro/tutorial01/) first and then come back to this tutorial.\\n\\nAlso, make sure you read a bit about Centrifugo \u2013 [introduction](https://centrifugal.dev/docs/getting-started/introduction) and [quickstart tutorial](https://centrifugal.dev/docs/getting-started/quickstart).\\n\\nWe also assume that you have [Django installed](https://docs.djangoproject.com/en/stable/intro/install/) already.\\n\\nOne possible way to quickly install Django locally is to create virtualenv, activate it, and install Django:\\n\\n```bash\\npython3 -m venv env\\n. env/bin/activate\\npip install django\\n```\\n\\nAlos, make sure you have Centrifugo v3 [installed](/docs/getting-started/installation) already.\\n\\nThis tutorial also uses Docker to run Redis. We use Redis as a Centrifugo engine \u2013 this allows us to have a scalable solution in the end. Using Redis is optional actually, Centrifugo uses a Memory engine by default (but it does not allow scaling Centrifugo nodes). We will also run Nginx with Docker to serve the entire app. [Install Docker](https://www.docker.com/get-started) from its official website but I am sure you already have one.\\n\\n## Creating a project\\n\\nFirst, let\'s create a Django project.\\n\\nFrom the command line, `cd` into a directory where you\u2019d like to store your code, then run the following command:\\n\\n```bash\\ndjango-admin startproject mysite\\n```\\n\\nThis will create a mysite directory in your current directory with the following contents:\\n\\n```\\n\u276f tree mysite\\nmysite\\n\u251c\u2500\u2500 manage.py\\n\u2514\u2500\u2500 mysite\\n    \u251c\u2500\u2500 __init__.py\\n    \u251c\u2500\u2500 asgi.py\\n    \u251c\u2500\u2500 settings.py\\n    \u251c\u2500\u2500 urls.py\\n    \u2514\u2500\u2500 wsgi.py\\n```\\n\\n## Creating the chat app\\n\\nWe will put the code for the chat server inside `chat` app.\\n\\nMake sure you\u2019re in the same directory as `manage.py` and type this command:\\n\\n```bash\\npython3 manage.py startapp chat\\n```\\n\\nThat\u2019ll create a directory chat, which is laid out like this:\\n\\n```\\n\u276f tree chat\\nchat\\n\u251c\u2500\u2500 __init__.py\\n\u251c\u2500\u2500 admin.py\\n\u251c\u2500\u2500 apps.py\\n\u251c\u2500\u2500 migrations\\n\u2502   \u2514\u2500\u2500 __init__.py\\n\u251c\u2500\u2500 models.py\\n\u251c\u2500\u2500 tests.py\\n\u2514\u2500\u2500 views.py\\n```\\n\\nFor this tutorial, we will only be working with `chat/views.py` and `chat/__init__.py`. Feel free to remove all other files from the chat directory.\\n\\nAfter removing unnecessary files, the chat directory should look like this:\\n\\n```\\n\u276f tree chat\\nchat\\n\u251c\u2500\u2500 __init__.py\\n\u2514\u2500\u2500 views.py\\n```\\n\\nWe need to tell our project that the chat app is installed. Edit the `mysite/settings.py` file and add \'chat\' to the `INSTALLED_APPS` setting. It\u2019ll look like this:\\n\\n```python\\n# mysite/settings.py\\nINSTALLED_APPS = [\\n    \'chat\',\\n    \'django.contrib.admin\',\\n    \'django.contrib.auth\',\\n    \'django.contrib.contenttypes\',\\n    \'django.contrib.sessions\',\\n    \'django.contrib.messages\',\\n    \'django.contrib.staticfiles\',\\n]\\n```\\n\\n## Add the index view\\n\\nWe will now create the first view, an index view that lets you type the name of a chat room to join.\\n\\nCreate a templates directory in your chat directory. Within the templates directory, you have just created, create another directory called `chat`, and within that create a file called `index.html` to hold the template for the index view.\\n\\nYour chat directory should now look like this:\\n\\n```\\n\u276f tree chat\\nchat\\n\u251c\u2500\u2500 __init__.py\\n\u251c\u2500\u2500 templates\\n\u2502   \u2514\u2500\u2500 chat\\n\u2502       \u2514\u2500\u2500 index.html\\n\u2514\u2500\u2500 views.py\\n```\\n\\nPut the following code in chat/templates/chat/index.html:\\n\\n```html title=\\"chat/templates/chat/index.html\\"\\n<!DOCTYPE html>\\n<html>\\n\\n<head>\\n    <meta charset=\\"utf-8\\" />\\n    <title>Select a chat room</title>\\n</head>\\n\\n<body>\\n    <div class=\\"center\\">\\n        <div class=\\"input-wrapper\\">\\n            <input type=\\"text\\" id=\\"room-name-input\\" />\\n        </div>\\n        <div class=\\"input-help\\">\\n            Type a room name to <a id=\\"room-name-submit\\" href=\\"#\\">JOIN</a>\\n        </div>\\n    </div>\\n    <script>\\n        const nameInput = document.querySelector(\'#room-name-input\');\\n        const nameSubmit = document.querySelector(\'#room-name-submit\');\\n        nameInput.focus();\\n        nameInput.onkeyup = function (e) {\\n            if (e.keyCode === 13) {  // enter, return\\n                nameSubmit.click();\\n            }\\n        };\\n        nameSubmit.onclick = function (e) {\\n            e.preventDefault();\\n            var roomName = nameInput.value;\\n            if (!roomName) {\\n                return;\\n            }\\n            window.location.pathname = \'/chat/room/\' + roomName + \'/\';\\n        };\\n    <\/script>\\n</body>\\n\\n</html>\\n```\\n\\nCreate the view function for the room view. Put the following code in `chat/views.py`:\\n\\n```python title=\\"chat/views.py\\"\\nfrom django.shortcuts import render\\n\\ndef index(request):\\n    return render(request, \'chat/index.html\')\\n```\\n\\nTo call the view, we need to map it to a URL - and for this, we need a URLconf.\\n\\nTo create a URLconf in the chat directory, create a file called `urls.py`. Your app directory should now look like this:\\n\\n```\\n\u276f tree chat\\nchat\\n\u251c\u2500\u2500 __init__.py\\n\u251c\u2500\u2500 templates\\n\u2502   \u2514\u2500\u2500 chat\\n\u2502       \u2514\u2500\u2500 index.html\\n\u2514\u2500\u2500 views.py\\n\u2514\u2500\u2500 urls.py\\n```\\n\\nIn the `chat/urls.py` file include the following code:\\n\\n```python title=\\"chat/urls.py\\"\\nfrom django.urls import path\\n\\nfrom . import views\\n\\nurlpatterns = [\\n    path(\'\', views.index, name=\'index\'),\\n]\\n```\\n\\nThe next step is to point the root URLconf at the `chat.urls` module. In `mysite/urls.py`, add an import for `django.conf.urls.include` and insert an include() in the urlpatterns list, so you have:\\n\\n```python title=\\"mysite/urls.py\\"\\nfrom django.conf.urls import include\\nfrom django.urls import path\\nfrom django.contrib import admin\\n\\nurlpatterns = [\\n    path(\'chat/\', include(\'chat.urls\')),\\n    path(\'admin/\', admin.site.urls),\\n]\\n```\\n\\nLet\u2019s verify that the index view works. Run the following command:\\n\\n```bash\\npython3 manage.py runserver\\n```\\n\\nYou\u2019ll see the following output on the command line:\\n\\n```\\nWatching for file changes with StatReloader\\nPerforming system checks...\\n\\nSystem check identified no issues (0 silenced).\\n\\nYou have 18 unapplied migration(s). Your project may not work properly until you apply the migrations for app(s): admin, auth, contenttypes, sessions.\\nRun \'python manage.py migrate\' to apply them.\\nOctober 21, 2020 - 18:49:39\\nDjango version 3.1.2, using settings \'mysite.settings\'\\nStarting development server at http://localhost:8000/\\nQuit the server with CONTROL-C.\\n```\\n\\nGo to [http://localhost:8000/chat/](http://localhost:8000/chat/) in your browser and you should see the a text input to provide a room name.\\n\\nType in \\"lobby\\" as the room name and press Enter. You should be redirected to the room view at [http://localhost:8000/chat/room/lobby/](http://localhost:8000/chat/room/lobby/) but we haven\u2019t written the room view yet, so you\u2019ll get a \\"Page not found\\" error page.\\n\\nGo to the terminal where you ran the runserver command and press Control-C to stop the server.\\n\\n## Add the room view\\n\\nWe will now create the second view, a room view that lets you see messages posted in a particular chat room.\\n\\nCreate a new file `chat/templates/chat/room.html`. Your app directory should now look like this:\\n\\n```\\nchat\\n\u251c\u2500\u2500 __init__.py\\n\u251c\u2500\u2500 templates\\n\u2502   \u2514\u2500\u2500 chat\\n\u2502       \u251c\u2500\u2500 index.html\\n\u2502       \u2514\u2500\u2500 room.html\\n\u251c\u2500\u2500 urls.py\\n\u2514\u2500\u2500 views.py\\n```\\n\\nCreate the view template for the room view in `chat/templates/chat/room.html`:\\n\\n```html title=\\"chat/templates/chat/room.html\\"\\n<!DOCTYPE html>\\n<html>\\n\\n<head>\\n    <meta charset=\\"utf-8\\" />\\n    <title>Chat Room</title>\\n    <script src=\\"https://cdn.jsdelivr.net/gh/centrifugal/centrifuge-js@2.8.3/dist/centrifuge.min.js\\"><\/script>\\n</head>\\n\\n<body>\\n    <ul id=\\"chat-thread\\" class=\\"chat-thread\\"></ul>\\n    <div class=\\"chat-message\\">\\n        <input id=\\"chat-message-input\\" class=\\"chat-message-input\\" type=\\"text\\" autocomplete=\\"off\\" autofocus />\\n    </div>\\n    {{ room_name|json_script:\\"room-name\\" }}\\n    <script>\\n        const roomName = JSON.parse(document.getElementById(\'room-name\').textContent);\\n        const chatThread = document.querySelector(\'#chat-thread\');\\n        const messageInput = document.querySelector(\'#chat-message-input\');\\n\\n        const centrifuge = new Centrifuge(\\"ws://\\" + window.location.host + \\"/connection/websocket\\");\\n\\n        centrifuge.on(\'connect\', function (ctx) {\\n            console.log(\\"connected\\", ctx);\\n        });\\n\\n        centrifuge.on(\'disconnect\', function (ctx) {\\n            console.log(\\"disconnected\\", ctx);\\n        });\\n\\n        const sub = centrifuge.subscribe(\'rooms:\' + roomName, function (ctx) {\\n            const chatNewThread = document.createElement(\'li\');\\n            const chatNewMessage = document.createTextNode(ctx.data.message);\\n            chatNewThread.appendChild(chatNewMessage);\\n            chatThread.appendChild(chatNewThread);\\n            chatThread.scrollTop = chatThread.scrollHeight;\\n        });\\n\\n        centrifuge.connect();\\n\\n        messageInput.focus();\\n        messageInput.onkeyup = function (e) {\\n            if (e.keyCode === 13) {  // enter, return\\n                e.preventDefault();\\n                const message = messageInput.value;\\n                if (!message) {\\n                    return;\\n                }\\n                sub.publish({ \'message\': message });\\n                messageInput.value = \'\';\\n            }\\n        };\\n    <\/script>\\n</body>\\n\\n</html>\\n```\\n\\nCreate the view function for the room view in `chat/views.py`:\\n\\n```python title=\\"chat/views.py\\"\\nfrom django.shortcuts import render\\n\\n\\ndef index(request):\\n    return render(request, \'chat/index.html\')\\n\\n\\ndef room(request, room_name):\\n    return render(request, \'chat/room.html\', {\\n        \'room_name\': room_name\\n    })\\n```\\n\\nCreate the route for the room view in `chat/urls.py`:\\n\\n```python\\n# chat/urls.py\\nfrom django.urls import path, re_path\\n\\nfrom . import views\\n\\nurlpatterns = [\\n    path(\'\', views.index, name=\'index\'),\\n    re_path(\'room/(?P<room_name>[A-z0-9_-]+)/\', views.room, name=\'room\'),\\n]\\n```\\n\\nStart the development server:\\n\\n```\\npython3 manage.py runserver\\n```\\n\\nGo to [http://localhost:8000/chat/](http://localhost:8000/chat/) in your browser and to see the index page.\\n\\nType in \\"lobby\\" as the room name and press enter. You should be redirected to the room page at [http://localhost:8000/chat/lobby/](http://localhost:8000/chat/lobby/) which now displays an empty chat log.\\n\\nType the message \\"hello\\" and press Enter. Nothing happens! In particular, the message does not appear in the chat log. Why?\\n\\nThe room view is trying to open a WebSocket connection with Centrifugo using the URL `ws://localhost:8000/connection/websocket` but we haven\u2019t started Centrifugo to accept WebSocket connections yet. If you open your browser\u2019s JavaScript console, you should see an error that looks like this:\\n\\n```\\nWebSocket connection to \'ws://localhost:8000/connection/websocket\' failed\\n```\\n\\nAnd since port 8000 has already been allocated we will start Centrifugo at a different port actually.\\n\\n## Starting Centrifugo server\\n\\nAs promised we will use Centrifugo with Redis engine. So first thing to do before running Centrifugo is to start Redis:\\n\\n```bash\\ndocker run -it --rm -p 6379:6379 redis:6\\n```\\n\\nThen create a configuration file for Centrifugo:\\n\\n```json\\n{\\n    \\"port\\": 8001,\\n    \\"engine\\": \\"redis\\",\\n    \\"redis_address\\": \\"redis://localhost:6379\\",\\n    \\"allowed_origins\\": \\"http://localhost:9000\\",\\n    \\"proxy_connect_endpoint\\": \\"http://localhost:8000/chat/centrifugo/connect/\\",\\n    \\"proxy_publish_endpoint\\": \\"http://localhost:8000/chat/centrifugo/publish/\\",\\n    \\"proxy_subscribe_endpoint\\": \\"http://localhost:8000/chat/centrifugo/subscribe/\\",\\n    \\"proxy_http_headers\\": [\\"Cookie\\"],\\n    \\"namespaces\\": [\\n        {\\n            \\"name\\": \\"rooms\\",\\n            \\"publish\\": true,\\n            \\"proxy_publish\\": true,\\n            \\"proxy_subscribe\\": true\\n        }\\n    ]\\n}\\n```\\n\\nAnd run Centrifugo with it like this:\\n\\n```bash\\ncentrifugo -c config.json\\n```\\n\\nLet\'s describe some options we used here:\\n\\n* `port` - sets the port Centrifugo runs on since we are running everything on localhost we make it different (8001) from the port allocated for the Django server (8000).\\n* `engine` - as promised we are using Redis engine so we can easily scale Centrifigo nodes to handle lots of WebSocket connections\\n* `redis_address` allows setting Redis address\\n* `allowed_origins` - we will connect from `http://localhost:9000` so we need to allow it\\n* `namespaces` \u2013 we are using `rooms:` prefix when subscribing to a channel, i.e. using Centrifugo `rooms` namespace. Here we define this namespace and tell Centrifigo to proxy subscribe and publish events for channels in the namespace. \\n\\n:::tip\\n\\nIt\'s a good practice to use different namespaces in Centrifugo for different real-time features as this allows enabling only required options for a specific task. \\n\\n:::\\n\\nAlso, config has some options related to [Centrifugo proxy feature](/docs/server/proxy). This feature allows proxying WebSocket events to the configured endpoints. We will proxy three types of events:\\n\\n1. Connect (called when a user establishes WebSocket connection with Centrifugo)\\n1. Subscribe (called when a user wants to subscribe on a channel)\\n1. Publish (called when a user tries to publish data to a channel)\\n\\n## Adding Nginx\\n\\nIn Centrifugo config we set endpoints which we will soon implement inside our Django app. You may notice that the allowed origin has a URL with port `9000`. That\'s because we want to proxy Cookie headers from a persistent connection established with Centrifugo to the Django app and need Centrifugo and Django to share the same origin (so browsers can send Django session cookies to Centrifugo).\\n\\nWhile not used in this tutorial (we will use fake `tutorial-user` as user ID here) \u2013 this can be useful if you decide to authenticate connections using Django native sessions framework later. To achieve this we should also add Nginx with a configuration like this:\\n\\n```text title=\\"nginx.conf\\"\\nevents {\\n    worker_connections 1024;\\n}\\n\\nerror_log /dev/stdout info;\\n\\nhttp {\\n    access_log /dev/stdout;\\n\\n    server {\\n        listen 9000;\\n\\n        server_name localhost;\\n\\n        location / {\\n            proxy_pass http://host.docker.internal:8000;\\n            proxy_http_version 1.1;\\n            proxy_set_header Host $host;\\n            proxy_set_header X-Real-IP $remote_addr;\\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\\n            proxy_set_header X-Forwarded-Proto $scheme;\\n        }\\n\\n        location /connection/websocket {\\n            proxy_pass http://host.docker.internal:8001;\\n            proxy_http_version 1.1;\\n            proxy_buffering off;\\n            keepalive_timeout 65;\\n            proxy_read_timeout 60s;\\n            proxy_set_header Upgrade $http_upgrade;\\n            proxy_set_header Connection \'upgrade\';\\n            proxy_set_header Host $host;\\n            proxy_set_header X-Real-IP $remote_addr;\\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\\n            proxy_set_header X-Forwarded-Proto $scheme;\\n            proxy_cache_bypass $http_upgrade;\\n        }\\n    }\\n}\\n```\\n\\nStart Nginx (replace the path to `nginx.conf` to yours):\\n\\n```bash\\ndocker run -it --rm -v /path/to/nginx.conf:/etc/nginx/nginx.conf:ro -p 9000:9000 --add-host=host.docker.internal:host-gateway nginx\\n```\\n\\nNote that we are exposing port 9000 to localhost and use a possibility to use `host.docker.internal` host to communicate from inside Docker network with services which are running on localhost (on the host machine). See [this answer on SO](https://stackoverflow.com/questions/31324981/how-to-access-host-port-from-docker-container).\\n\\nOpen [http://localhost:9000](http://localhost:9000). Nginx should now properly proxy requests to Django server and to Centrifugo, but we still need to do some things.\\n\\n## Implementing proxy handlers\\n\\nWell, now if you try to open a chat page with Nginx, Centrifugo, Django, and Redis running you will notice some errors in Centrifugo logs. That\'s because Centrifugo tries to proxy WebSocket connect events to Django to authenticate them but we have not created event handlers in Django yet. Let\'s fix this.\\n\\nExtend chat/urls.py:\\n\\n```python title=\\"chat/urls.py\\"\\nfrom django.urls import path, re_path\\n\\nfrom . import views\\n\\nurlpatterns = [\\n    path(\'\', views.index, name=\'index\'),\\n    re_path(\'room/(?P<room_name>[A-z0-9_-]+)/\', views.room, name=\'room\'),\\n    path(\'centrifugo/connect/\', views.connect, name=\'connect\'),\\n    path(\'centrifugo/subscribe/\', views.subscribe, name=\'subscribe\'),\\n    path(\'centrifugo/publish/\', views.publish, name=\'publish\'),\\n]\\n```\\n\\nExtend chat/views.py:\\n\\n```python title=\\"chat/views.py\\"\\nfrom django.http import JsonResponse\\nfrom django.views.decorators.csrf import csrf_exempt\\n\\n@csrf_exempt\\ndef connect(request):\\n    # In connect handler we must authenticate connection.\\n    # Here we return a fake user ID to Centrifugo to keep tutorial short.\\n    # More details about connect result format can be found in proxy docs:\\n    # https://centrifugal.dev/docs/server/proxy#connect-proxy\\n    logger.debug(request.body)\\n    response = {\\n        \'result\': {\\n            \'user\': \'tutorial-user\'\\n        }\\n    }\\n    return JsonResponse(response)\\n\\n@csrf_exempt\\ndef publish(request):\\n    # In publish handler we can validate publication request initialted by a user.\\n    # Here we return an empty object \u2013 thus allowing publication.\\n    # More details about publish result format can be found in proxy docs:\\n    # https://centrifugal.dev/docs/server/proxy#publish-proxy\\n    response = {\\n        \'result\': {}\\n    }\\n    return JsonResponse(response)\\n\\n@csrf_exempt\\ndef subscribe(request):\\n    # In subscribe handler we can validate user subscription request to a channel.\\n    # Here we return an empty object \u2013 thus allowing subscription.\\n    # More details about subscribe result format can be found in proxy docs:\\n    # https://centrifugal.dev/docs/server/proxy#subscribe-proxy\\n    response = {\\n        \'result\': {}\\n    }\\n    return JsonResponse(response)        \\n```\\n\\n`connect` view will accept all connections and return user ID as `tutorial-user`. In real app you most probably want to use Django sessions and return real authenticated user ID instead of `tutorial-user`. Since we told Centrifugo to proxy connection `Cookie` headers native Django user authentication will work just fine. \\n\\nRestart Django and try the chat app again. You should now successfully connect. Open a browser tab to the room page at [http://localhost:9000/chat/room/lobby/](http://localhost:9000/chat/room/lobby/). Open a second browser tab to the same room page.\\n\\nIn the second browser tab, type the message \\"hello\\" and press Enter. You should now see \\"hello\\" echoed in the chat log in both the second browser tab and in the first browser tab.\\n\\nYou now have a basic fully-functional chat server!\\n\\n## What could be improved\\n\\nThe list is large, but it\'s fun to do. To name some possible improvements:\\n\\n* Replace `tutorial-user` used here with native Django session framework. We already proxying the `Cookie` header to Django from Centrifugo, so you can reuse native Django authentication. Only allow authenticated users to join rooms.\\n* Create `Room` model and add users to it \u2013 thus you will be able to check permissions inside subscribe and publish handlers.\\n* Create `Message` model to display chat history in `Room`.\\n* Replace Django devserver with something more suitable for production like [Gunicorn](https://gunicorn.org/).\\n* Check out Centrifugo possibilities like presence to display online users.\\n* Use [cent](https://github.com/centrifugal/cent) Centrifugo HTTP API library to publish something to a user on behalf of a server. In this case you can avoid using publish proxy, publish messages to Django over convinient AJAX call - and then call Centrifugo HTTP API to publish message into a channel.\\n* You can replace connect proxy (which is an HTTP call from Centrifugo to Django on each connect) with JWT authentication. JWT authentication may result in a better application performance (since no additional proxy requests will be issued on connect). It can allow your Django app to handle millions of users on a reasonably small hardware and survive mass reconnects from all those users. More details can be found in [Scaling WebSocket in Go and beyond](https://centrifugal.dev/blog/2020/11/12/scaling-websocket) blog post.\\n* Instead of using subscribe proxy you can put channel into connect proxy result or into JWT \u2013 thus using [server-side subscriptions](/docs/server/server_subs) and avoid subscribe proxy HTTP call.\\n\\nOne more thing I\'d like to note is that if you aim to build a chat application like WhatsApp or Telegram where you have a screen with list of chats (which can be pretty long!) you should not create a separate channel for each room. In this case using separate channel per room does not scale well and you better use personal channel for each user to receive all user-related messages. And as soon as message published to a chat you can send message to each participant\'s channel. In this case, take a look at Centrifugo [broadcast API](/docs/server/server_api#broadcast).\\n\\n## Tutorial source code with docker-compose\\n\\nThe full example which can run by issuing a single `docker compose up` [can be found on Github](https://github.com/centrifugal/examples/tree/master/v3/python_django_chat_tutorial). It also has some CSS styles so that the chat looks like shown in the beginning.\\n\\n## Conclusion\\n\\nHere we implemented a basic chat app with Django and Centrifugo.\\n\\nWhile a chat still requires work to be suitable for production this example can help understand core concepts of Centrifugo - specifically channel namespaces and proxy features.\\n\\nIt\'s possible to use unidirectional Centrifugo transports instead of bidirectional WebSocket used here \u2013 in this case, you can go without using `centrifuge-js` at all.\\n\\nCentrifugo scales perfectly if you need to handle more connections \u2013 thanks to Centrifugo built-in PUB/SUB engines.\\n\\nIt\'s also possible to use server-side subscriptions, keep channel history cache, use JWT authentication instead of connect proxy, enable channel presence, and more. All the power of Centrifugo is in your hands.\\n\\nHope you enjoyed this tutorial. And let the Centrifugal force be with you!\\n\\nJoin our [community channels](/docs/getting-started/introduction#join-community) in case of any questions left after reading this."},{"id":"/2021/10/18/integrating-with-nodejs","metadata":{"permalink":"/blog/2021/10/18/integrating-with-nodejs","editUrl":"https://github.com/centrifugal/centrifugal.dev/edit/main/blog/2021-10-18-integrating-with-nodejs.md","source":"@site/blog/2021-10-18-integrating-with-nodejs.md","title":"Centrifugo integration with NodeJS tutorial","description":"In this tutorial we are integrating Centrifugo with NodeJS. We are using Centrifugo connect proxy feature to authenticate connections over standard Express.js session middleware.","date":"2021-10-18T00:00:00.000Z","formattedDate":"October 18, 2021","tags":[{"label":"centrifugo","permalink":"/blog/tags/centrifugo"},{"label":"tutorial","permalink":"/blog/tags/tutorial"},{"label":"proxy","permalink":"/blog/tags/proxy"}],"readingTime":6.475,"hasTruncateMarker":true,"authors":[{"name":"Alexander Emelin","title":"Creator of Centrifugo","imageURL":"https://github.com/FZambia.png"}],"frontMatter":{"title":"Centrifugo integration with NodeJS tutorial","tags":["centrifugo","tutorial","proxy"],"description":"In this tutorial we are integrating Centrifugo with NodeJS. We are using Centrifugo connect proxy feature to authenticate connections over standard Express.js session middleware.","author":"Alexander Emelin","authorTitle":"Creator of Centrifugo","authorImageURL":"https://github.com/FZambia.png","image":"/img/keyboard.png","hide_table_of_contents":false},"prevItem":{"title":"Centrifugo integration with Django \u2013 building a basic chat application","permalink":"/blog/2021/11/04/integrating-with-django-building-chat-application"},"nextItem":{"title":"Centrifugo v3 released","permalink":"/blog/2021/08/31/hello-centrifugo-v3"}},"content":"![Centrifuge](/img/keyboard.png)\\n\\nCentrifugo is a scalable real-time messaging server in a language-agnostic way. In this tutorial we will integrate Centrifugo with NodeJS backend using a connect proxy feature of Centrifugo for user authentication and native session middleware of ExpressJS framework.\\n\\nWhy would NodeJS developers want to integrate a project with Centrifugo? This is a good question especially since there are lots of various tools for real-time messaging available in NodeJS ecosystem.\\n\\n\x3c!--truncate--\x3e\\n\\nI found several points which could be a good motivation:\\n\\n* Centrifugo scales well \u2013 we have a very optimized Redis Engine with client-side sharding and Redis Cluster support. We can also scale with KeyDB, Nats, or Tarantool. Centrifugo can scale to millions connections distributed over different server nodes.\\n* Centrifugo is pretty fast (written in Go) and can handle thousands of clients per node. Client protocol is optimized for thousands of messages per second.\\n* Centrifugo provides a variety of features out-of-the-box \u2013 some of them are unique, especially for real-time servers that scale to many nodes.\\n* Centrifugo works as a separate service \u2013 so can be a universal tool in developer\'s pocket, can migrate from one project to another, no matter what programming language or framework is used for a business logic.\\n\\nHaving said this all \u2013 let\'s move to a tutorial itself.\\n\\n## What we are building\\n\\nNot a super-cool app to be honest. Our goal here is to give a reader an idea how integration with Centrifugo could look like. There are many possible apps which could be built on top of this knowledge.\\n\\nThe end result here will allow application user to authenticate and once authenticated \u2013 connect to Centrifugo. Centrifugo will proxy connection requests to NodeJS backend and native ExpressJS session middleware will be used for connection authentication. We will also send some periodical real-time messages to a user personal channel.\\n\\nThe [full source code of this tutorial](https://github.com/centrifugal/examples/tree/master/v3/nodejs_proxy) located on Github. You can clone examples repo and run this demo by simply writing:\\n\\n```bash\\ndocker compose up\\n```\\n\\n## Creating Express.js app\\n\\nStart new NodeJS app:\\n\\n```bash\\nnpm init\\n```\\n\\nInstall dependencies:\\n\\n```bash\\nnpm install express express-session cookie-parser axios morgan\\n```\\n\\nCreate `index.js` file.\\n\\n```javascript title=\\"index.js\\"\\nconst express = require(\'express\');\\nconst cookieParser = require(\\"cookie-parser\\");\\nconst sessions = require(\'express-session\');\\nconst morgan = require(\'morgan\');\\nconst axios = require(\'axios\');\\n\\nconst app = express();\\nconst port = 3000;\\napp.use(express.json());\\n\\nconst oneDay = 1000 * 60 * 60 * 24;\\n\\napp.use(sessions({\\n  secret: \\"this_is_my_secret_key\\",\\n  saveUninitialized: true,\\n  cookie: { maxAge: oneDay },\\n  resave: false\\n}));\\napp.use(cookieParser());\\napp.use(express.urlencoded({ extended: true }))\\napp.use(express.json())\\napp.use(express.static(\'static\'));\\napp.use(morgan(\'dev\'));\\n\\napp.get(\'/\', (req, res) => {\\n  if (req.session.userid) {\\n    res.sendFile(\'views/app.html\', { root: __dirname });\\n  } else\\n    res.sendFile(\'views/login.html\', { root: __dirname })\\n});\\n\\napp.listen(port, () => {\\n  console.log(`Example app listening at http://localhost:${port}`);\\n});\\n```\\n\\nCreate `login.html` file in `views` folder:\\n\\n```html title=\\"views/login.html\\"\\n<html>\\n\\n<body>\\n    <form action=\\"/login\\" method=\\"post\\">\\n        <h2>Login (username: demo-user, password: demo-pass)</h2>\\n        <div class=\\"input-field\\">\\n            <input type=\\"text\\" name=\\"username\\" id=\\"username\\" placeholder=\\"Enter Username\\">\\n        </div>\\n        <div class=\\"input-field\\">\\n            <input type=\\"password\\" name=\\"password\\" id=\\"password\\" placeholder=\\"Enter Password\\">\\n        </div>\\n        <input type=\\"submit\\" value=\\"Log in\\">\\n    </form>\\n</body>\\n\\n</html>\\n```\\n\\nAlso create `app.html` file in `views` folder:\\n\\n```html title=\\"views/app.html\\"\\n<html>\\n\\n<head>\\n  <link rel=\\"stylesheet\\" href=\\"app.css\\">\\n  <script src=\\"https://cdn.jsdelivr.net/gh/centrifugal/centrifuge-js@2.8.3/dist/centrifuge.min.js\\"><\/script>\\n</head>\\n\\n<body>\\n  <div>\\n    <a href=\'/logout\'>Click to logout</a>\\n  </div>\\n  <div id=\\"log\\"></div>\\n</body>\\n\\n</html>\\n```\\n\\nMake attention that we import `centrifuge-js` client here which abstracts away Centrifugo bidirectional WebSocket protocol.\\n\\nLet\'s write an HTTP handler for login form:\\n\\n```javascript title=\\"index.js\\"\\nconst myusername = \'demo-user\'\\nconst mypassword = \'demo-pass\'\\n\\napp.post(\'/login\', (req, res) => {\\n  if (req.body.username == myusername && req.body.password == mypassword) {\\n    req.session.userid = req.body.username;\\n    res.redirect(\'/\');\\n  } else {\\n    res.send(\'Invalid username or password\');\\n  }\\n});\\n```\\n\\nIn this example we use hardcoded username and password for out single user. Of course in real app you will have a database with user credentials. But since our goal is only show integration with Centrifugo \u2013 we are skipping these hard parts here.\\n\\nAlso create a handler for a logout request:\\n\\n```javascript title=\\"index.js\\"\\napp.get(\'/logout\', (req, res) => {\\n  req.session.destroy();\\n  res.redirect(\'/\');\\n});\\n```\\n\\nNow if you run an app with `node index.js` you will see a login form using which you can authenticate. At this point this is a mostly convenient NodeJS application, let\'s add Centrifugo integration. \\n\\n## Starting Centrifugo\\n\\nRun Centrifugo with `config.json` like this:\\n\\n```json title=\\"config.json\\"\\n{\\n  \\"token_hmac_secret_key\\": \\"secret\\",\\n  \\"admin\\": true,\\n  \\"admin_password\\": \\"password\\",\\n  \\"admin_secret\\": \\"my_admin_secret\\",\\n  \\"api_key\\": \\"my_api_key\\",\\n  \\"allowed_origins\\": [\\n    \\"http://localhost:9000\\"\\n  ],\\n  \\"user_subscribe_to_personal\\": true,\\n  \\"proxy_connect_endpoint\\": \\"http://localhost:3000/centrifugo/connect\\",\\n  \\"proxy_http_headers\\": [\\n    \\"Cookie\\"\\n  ]\\n}\\n```\\n\\nI.e.:\\n\\n```\\n./centrifugo -c config.json\\n```\\n\\nCreate `app.js` file in `static` folder:\\n\\n```javascript title=\\"static/app.js\\"\\nfunction drawText(text) {\\n    const div = document.createElement(\'div\');\\n    div.innerHTML = text;\\n    document.getElementById(\'log\').appendChild(div);\\n}\\n\\nconst centrifuge = new Centrifuge(\'ws://localhost:9000/connection/websocket\');\\n\\ncentrifuge.on(\'connect\', function () {\\n    drawText(\'Connected to Centrifugo\');\\n});\\n\\ncentrifuge.on(\'disconnect\', function () {\\n    drawText(\'Disconnected from Centrifugo\');\\n});\\n\\ncentrifuge.on(\'publish\', function (ctx) {\\n    drawText(\'Publication, time = \' + ctx.data.time);\\n});\\n\\ncentrifuge.connect();\\n```\\n\\n## Adding Nginx\\n\\nSince we are going to use native session auth of ExpressJS we can\'t just connect from localhost:3000 (where our NodeJS app is served) to Centrifugo running on localhost:8000 \u2013 browser won\'t send a `Cookie` header to Centrifugo in this case. Due to this reason we need a reverse proxy which will terminate a traffic from frontend and proxy requests to NodeJS process or to Centrifugo depending on URL path. In this case both browser and NodeJS app will share the same origin \u2013 so Cookie will be sent to Centrifugo in WebSocket Upgrade request.\\n\\n:::tip\\n\\nAlternatively, we could also use [JWT authentication](/docs/server/authentication) of Centrifugo but that\'s a topic for another tutorial. Here we are using [connect proxy feature](/docs/server/proxy#connect-proxy) for auth. \\n\\n:::\\n\\nNginx config will look like this:\\n\\n```\\nserver {\\n  listen 9000;\\n\\n  server_name localhost;\\n\\n  location / {\\n    proxy_pass http://localhost:3000;\\n    proxy_http_version 1.1;\\n    proxy_set_header Host $host;\\n    proxy_set_header X-Real-IP $remote_addr;\\n    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\\n    proxy_set_header X-Forwarded-Proto $scheme;\\n  }\\n\\n  location /connection {\\n    proxy_pass http://localhost:8000;\\n    proxy_http_version 1.1;\\n    proxy_set_header Upgrade $http_upgrade;\\n    proxy_set_header Connection \'upgrade\';\\n    proxy_set_header Host $host;\\n    proxy_set_header X-Real-IP $remote_addr;\\n    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\\n    proxy_set_header X-Forwarded-Proto $scheme;\\n    proxy_cache_bypass $http_upgrade;\\n  }\\n}\\n```\\n\\nRun Nginx and open [http://localhost:9000](http://localhost:9000). After authenticating in app you should see an attempt to connect to a WebSocket endpoint. But connection will fail since we need to implement connect proxy handler in NodeJS app.\\n\\n```javascript title=\\"index.js\\"\\napp.post(\'/centrifugo/connect\', (req, res) => {\\n  if (req.session.userid) {\\n    res.json({\\n      result: {\\n        user: req.session.userid\\n      }\\n    });\\n  } else\\n    res.json({\\n      disconnect: {\\n        code: 1000,\\n        reason: \\"unauthorized\\",\\n        reconnect: false\\n      }\\n    });\\n});\\n```\\n\\nRestart NodeJS process and try opening an app again. Application should now successfully connect to Centrifugo.\\n\\n## Send real-time messages\\n\\nLet\'s also periodically publish current server time to a client\'s personal channel. In Centrifugo configuration we set a `user_subscribe_to_personal` option which turns on [automatic subscription to a personal channel](/docs/server/server_subs#automatic-personal-channel-subscription) for each connected user. We can use `axios` library and send publish API requests to Centrifugo periodically (according to [API docs](/docs/server/server_api#http-api)): \\n\\n```javascript title=\\"index.js\\"\\nconst centrifugoApiClient = axios.create({\\n  baseURL: `http://centrifugo:8000/api`,\\n  headers: {\\n    Authorization: `apikey my_api_key`,\\n    \'Content-Type\': \'application/json\',\\n  },\\n});\\n\\nsetInterval(async () => {\\n  try {\\n    await centrifugoApiClient.post(\'\', {\\n      method: \'publish\',\\n      params: {\\n        channel: \'#\' + myusername, // construct personal channel name.\\n        data: {\\n          time: Math.floor(new Date().getTime() / 1000),\\n        },\\n      },\\n    });\\n  } catch (e) {\\n    console.error(e.message);\\n  }\\n}, 5000);\\n```\\n\\nAfter restarting NodeJS you should see periodical updates on application web page.\\n\\nYou can also log in into Centrifugo admin web UI [http://localhost:8000](http://localhost:8000) using password `password` - and play with other available server API from within web interface.\\n\\n## Conclusion\\n\\nWhile not being super useful this example can help understanding core concepts of Centrifugo - specifically connect proxy feature and server API.\\n\\nIt\'s possible to use unidirectional Centrifugo transports instead of bidrectional WebSocket used here \u2013 in this case you can go without using `centrifuge-js` at all.\\n\\nThis application scales perfectly if you need to handle more connections \u2013 thanks to Centrifugo builtin PUB/SUB engines.\\n\\nIt\'s also possible to use client-side subscriptions, keep channel history cache, enable channel presence and more. All the power of Centrifugo is in your hands."},{"id":"/2021/08/31/hello-centrifugo-v3","metadata":{"permalink":"/blog/2021/08/31/hello-centrifugo-v3","editUrl":"https://github.com/centrifugal/centrifugal.dev/edit/main/blog/2021-08-31-hello-centrifugo-v3.md","source":"@site/blog/2021-08-31-hello-centrifugo-v3.md","title":"Centrifugo v3 released","description":"Centrifugo v3 released with lots of exciting improvements","date":"2021-08-31T00:00:00.000Z","formattedDate":"August 31, 2021","tags":[{"label":"centrifugo","permalink":"/blog/tags/centrifugo"},{"label":"release","permalink":"/blog/tags/release"}],"readingTime":14.055,"hasTruncateMarker":true,"authors":[{"name":"Centrifugal team","title":"Let the Centrifugal force be with you","imageURL":"/img/logo_animated.svg"}],"frontMatter":{"title":"Centrifugo v3 released","tags":["centrifugo","release"],"description":"Centrifugo v3 released with lots of exciting improvements","author":"Centrifugal team","authorTitle":"Let the Centrifugal force be with you","authorImageURL":"/img/logo_animated.svg","image":"/img/v3_blog.jpg","hide_table_of_contents":false},"prevItem":{"title":"Centrifugo integration with NodeJS tutorial","permalink":"/blog/2021/10/18/integrating-with-nodejs"},"nextItem":{"title":"Centrifuge \u2013 real-time messaging with Go","permalink":"/blog/2021/01/15/centrifuge-intro"}},"content":"![Centrifuge](/img/v3_blog.jpg)\\n\\nAfter almost three years of Centrifugo v2 life cycle we are happy to announce the next major release of Centrifugo. During the last several months deep in our Centrifugal laboratory we had been synthesizing an improved version of the server.\\n\\nNew Centrifugo v3 is targeting to improve Centrifugo adoption for basic real-time application cases, improves server performance and extends existing features with new functionality. It comes with unidirectional real-time transports, protocol speedups, super-fast engine implementation based on Tarantool, new documentation site, GRPC proxy, API extensions and PRO version which provides unique possibilities for business adopters.\\n\\n\x3c!--truncate--\x3e\\n\\n### Centrifugo v2 flashbacks\\n\\nCentrifugo v2 life cycle has come to an end. Before discussing v3 let\'s look back at what has been done during the last three years.\\n\\nCentrifugo v2 was a pretty huge refactoring of v1. Since the v2 release, Centrifugo is built on top of  new [Centrifuge library](https://github.com/centrifugal/centrifuge) for Go language. Centrifuge library evolved significantly since its initial release and now powers Grafana v8 real-time streaming among other things.\\n\\nHere is an awesome demo made by my colleague <a href=\\"https://github.com/alexanderzobnin\\">Alexander Zobnin</a> that demonstrates real-time telemetry of Assetto Corsa sports car streamed in real-time to Grafana dashboard: \\n\\n<div class=\\"vimeo-full-width\\">\\n   <iframe src=\\"https://player.vimeo.com/video/570333329?title=0&byline=0&portrait=0\\" frameborder=\\"0\\" allow=\\"autoplay; fullscreen\\" allowfullscreen></iframe>\\n</div>\\n<p></p>\\n\\nCentrifugo integrated with Redis Streams, got Redis Cluster support, can now work with Nats server as a PUB/SUB broker. Notable additions of Centrifugo v2 were [server-side subscriptions](/docs/server/server_subs) with some interesting features on top \u2013 like maintaining a single global connection from one user and automatic personal channel subscription upon user connect.\\n\\nA very good addition which increased Centrifugo adoption a lot was introduction of [proxy to backend](/docs/server/proxy). This made Centrifugo fit many setups where JWT authentication and existing subscription permission model did not suit well before.\\n\\nClient ecosystem improved significantly. The fact that client protocol migrated to a strict Protobuf schema allowed to introduce binary protocol format (in addition to JSON) and simplify building client connectors. We now have much better and complete client libraries (compared to v1 situation).\\n\\nWe also have an [official Helm chart](https://github.com/centrifugal/helm-charts), [Grafana dashboard](https://grafana.com/grafana/dashboards/13039) for Prometheus datasource, and so on.\\n\\n![](https://grafana.com/api/dashboards/13039/images/8950/image)\\n\\nCentrifugo is becoming more noticeable in a wider real-time technology community. For example, it was included in a [periodic table of real-time](https://ably.com/periodic-table-of-realtime) created by Ably.com (one of the most powerful real-time messaging cloud services at the moment):\\n\\n![](https://ik.imagekit.io/ably/ghost/prod/2021/08/periodic-table-screenshots-combined-without-banner-no-legend.jpg?tr=w-1520)\\n\\nOf course, there are many aspects where Centrifugo can be improved. And v3 addresses some of them. Below we will look at the most notable features and changes of the new major Centrifugo version.\\n\\n### Backwards compatibility\\n\\nLet\'s start with the most important thing \u2013 backwards compatibility concerns.\\n\\nIn Centrifugo v3 client protocol mostly stayed the same. We expect that most applications will be able to update without any change on a client-side. This was an important concern for v3 given how painful the update cycle can be on mobile devices and lessons learned from v1 to v2 migration. There is one breaking change though which can affect users who use history API manually from a client-side (we provide a temporary workaround to give apps a chance to migrate smoothly).\\n\\nOn a server-side, much more changes happened, especially in the configuration: some options were renamed, some were removed. We provide a [v2 to v3 configuration converter](/docs/3/getting-started/migration_v3#v2-to-v3-config-converter) which can help dealing with changes. In most cases, all you should do is adapt Centrifugo configuration to match v3 changes and redeploy Centrifugo using v3 build instead of v2. All features are still there (or a replacement exists, like for `channels` API).\\n\\nFor more details, refer to the [v3 migration guide](/docs/3/getting-started/migration_v3).\\n\\n### License change\\n\\nAs some of you know we considered changing Centrifugo license to AGPL v3 for a new release. After thinking a lot about this we decided to not step into this area.\\n\\nBut the license has been changed: the license of OSS Centrifugo is now Apache 2.0 instead of MIT. Apache 2.0 is also a permissive OSS license, it\'s just a bit more concrete in some aspects.\\n\\n![](https://user-images.githubusercontent.com/2097922/91162089-8570e100-e6c3-11ea-8c41-cd8fcfe049d0.png)\\n\\n### Unidirectional real-time transports\\n\\nServer-side subscriptions introduced in Centrifugo v2 and recent improvements in the underlying Centrifuge library opened a road for a unidirectional approach.\\n\\nThis means that Centrifugo v3 provides a set of unidirectional real-time transports where messages flow only in one direction \u2013 from a server to a client. Why is this change important?\\n\\nCentrifugo originally concentrated on using bidirectional transports for client-server communication. Like WebSocket and SockJS. Bidirectional transports allow implementing some great protocol features since a client can communicate with a server in various ways after establishing a persistent connection. While this is a great opportunity this also leads to an increased complexity.\\n\\nCentrifugo users had to use special client connector libraries which abstracted underlying work into a simple public API. But internally connectors do many things: matching requests to responses, handling timeouts, handling an ordering, queuing operations, error handling. So the client connector is a pretty complex piece of software.\\n\\nBut what if a user just needs to receive real-time updates from a stable set of channels known in connection time? Can we simplify everything and avoid using custom software on a client-side?\\n\\nWith unidirectional transports, the answer is yes. Clients can now connect to Centrifugo using a bunch of unidirectional transports. And the greatest thing is that in this case, developers should not depend on Centrifugo client connectors at all \u2013 just use native browser APIs or GRPC-generated code. It\'s finally possible to consume events from Centrifugo using CURL (see [an example](/docs/transports/uni_http_stream#connecting-using-curl)).\\n\\nUsing unidirectional transports you can still benefit from Centrifugo built-in scalability with various engines, utilize built-in authentication over JWT or the connect proxy feature.\\n\\nWith subscribe server API (see below) it\'s even possible to subscribe unidirectional client to server-side channels dynamically. With refresh server API or the refresh proxy feature it\'s possible to manage a connection expiration.\\n\\nCentrifugo supports the following unidirectional transports:\\n\\n* [EventSource (SSE)](/docs/transports/uni_sse)\\n* [HTTP streaming](/docs/transports/uni_http_stream)\\n* [Unidirectional WebSocket](/docs/transports/uni_websocket)\\n* [Unidirectional GRPC stream](/docs/transports/uni_grpc)\\n\\nWe expect that introducing unidirectional transports will significantly increase Centrifugo adoption.\\n\\n### History iteration API\\n\\n<img src=\\"/img/centrifuge.svg\\" align=\\"right\\" width=\\"25%\\" />\\n\\nThere was a rather important limitation of Centrifugo history API \u2013 it was not very suitable for keeping large streams because a call to a history could only return the entire channel history.\\n\\nCentrifugo v3 introduces an API to iterate over a stream. It\'s possible to do from the current stream beginning or end, in both directions \u2013 forward and backward, with configured limit. Also with certain starting stream position if it\'s known.\\n\\nThis, among other things, can help to implement manual missed message recovery on a client-side to reduce the load on the application backend.\\n\\nHere is an example program in Go which endlessly iterates over stream both ends (using [gocent](https://github.com/centrifugal/gocent) API library), upon reaching the end of stream the iteration goes in reversed direction (not really useful in real world but fun): \\n\\n```go\\n// Iterate by 10.\\nlimit := 10\\n// Paginate in reversed order first, then invert it.\\nreverse := true\\n// Start with nil StreamPosition, then fill it with value while paginating.\\nvar sp *gocent.StreamPosition\\n\\nfor {\\n\\thistoryResult, err = c.History(\\n        ctx,\\n        channel,\\n\\t\\tgocent.WithLimit(limit),\\n\\t\\tgocent.WithReverse(reverse),\\n        gocent.WithSince(sp),\\n\\t)\\n\\tif err != nil {\\n\\t\\tlog.Fatalf(\\"Error calling history: %v\\", err)\\n\\t}\\n\\tfor _, pub := range historyResult.Publications {\\n\\t\\tlog.Println(pub.Offset, \\"=>\\", string(pub.Data))\\n\\t\\tsp = &gocent.StreamPosition{\\n\\t\\t\\tOffset: pub.Offset,\\n\\t\\t\\tEpoch:  historyResult.Epoch,\\n\\t\\t}\\n\\t}\\n\\tif len(historyResult.Publications) < limit {\\n\\t\\t// Got all pubs, invert pagination direction.\\n\\t\\treverse = !reverse\\n\\t\\tlog.Println(\\"end of stream reached, change iteration direction\\")\\n\\t}\\n}\\n```\\n\\n:::caution\\n\\nThis new API does not remove the need in having the main application database \u2013 that\'s still mandatory for idiomatic Centrifugo usage.\\n\\n:::\\n\\n### Redis Streams by default\\n\\nIn Centrifugo v3 Redis engine uses Redis Stream data structure by default for keeping channel history. Before v3 Redis Streams were supported by not enabled by default so almost nobody used them. This change is important in terms of introducing history iteration API described above \u2013 since Redis Streams allow doing iteration effectively. \\n\\n### Tarantool engine\\n\\nAs you may know, Centrifugo has several built-in engines that allow scaling Centrifugo nodes (using PUB/SUB) and keep shared history and presence state. Before v3 Centrifugo had in-memory and Redis (or KeyDB) engines available.\\n\\nIntroducing a new engine to Centrifugo is pretty hard since the engine should provide a very robust PUB/SUB performance, fast history and presence operations, possibility to publish a message to PUB/SUB and save to history atomically. It also should allow dealing with ephemeral frequently changing subscriptions. It\'s typical for Centrifugo use case to have millions of users each subscribed to a  unique channel and constantly connecting/disconnecting (thus subscribing/unsubscribing).\\n\\n![](https://www.tadviser.ru/images/thumb/1/1a/Tarantool_%D0%A1%D0%A3%D0%91%D0%94_logo_2020.png/840px-Tarantool_%D0%A1%D0%A3%D0%91%D0%94_logo_2020.png)\\n\\nIn v3 we added **experimental** support for the [Tarantool](https://www.tarantool.io/en/) engine. It fits nicely all the requirements above and provides a huge performance speedup for history and presence operations compared to Redis. According to our benchmarks, the speedup can be up to 4-10x depending on operation. The PUB/SUB performance of Tarantool is comparable with Redis (10-20% worse according to our internal benchmarks to be exact, but that\'s pretty much the same).\\n\\nFor example, let\'s look at Centrifugo benchmark where we recover zero messages (i.e. emulate a situations when many connections disconnected for a very short time interval due to load balancer reload).\\n\\nFor Redis engine:\\n\\n```bash title=\\"Redis engine, single Redis instance\\"\\nBenchmarkRedisRecover       26883 ns/op\\t    1204 B/op\\t   28 allocs/op\\n```\\n\\nCompare it with the same operation measured with Tarantool engine:\\n\\n```bash title=\\"Tarantool engine, single Tarantool instance\\"\\nBenchmarkTarantoolRecover    6292 ns/op\\t     563 B/op\\t   10 allocs/op\\n```\\n\\nTarantool can provide new storage properties (like synchronous replication), new adoption. We are pretty excited about adding it as an option.\\n\\nThe reason why Tarantool support is experimental is because Tarantool integration involves one more moving piece \u2013 the [Centrifuge Lua module](https://github.com/centrifugal/tarantool-centrifuge) which should be run by a Tarantool server.\\n\\nThis increases deployment complexity and given the fact that many users have their own best practices in Tarantool deployment we are still evaluating a sufficient way to distribute Lua part. For now, we are targeting standalone (see examples in [centrifugal/tarantool-centrifuge](https://github.com/centrifugal/tarantool-centrifuge)) and Cartridge Tarantool setups (with [centrifugal/rotor](https://github.com/centrifugal/rotor)).\\n\\nRefer to the [Tarantool Engine documentation](/docs/server/engines#tarantool-engine) for more details.\\n\\n### GRPC proxy\\n\\nCentrifugo can now transform events received over persistent connections from users into GRPC calls to the application backend (in addition to the HTTP proxy available in v2).\\n\\nGRPC support should make Centrifugo ready for today\'s microservice architecture where GRPC is a huge player for inter-service communication.\\n\\nSo we mostly just provide more choices for Centrifugo users here. GRPC has some good advantages \u2013 for example an application backend RPC layer which is responsible for communication with Centrifugo can now be generated from Protobuf definitions for all popular programming languages.\\n\\n### Server API improvements\\n\\n<img src=\\"/img/test-tube.svg\\" align=\\"right\\" width=\\"25%\\" />\\n\\nCentrifugo v3 has some valuable server API improvements.\\n\\nThe new `subscribe` API method allows subscribing connection to a channel at any point in time. This works by utilizing server-side subscriptions. So it\'s not only possible to subscribe connection to a list of server-side channels during the connection establishment phase \u2013 but also later during the connection lifetime. This may be very useful for the unidirectional approach - by emulating client-side subscribe call over request to application backend which in turn calls subscribe Centrifugo server API.\\n\\nPublish API now returns the current top stream position (offset and epoch) for channels with history enabled.\\n\\nServer history API inherited iteration possibilities described above.\\n\\nChannels command now returns a number of clients in a channel, also supports channel filtering by a pattern. Since we changed how channels call implemented internally there is no limitation anymore to call it when using Redis cluster.\\n\\nAdmin web UI has been updated too to support new API methods, so you can play with new API from its `actions` tab.\\n\\n### Better clustering\\n\\nCentrifugo behaves a bit better in cluster mode: as soon as a node leaves a cluster gracefully (upon graceful termination) it sends a shutdown signal to the control channel thus giving other nodes a chance to immediately delete that node from the local registry.\\n\\n### Client improvements\\n\\nWhile preparing the v3 release we improved client connectors too. All existing client connectors now actualized to the latest protocol, support server-side subscriptions, history API.\\n\\nOne important detail is that it\'s not required to set `?format=protobuf` URL param now when connecting to Centrifugo from mobile devices - this is now managed internally by using the WebSocket subprotocol mechanism (requires using the latest client connector version and Centrifugo v3).\\n\\n### New documentation site\\n\\nYou are reading this post on a new project site. It\'s built with amazing [Docusaurus](https://docusaurus.io/).\\n\\nA lot of documents were actualized, extended, and rewritten. We also now have new chapters like:\\n\\n* [Main highlights](/docs/getting-started/highlights)\\n* [Design overview](/docs/getting-started/design)\\n* [History and recovery](/docs/server/history_and_recovery)\\n* [Error and disconnect codes](/docs/server/codes).\\n\\nServer API and proxy documentation have been improved significantly.\\n\\n### Performance improvements\\n\\n<img src=\\"/img/stopwatch.svg\\" align=\\"right\\" width=\\"25%\\" />\\n\\nCentrifugo v3 has some notable performance improvements.\\n\\nJSON client protocol now utilizes a couple of libraries (`easyjson` for encoding and `segmentio/encoding` for unmarshaling). Actually we use a slightly customized version of `easyjson` library to achieve even faster performance than it provides out-of-the-box. Changes allowed to speed up JSON encoding and decoding up to 4-5x for small messages. For large payloads speed up can be even more noticeable \u2013 we observed up to 30x performance boost when serializing 5kb messages.\\n\\nFor example, let\'s look at a JSON serialization benchmark result for 256 byte payload. Here is what we had before:\\n\\n```bash title=\\"Centrifugo v2 JSON encoding/decoding\\"\\ncpu: Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz\\nBenchmarkMarshal-12              \\t 5883 ns/op\\t    1121 B/op\\t    6 allocs/op\\nBenchmarkMarshalParallel-12      \\t 1009 ns/op\\t    1121 B/op\\t    6 allocs/op\\nBenchmarkUnmarshal-12            \\t 1717 ns/op\\t    1328 B/op\\t   16 allocs/op\\nBenchmarkUnmarshalParallel-12    \\t492.2 ns/op\\t    1328 B/op\\t   16 allocs/op\\n```\\n\\nAnd what we have now with mentioned JSON optimizations:\\n\\n```bash title=\\"Centrifugo v3 JSON encoding/decoding\\"\\ncpu: Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz\\nBenchmarkMarshal-12              \\t 461.3 ns/op\\t 928 B/op\\t    3 allocs/op\\nBenchmarkMarshalParallel-12      \\t 250.6 ns/op\\t 928 B/op\\t    3 allocs/op\\nBenchmarkUnmarshal-12            \\t 476.5 ns/op\\t 136 B/op\\t    3 allocs/op\\nBenchmarkUnmarshalParallel-12    \\t 107.2 ns/op\\t 136 B/op\\t    3 allocs/op\\n```\\n\\n:::tip\\n\\nCentrifugo Protobuf protocol is still faster than JSON for encoding/decoding on a server-side.\\n\\n:::\\n\\nOf course, JSON encoding is only one part of Centrifugo \u2013 so you should not expect overall 4x performance improvement. But loaded setups should notice the difference and this should also be a good thing for reducing garbage collection pauses.\\n\\nCentrifugo inherited a couple of other improvements from the Centrifuge library.\\n\\nIn-memory connection hub is now sharded \u2013 this should reduce lock contention between operations in different channels. In [our artificial benchmarks](https://github.com/centrifugal/centrifuge/pull/184) we noticed a 3x better hub throughput, but in reality the benefit is heavily depends on the usage pattern.\\n\\nCentrifugo now allocates less during message broadcasting to a large number of subscribers.\\n\\nAlso, an upgrade to Go 1.17 for builds results in ~5% performance boost overall, thanks to a new way of passing function arguments and results using registers instead of the stack introduced in Go 1.17.\\n\\n### Centrifugo PRO\\n\\nThe final notable thing is an introduction of Centrifugo PRO. This is an extended version of Centrifugo built on top of the OSS version. It provides some unique features targeting business adopters.\\n\\nThose who followed Centrifugo for a long time know that there were some attempts to make project development sustainable. Buy me a coffee and Opencollective approaches were not successful, during a year we got ~300$ of total contributions. While we appreciate these contributions a lot - this does not fairly justify a time spent on Centrifugo maintenance these days and does not allow bringing it to the next level. So here is an another attempt to monetize Centrifugo.\\n\\nCentrifugo PRO details and features described [here in docs](/docs/pro/overview). Let\'s see how it goes. We believe that a set of additional functionality can provide great advantages for both small and large-scale Centrifugo setups. PRO features can give useful insights on a system, protect from client API misusing, reduce server resource usage, and more.\\n\\nPRO version will be released soon after Centrifugo v3 OSS.\\n\\n### Conclusion\\n\\nThere are some other changes introduced in v3 but not mentioned here. The full list can be found in the release notes and the migration guide.\\n\\nHope we stepped into an exciting time of the v3 life cycle and many improvements will follow. Join our communities in Telegram and Discord if you have questions or want to follow Centrifugo development:\\n\\n[![Join the chat at https://t.me/joinchat/ABFVWBE0AhkyyhREoaboXQ](https://img.shields.io/badge/Telegram-Group-orange?style=flat&logo=telegram)](https://t.me/joinchat/ABFVWBE0AhkyyhREoaboXQ) &nbsp;[![Join the chat at https://discord.gg/tYgADKx](https://img.shields.io/discord/719186998686122046?style=flat&label=Discord&logo=discord)](https://discord.gg/tYgADKx)\\n\\nEnjoy Centrifugo v3, and let the Centrifugal force be with you.\\n\\n:::note Special thanks\\n\\nSpecial thanks to [Anton Silischev](https://github.com/silischev) for the help with v3 tests, examples and CI. To [Leon Sorokin](https://github.com/leeoniya) for the spinning CSS Centrifugo logo. To [Michael Filonenko](https://github.com/filonenko-mikhail) for the help with Tarantool. To [German Saprykin](https://github.com/mogol) for Dart magic.\\n\\nThanks to the community members who tested out Centrifugo v3 beta, found bugs and sent improvements.\\n\\n<div>Icons used here made by <a href=\\"https://www.flaticon.com/authors/wanicon\\" title=\\"wanicon\\">wanicon</a> from <a href=\\"https://www.flaticon.com/\\" title=\\"Flaticon\\">www.flaticon.com</a></div>\\n\\n:::"},{"id":"/2021/01/15/centrifuge-intro","metadata":{"permalink":"/blog/2021/01/15/centrifuge-intro","editUrl":"https://github.com/centrifugal/centrifugal.dev/edit/main/blog/2021-01-15-centrifuge-intro.md","source":"@site/blog/2021-01-15-centrifuge-intro.md","title":"Centrifuge \u2013 real-time messaging with Go","description":"An introduction to Centrifuge \u2013 real-time messaging with Go","date":"2021-01-15T00:00:00.000Z","formattedDate":"January 15, 2021","tags":[{"label":"centrifuge","permalink":"/blog/tags/centrifuge"},{"label":"go","permalink":"/blog/tags/go"}],"readingTime":22.93,"hasTruncateMarker":true,"authors":[{"name":"Alexander Emelin","title":"Creator of Centrifugo","imageURL":"https://github.com/FZambia.png"}],"frontMatter":{"title":"Centrifuge \u2013 real-time messaging with Go","tags":["centrifuge","go"],"author":"Alexander Emelin","authorTitle":"Creator of Centrifugo","authorImageURL":"https://github.com/FZambia.png","description":"An introduction to Centrifuge \u2013 real-time messaging with Go","image":"https://i.imgur.com/W1PeoJL.jpg","hide_table_of_contents":false},"prevItem":{"title":"Centrifugo v3 released","permalink":"/blog/2021/08/31/hello-centrifugo-v3"},"nextItem":{"title":"Scaling WebSocket in Go and beyond","permalink":"/blog/2020/11/12/scaling-websocket"}},"content":"![Centrifuge](https://i.imgur.com/W1PeoJL.jpg)\\n\\nIn this post I\'ll try to introduce [Centrifuge](https://github.com/centrifugal/centrifuge) - the heart of Centrifugo.\\n\\nCentrifuge is a real-time messaging library for the Go language.\\n\\nThis post is going to be pretty long (looks like I am a huge fan of long reads) \u2013 so make sure you also have a drink (probably two) and let\'s go!\\n\\n\x3c!--truncate--\x3e\\n\\n## How it\'s all started\\n\\nI wrote several blog posts before ([for example this one](https://medium.com/@fzambia/four-years-in-centrifuge-ce7a94e8b1a8) \u2013 yep, it\'s on Medium...) about an original motivation of [Centrifugo](https://github.com/centrifugal/centrifugo) server.\\n\\n:::danger\\n\\nCentrifugo server is not the same as Centrifuge library for Go. It\'s a full-featured project built on top of Centrifuge library. Naming can be confusing, but it\'s not too hard once you spend some time with ecosystem.\\n\\n:::\\n\\nIn short \u2013 Centrifugo was implemented to help traditional web frameworks dealing with many persistent connections (like WebSocket or SockJS HTTP transports). So frameworks like Django or Ruby on Rails, or frameworks from the PHP world could be used on a backend but still provide real-time messaging features like chats, multiplayer browser games, etc for users. With a little help from Centrifugo.\\n\\nNow there are cases when Centrifugo server used in conjunction even with a backend written in Go. While Go mostly has no problems dealing with many concurrent connections \u2013 Centrifugo provides some features beyond simple message passing between a client and a server. That makes it useful, especially since design is pretty non-obtrusive and fits well microservices world. Centrifugo is used in some well-known projects (like ManyChat, Yoola.io, Spot.im, Badoo etc).\\n\\nAt the end of 2018, I released Centrifugo v2 based on a real-time messaging library for Go language \u2013 Centrifuge \u2013 the subject of this post.\\n\\nIt was a pretty hard experience to decouple Centrifuge out of the monolithic Centrifugo server \u2013 I was unable to make all the things right immediately, so Centrifuge library API went through several iterations where I introduced backward-incompatible changes. All those changes targeted to make Centrifuge a more generic tool and remove opinionated or limiting parts.\\n\\n## So what is Centrifuge?\\n\\nThis is ... well, a framework to build real-time messaging applications with Go language. If you ever heard about [socket.io](https://socket.io) \u2013 then you can think about Centrifuge as an analogue. I think the most popular applications these days are chats of different forms, but I want to emphasize that Centrifuge is not a framework to build chats \u2013 it\'s a generic instrument that can be used to create different sorts of real-time applications \u2013 real-time charts, multiplayer games.\\n\\nThe obvious choice for real-time messaging transport to achieve fast and cross-platform bidirectional communication these days is WebSocket. Especially if you are targeting a browser environment. You mostly don\'t need to use WebSocket HTTP polyfills in 2021 (though there are still corner cases so Centrifuge supports [SockJS](https://github.com/sockjs/sockjs-client) polyfill).\\n\\nCentrifuge has its own custom protocol on top of plain WebSocket or SockJS frames. \\n\\nThe reason why Centrifuge has its own protocol on top of underlying transport is that it provides several useful primitives to build real-time applications. The protocol [described as strict Protobuf schema](https://github.com/centrifugal/protocol/blob/master/definitions/client.proto). It\'s possible to pass JSON or binary Protobuf-encoded data over the wire with Centrifuge.\\n\\n:::note\\n\\nGRPC is very handy these days too (and can be used in a browser with a help of additional proxies), some developers prefer using it for real-time messaging apps \u2013 especially when one-way communication needed. It can be a bit better from integration perspective but more resource-consuming on server side and a bit trickier to deploy.\\n\\n:::\\n\\n:::note\\n\\nTake a look at [WebTransport](https://w3c.github.io/webtransport/) \u2013 a brand-new spec for web browsers to allow fast communication between a client and a server on top of QUIC \u2013 it may be a good alternative to WebSocket in the future. This in a draft status at the moment, but it\'s [already possible to play with in Chrome](https://centrifugal.github.io/centrifugo/blog/quic_web_transport/).\\n\\n:::\\n\\nOwn protocol is one of the things that prove the framework status of Centrifuge. This dictates certain limits (for example, you can\'t just use an alternative message encoding) and makes developers use custom client connectors on a front-end side to communicate with a Centrifuge-based server (see more about connectors in ecosystem part).\\n\\nBut protocol solves many practical tasks \u2013 and here we are going to look at real-time features it provides for a developer.\\n\\n## Centrifuge Node\\n\\nTo start working with Centrifuge you need to start Centrifuge server Node. Node is a core of Centrifuge \u2013 it has many useful methods \u2013 set event handlers, publish messages to channels, etc. We will look at some events and channels concept very soon.\\n\\nAlso, Node abstracts away scalability aspects, so you don\'t need to think about how to scale WebSocket connections over different server instances and still have a way to deliver published messages to interested clients.\\n\\nFor now, let\'s start a single instance of Node that will serve connections for us:\\n\\n```go\\nnode, err := centrifuge.New(centrifuge.DefaultConfig)\\nif err != nil {\\n    log.Fatal(err)\\n}\\n\\nif err := node.Run(); err != nil {\\n    log.Fatal(err)\\n}\\n```\\n\\nIt\'s also required to serve a WebSocket handler \u2013 this is possible just by registering `centrifuge.WebsocketHandler` in HTTP mux:\\n\\n```go\\nwsHandler := centrifuge.NewWebsocketHandler(node, centrifuge.WebsocketConfig{})\\nhttp.Handle(\\"/connection/websocket\\", wsHandler)\\n```\\n\\nNow it\'s possible to connect to a server (using Centrifuge connector for a browser called `centrifuge-js`):\\n\\n```javascript\\nconst centrifuge = new Centrifuge(\'ws://localhost:8000/connection/websocket\');\\ncentrifuge.connect();\\n```\\n\\nThough connection will be rejected by the server since we also need to provide authentication details \u2013 Centrifuge expects explicitly provided connection `Credentials` to accept connection.\\n\\n## Authentication\\n\\nLet\'s look at how we can tell Centrifuge details about connected user identity, so it could accept an incoming connection.\\n\\nThere are two main ways to authenticate client connection in Centrifuge.\\n\\nThe first one is over the native middleware mechanism. It\'s possible to wrap `centrifuge.WebsocketHandler` or `centrifuge.SockjsHandler` with middleware that checks user authentication and tells Centrifuge current user ID over `context.Context`:\\n\\n```go\\nfunc auth(h http.Handler) http.Handler {\\n\\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\\n\\t\\tcred := &centrifuge.Credentials{\\n\\t\\t\\tUserID: \\"42\\",\\n\\t\\t}\\n\\t\\tnewCtx := centrifuge.SetCredentials(r.Context(), cred)\\n\\t\\tr = r.WithContext(newCtx)\\n\\t\\th.ServeHTTP(w, r)\\n\\t})\\n}\\n```\\n\\nSo WebsocketHandler can be registered this way (note that a handler now wrapped by auth middleware):\\n\\n```go\\nwsHandler := centrifuge.NewWebsocketHandler(node, centrifuge.WebsocketConfig{})\\nhttp.Handle(\\"/connection/websocket\\", auth(wsHandler))\\n```\\n\\nAnother authentication way is a bit more generic \u2013 developers can authenticate connection based on custom token sent from a client inside first WebSocket/SockJS frame. This is called `connect` frame in terms of Centrifuge protocol. Any string token can be set \u2013 this opens a way to use JWT, Paceto, and any other kind of authentication tokens. For example [see an authenticaton with JWT](https://github.com/centrifugal/centrifuge/tree/master/_examples/jwt_token).\\n\\n:::note\\n\\nBTW it\'s also possible to pass any information from client side with a first connect message from client to server and return custom information about server state to a client. This is out of post scope though.\\n\\n:::\\n\\nNothing prevents you to [integrate Centrifuge with OAuth2](https://github.com/centrifugal/centrifuge/tree/master/_examples/chat_oauth2) or another framework session mechanism \u2013 [like Gin for example](https://github.com/centrifugal/centrifuge/tree/master/_examples/chat_oauth2).\\n\\n## Channel subscriptions\\n\\nAs soon as a client connected and successfully authenticated it can subscribe to channels. Channel (room or topic in other systems) is a lightweight and ephemeral entity in Centrifuge. Channel can have different features (we will look at some channel features below). Channels created automatically as soon as the first subscriber joins and destroyed as soon as the last subscriber left.\\n\\nThe application can have many real-time features \u2013 even on one app screen. So sometimes client subscribes to several channels \u2013 each related to a specific real-time feature (for example one channel for chat updates, one channel likes notification stream, etc).\\n\\nChannel is just an ASCII string. A developer is responsible to find the best channel naming convention suitable for an application. Channel naming convention is an important aspect since in many cases developers want to authorize subscription to a channel on the server side \u2013 so only authorized users could listen to specific channel updates.\\n\\nLet\'s look at a basic subscription example on the client-side:\\n\\n```javascript\\ncentrifuge.subscribe(\'example\', function(msgCtx) {\\n    console.log(msgCtx)\\n})\\n```\\n\\nOn the server-side, you need to define subscribe event handler. If subscribe event handler not set then the connection won\'t be able to subscribe to channels at all. Subscribe event handler is where a developer may check permissions of the current connection to read channel updates. Here is a basic example of subscribe event handler that simply allows subscriptions to channel `example` for all authenticated connections and reject subscriptions to all other channels:\\n\\n```go\\nnode.OnConnect(func(client *centrifuge.Client) {\\n    client.OnSubscribe(func(e centrifuge.SubscribeEvent, cb centrifuge.SubscribeCallback) {\\n        if e.Channel != \\"example\\" {\\n            cb(centrifuge.SubscribeReply{}, centrifuge.ErrorPermissionDenied)\\n            return\\n        }\\n        cb(centrifuge.SubscribeReply{}, nil)\\n    })\\n})\\n```\\n\\nYou may notice a callback style of reacting to connection related things. While not being very idiomatic for Go it\'s very practical actually. The reason why we use callback style inside client event handlers is that it gives a developer possibility to control operation concurrency (i.e. process sth in separate goroutines or goroutine pool) and still control the order of events. See [an example](https://github.com/centrifugal/centrifuge/tree/master/_examples/concurrency) that demonstrates concurrency control in action.\\n\\nNow if some event published to a channel:\\n\\n```go\\n// Here is how we can publish data to a channel.\\nnode.Publish(\\"example\\", []byte(`{\\"input\\": \\"hello\\"}`))\\n```\\n\\n\u2013 data will be delivered to a subscribed client, and message will be printed to Javascript console. PUB/SUB in its usual form.\\n\\n:::note\\n\\nThough Centrifuge protocol based on Protobuf schema in example above we published a JSON message into a channel. By default, we can only send JSON to connections since default protocol format is JSON. But we can switch to Protobuf-based binary protocol by connecting to `ws://localhost:8000/connection/websocket?format=protobuf` endpoint \u2013 then it\'s possible to send binary data to clients.\\n\\n:::\\n\\n## Async message passing\\n\\nWhile Centrifuge mostly shines when you need channel semantics it\'s also possible to send any data to connection directly \u2013 to achieve bidirectional asynchronous communication, just what a native WebSocket provides.\\n\\nTo send a message to a server one can use the `send` method on the client-side:\\n\\n```javascript\\ncentrifuge.send({\\"input\\": \\"hello\\"});\\n```\\n\\nOn the server-side data will be available inside a message handler:\\n\\n```go\\nclient.OnMessage(func(e centrifuge.MessageEvent) {\\n    log.Printf(\\"message from client: %s\\", e.Data)\\n})\\n```\\n\\nAnd vice-versa, to send data to a client use `Send` method of `centrifuge.Client`:\\n\\n```go\\nclient.Send([]byte(`{\\"input\\": \\"hello\\"}`))\\n```\\n\\nTo listen to it on the client-side:\\n\\n```javascript\\ncentrifuge.on(\'message\', function(data) {\\n    console.log(data);\\n});\\n```\\n\\n## RPC\\n\\nRPC is a primitive for sending a request from a client to a server and waiting for a response (in this case all communication still happens via asynchronous message passing internally, but Centrifuge takes care of matching response data to request previously sent).\\n\\nOn client side it\'s as simple as:\\n\\n```javascript\\nconst resp = await centrifuge.namedRPC(\'my_method\', {});\\n```\\n\\nOn server side RPC event handler should be set to make calls available:\\n\\n```go\\nclient.OnRPC(func(e centrifuge.RPCEvent, cb centrifuge.RPCCallback) {\\n    if e.Method == \\"my_method\\" {\\n        cb(centrifuge.RPCReply{Data: []byte(`{\\"result\\": \\"42\\"}`)}, nil)\\n        return\\n    }\\n    cb(centrifuge.RPCReply{}, centrifuge.ErrorMethodNotFound)\\n})\\n```\\n\\nNote, that it\'s possible to pass the name of RPC and depending on it and custom request params return different results to a client \u2013 just like a regular HTTP request but over asynchronous WebSocket (or SockJS) connection.\\n\\n## Server-side subscriptions\\n\\nIn many cases, a client is a source of knowledge which channels it wants to subscribe to on a specific application screen. But sometimes you want to control subscriptions to channels on a server-side. This is also possible in Centrifuge.\\n\\nIt\'s possible to provide a slice of channels to subscribe connection to at the moment of connection establishment phase:\\n\\n```go\\nnode.OnConnecting(func(ctx context.Context, e centrifuge.ConnectEvent) (centrifuge.ConnectReply, error) {\\n    return centrifuge.ConnectReply{\\n        Subscriptions: map[string]centrifuge.SubscribeOptions{\\n            \\"example\\": {},\\n        },\\n    }, nil\\n})\\n```\\n\\nNote, that `OnConnecting` does not follow callback-style \u2013 this is because it can only happen once at the start of each connection \u2013 so there is no need to control operation concurrency.\\n\\nIn this case on the client-side you will have access to messages published to channels by listening to `on(\'publish\')` event:\\n\\n```javascript\\ncentrifuge.on(\'publish\', function(msgCtx) {\\n    console.log(msgCtx);\\n});\\n```\\n\\nAlso, `centrifuge.Client` has `Subscribe` and `Unsubscribe` methods so it\'s possible to subscribe/unsubscribe client to/from channel somewhere in the middle of its long WebSocket session.\\n\\n## Windowed history in channel\\n\\nEvery time a message published to a channel it\'s possible to provide custom history options. For example:\\n\\n```go\\nnode.Publish(\\n    \\"example\\",\\n    []byte(`{\\"input\\": \\"hello\\"}`),\\n    centrifuge.WithHistory(300, time.Minute),\\n)\\n```\\n\\nIn this case, Centrifuge will maintain a windowed Publication cache for a channel - or in other words, maintain a publication stream. This stream will have time retention (one minute in the example above) and the maximum size will be limited to the value provided during Publish (300 in the example above).\\n\\nEvery message inside a history stream has an incremental `offset` field. Also, a stream has a field called `epoch` \u2013 this is a unique identifier of stream generation - thus client will have a possibility to distinguish situations where a stream is completely removed and there is no guarantee that no messages have been lost in between even if offset looks fine.\\n\\nClient protocol provides a possibility to paginate over a stream from a certain position with a limit:\\n\\n```javascript\\nconst streamPosition = {\'offset\': 0, epoch: \'xyz\'} \\nresp = await sub.history({since: streamPosition, limit: 10});\\n```\\n\\nIteration over history stream is a new feature which is just merged into Centrifuge master branch and can only be used from Javascript client at the moment.\\n\\nAlso, Centrifuge has an automatic message recovery feature. Automatic recovery is very useful in scenarios when tons of persistent connections start reconnecting at once. I already described why this is useful in one of my previous posts about Websocket scalability. In short \u2013 since WebSocket connections are stateful then at the moment of mass reconnect they can create a very big spike in load on your main application database. Such mass reconnects are a usual thing in practice - for example when you reload your load balancers or re-deploying the Websocket server (new code version).\\n\\nOf course, recovery can also be useful for regular short network disconnects - when a user travels in the subway for example. But you always need a way to load an actual state from the main application database in case of an unsuccessful recovery.\\n\\nTo enable automatic recovery you can provide the `Recover` flag in subscribe options:\\n\\n```go\\nclient.OnSubscribe(func(e centrifuge.SubscribeEvent, cb centrifuge.SubscribeCallback) {\\n    cb(centrifuge.SubscribeReply{\\n        Options: centrifuge.SubscribeOptions{\\n            Recover:   true,\\n        },\\n    }, nil)\\n})\\n```\\n\\nObviously, recovery will work only for channels where history stream maintained. The limitation in recovery is that all missed publications sent to client in one protocol frame \u2013 pagination is not supported during recovery process. This means that recovery is mostly effective for not too long offline time without tons of missed messages.\\n\\n## Online presence and presence stats\\n\\nAnother cool thing Centrifuge exposes to developers is online presence information for channels. Presence information contains a list of active channel subscribers. This is useful to show the online status of players in a game for example.\\n\\nAlso, it\'s possible to turn on Join/Leave message feature inside channels: so each time connection subscribes to a channel all channel subscribers receive a Join message with client information (client ID, user ID). As soon as the client unsubscribes Leave message is sent to remaining channel subscribers with information who left a channel.\\n\\nHere is how to enable both online presence and join/leave features for a subscription to channel:\\n\\n```go\\nclient.OnSubscribe(func(e centrifuge.SubscribeEvent, cb centrifuge.SubscribeCallback) {\\n    cb(centrifuge.SubscribeReply{\\n        Options: centrifuge.SubscribeOptions{\\n            Presence:   true,\\n            JoinLeave:  true,\\n        },\\n    }, nil)\\n})\\n```\\n\\nOn a client-side then it\'s possible to call for the presence and setting event handler for join/leave messages. \\n\\nThe important thing to be aware of when using Join/Leave messages is that this feature can dramatically increase CPU utilization and overall traffic in channels with a big number of active subscribers \u2013 since on every client connect/disconnect event such Join or Leave message must be sent to all subscribers. The advice here \u2013 avoid using Join/Leave messages or be ready to scale (Join/Leave messages scale well when adding more Centrifuge Nodes \u2013 more about scalability below).\\n\\nOne more thing to remember is that online presence information can also be pretty expensive to request in channels with many active subscribers \u2013 since it returns information about all connections \u2013 thus payload in response can be large. To help a bit with this situation Centrifuge has a presence stats client API method. Presence stats only contain two counters: the number of active connections in the channel and amount of unique users in the channel.\\n\\nIf you still need to somehow process online presence in rooms with a massive number of active subscribers \u2013 then I think you better do it in near real-time - for example with fast OLAP like [ClickHouse](https://clickhouse.tech/).\\n\\n## Scalability aspects\\n\\nTo be fair it\'s not too hard to implement most of the features above inside one in-memory process. Yes, it takes time, but the code is mostly straightforward. When it comes to scalability things tend to be a bit harder.\\n\\nCentrifuge designed with the idea in mind that one machine is not enough to handle all application WebSocket connections. Connections should scale over application backend instances, and it should be simple to add more application nodes when the amount of users (connections) grows.\\n\\nCentrifuge abstracts scalability over the `Node` instance and two interfaces: `Broker` interface and `PresenceManager` interface.\\n\\nA broker is responsible for PUB/SUB and streaming semantics:\\n\\n```go\\ntype Broker interface {\\n\\tRun(BrokerEventHandler) error\\n\\tSubscribe(ch string) error\\n\\tUnsubscribe(ch string) error\\n\\tPublish(ch string, data []byte, opts PublishOptions) (StreamPosition, error)\\n\\tPublishJoin(ch string, info *ClientInfo) error\\n\\tPublishLeave(ch string, info *ClientInfo) error\\n\\tPublishControl(data []byte, nodeID string) error\\n\\tHistory(ch string, filter HistoryFilter) ([]*Publication, StreamPosition, error)\\n\\tRemoveHistory(ch string) error\\n}\\n```\\n\\nSee [full version with comments](https://github.com/centrifugal/centrifuge/blob/v0.14.2/engine.go#L98) in source code.\\n\\nEvery Centrifuge Node subscribes to channels via a broker. This provides a possibility to scale connections over many node instances \u2013 published messages will flow only to nodes with active channel subscribers.\\n\\nIt\'s and important thing to combine PUB/SUB with history inside a Broker implementation to achieve an atomicity of saving message into history stream and publishing it to PUB/SUB with generated offset.\\n\\nPresenceManager is responsible for online presence information management:\\n\\n```go\\ntype PresenceManager interface {\\n\\tPresence(ch string) (map[string]*ClientInfo, error)\\n\\tPresenceStats(ch string) (PresenceStats, error)\\n\\tAddPresence(ch string, clientID string, info *ClientInfo, expire time.Duration) error\\n\\tRemovePresence(ch string, clientID string) error\\n}\\n```\\n\\n[Full code with comments](https://github.com/centrifugal/centrifuge/blob/v0.14.2/engine.go#L150).\\n\\n`Broker` and `PresenceManager` together form an `Engine` interface:\\n\\n```go\\ntype Engine interface {\\n\\tBroker\\n\\tPresenceManager\\n}\\n```\\n\\nBy default, Centrifuge uses `MemoryEngine` that does not use any external services but limits developers to using only one Centrifuge Node (i.e. one server instance). Memory Engine is fast and can be suitable for some scenarios - even in production (with configured backup instance) \u2013 but as soon as the number of connections grows \u2013 you may need to load balance connections to different server instances. Here comes the Redis Engine.\\n\\nRedis Engine utilizes Redis for Broker and PresenceManager parts.\\n\\nHistory cache saved to Redis STREAM or Redis LIST data structures. For presence, Centrifuge uses a combination of HASH and ZSET structures.\\n\\nCentrifuge tries to fully utilize the connection between Node and Redis by using pipelining where possible and smart batching technique. All operations done in a single RTT with the help of Lua scripts loaded automatically to Redis on engine start.\\n\\nRedis is pretty fast and will allow your app to scale to some limits. When Redis starts being a bottleneck it\'s possible to shard data over different Redis instances. Client-side consistent sharding is built-in in Centrifuge and allows scaling further.\\n\\nIt\'s also possible to achieve Redis\'s high availability with built-in Sentinel support. Redis Cluster supported too. So Redis Engine covers many options to communicate with Redis deployed in different ways.\\n\\nAt Avito we served about 800k active connections in the messenger app with ease using a slightly adapted Centrifuge Redis Engine, so an approach proved to be working for rather big applications. We will look at some more concrete numbers below in the performance section.\\n\\nBoth `Broker` and `PresenceManager` are pluggable, so it\'s possible to replace them with alternative implementations. Examples show [how to use Nats server](https://github.com/centrifugal/centrifuge/tree/master/_examples/custom_broker_nats) for at most once only PUB/SUB together with Centrifuge. Also, we have [an example of full-featured Engine for Tarantool database](https://github.com/centrifugal/centrifuge/tree/master/_examples/custom_engine_tarantool) \u2013 Tarantool Engine shows even better throughput for history and presence operations than Redis-based Engine (up to 10x for some ops).\\n\\n## Order and delivery properties\\n\\nSince Centrifuge is a messaging system I also want to describe its order and message delivery guarantees.\\n\\nMessage ordering in channels supported. As soon as you publish messages into channels one after another of course.\\n\\nMessage delivery model is at most once by default. This is mostly comes from PUB/SUB model \u2013 message can be dropped on Centrifuge level if subscriber is offline or simply on broker level \u2013 since Redis PUB/SUB also works with at most once guarantee.\\n\\nThough if you maintain history stream inside a channel then things become a bit different. In this case you can tell Centrifuge to check client position inside stream. Since every publication has a unique incremental offset Centrifuge can track that client has correct offset inside a channel stream. If Centrifuge detects any missed messages it disconnects a client with special code \u2013 thus make it reconnect and recover messages from history stream. Since a message first saved to history stream and then published to PUB/SUB inside broker these mechanisms allow achieving at least once message delivery guarantee.\\n\\n![What happens on publish](https://i.imgur.com/PLb9xS5.jpg)\\n\\nEven if stream completely expired or dropped from broker memory Centrifuge will give a client a tip that messages could be lost \u2013 so client has a chance to restore state from a main application database.\\n\\n## Ecosystem\\n\\nHere I want to be fair with my readers \u2013 Centrifuge is not ideal. This is a project maintained mostly by one person at the moment with all consequences. This hits an ecosystem a lot, can make some design choices opinionated or non-optimal.\\n\\nI mentioned in the first post that Centrifuge built on top of the custom protocol. The protocol is based on a strict Protobuf schema, works with JSON and binary data transfer, supports many features. But \u2013 this means that to connect to the Centrifuge-based server developers have to use custom connectors that can speak with Centrifuge over its custom protocol.\\n\\nThe difficulty here is that protocol is asynchronous. Asynchronous protocols are harder to implement than synchronous ones. Multiplexing frames allows achieving good performance and fully utilize a single connection \u2013 but it hurts simplicity.\\n\\nAt this moment Centrifuge has client connectors for:\\n\\n* [centrifuge-js](https://github.com/centrifugal/centrifuge-js) - Javascript client for a browser, NodeJS and React Native\\n* [centrifuge-go](https://github.com/centrifugal/centrifuge-go) - for Go language\\n* [centrifuge-mobile](https://github.com/centrifugal/centrifuge-mobile) - for mobile development based on centrifuge-go and [gomobile](https://github.com/golang/mobile) project\\n* [centrifuge-swift](https://github.com/centrifugal/centrifuge-swift) - for iOS native development\\n* [centrifuge-java](https://github.com/centrifugal/centrifuge-java) - for Android native development and general Java\\n* [centrifuge-dart](https://github.com/centrifugal/centrifuge-dart) - for Dart and Flutter\\n\\nNot all clients support all protocol features. Another drawback is that all clients do not have a persistent maintainer \u2013 I mostly maintain everything myself. Connectors can have non-idiomatic and pretty dumb code since I had no previous experience with mobile development, they lack proper tests and documentation. This is unfortunate.\\n\\nThe good thing is that all connectors feel very similar, I am quickly releasing new versions when someone sends a pull request with improvements or bug fixes. So all connectors are alive.\\n\\nI maintain a feature matrix in connectors to let users understand what\'s supported. Actually feature support is pretty nice throughout all these connectors - there are only several things missing and not so much work required to make all connectors full-featured. But I really need help here.\\n\\nIt will be a big mistake to not mention Centrifugo as a big plus for Centrifuge library ecosystem. Centrifugo is a server deployed in many projects throughout the world. Many features of Centrifuge library and its connectors have already been tested by Centrifugo users.\\n\\nOne more thing to mention is that Centrifuge does not have v1 release. It still evolves \u2013 I believe that the most dramatic changes have already been made and backward compatibility issues will be minimal in the next releases \u2013 but can\'t say for sure.\\n\\n## Performance\\n\\nI made a test stand in Kubernetes with one million connections.\\n\\nI can\'t call this a proper benchmark \u2013 since in a benchmark your main goal is to destroy a system, in my test I just achieved some reasonable numbers on limited hardware. These numbers should give a good insight into a possible throughput, latency, and estimate hardware requirements (at least approximately).\\n\\nConnections landed on different server pods, 5 Redis instances have been used to scale connections between pods.\\n\\nThe detailed test stand description [can be found in Centrifugo documentation](https://centrifugal.github.io/centrifugo/misc/benchmark/).\\n\\n![Benchmark](/img/benchmark.gif)\\n\\nSome quick conclusions are:\\n\\n* One connection costs about 30kb of RAM\\n* Redis broker CPU utilization increases linearly with more messages traveling around\\n* 1 million connections with 500k **delivered** messages per second with 200ms delivery latency in 99 percentile can be served with hardware amount equal to one modern physical server machine. The possible amount of messages can vary a lot depending on the number of channel subscribers though.\\n\\n## Limitations\\n\\nCentrifuge does not allow subscribing on the same channel twice inside a single connection. It\'s not simple to add due to design decisions made \u2013 though there was no single user report about this in seven years of Centrifugo/Centrifuge history.\\n\\nCentrifuge does not support wildcard subscriptions. Not only because I never needed this myself but also due to some design choices made \u2013 so be aware of this.\\n\\nSockJS fallback does not support binary data - only JSON. If you want to use binary in your application then you can only use WebSocket with Centrifuge - there is no built-in fallback transport in this case.\\n\\nSockJS also requires sticky session support from your load balancer to emulate a stateful bidirectional connection with its HTTP fallback transports. Ideally, Centrifuge will go away from SockJS at some point, maybe when WebTransport becomes mature so users will have a choice between WebTransport or WebSocket.\\n\\nWebsocket `permessage-deflate` compression supported (thanks to Gorilla WebSocket), but it can be pretty expensive in terms of CPU utilization and memory usage \u2013 the overhead depends on usage pattern, it\'s pretty hard to estimate in numbers.\\n\\nAs said above you cannot only rely on Centrifuge for state recovery \u2013 it\'s still required to have a way to fully load application state from the main database.\\n\\nAlso, I am not very happy with current error and disconnect handling throughout the connector ecosystem \u2013 this can be improved though, and I have some ideas for the future.\\n\\n## Examples\\n\\nI am adding examples to [_examples](https://github.com/centrifugal/centrifuge/tree/master/_examples) folder of Centrifuge repo. These examples completely cover Centrifuge API - including things not mentioned here.\\n\\nCheck out the [tips & tricks](https://github.com/centrifugal/centrifuge#tips-and-tricks) section of README \u2013 it contains some additional insights about an implementation.\\n\\n## Conclusion\\n\\nI think [Centrifuge](https://github.com/centrifugal/centrifuge) could be a nice alternative to [socket.io](https://socket.io) - with a better performance, main server implementation in Go language, and even more builtin features to build real-time apps.\\n\\nCentrifuge ecosystem definitely needs more work, especially in client connectors area, tutorials, community, stabilizing API, etc.\\n\\nCentrifuge fits pretty well proprietary application development where time matters and deadlines are close, so developers tend to choose a ready solution instead of writing their own. I believe Centrifuge can be a great time saver here.\\n\\nFor Centrifugo server users Centrifuge package provides a way to write a more flexible server code adapted for business requirements but still use the same real-time core and have the same protocol features."},{"id":"/2020/11/12/scaling-websocket","metadata":{"permalink":"/blog/2020/11/12/scaling-websocket","editUrl":"https://github.com/centrifugal/centrifugal.dev/edit/main/blog/2020-11-12-scaling-websocket.md","source":"@site/blog/2020-11-12-scaling-websocket.md","title":"Scaling WebSocket in Go and beyond","description":"Scaling WebSocket in Go and beyond","date":"2020-11-12T00:00:00.000Z","formattedDate":"November 12, 2020","tags":[{"label":"websocket","permalink":"/blog/tags/websocket"},{"label":"go","permalink":"/blog/tags/go"}],"readingTime":18.705,"hasTruncateMarker":true,"authors":[{"name":"Alexander Emelin","title":"Creator of Centrifugo","imageURL":"https://github.com/FZambia.png"}],"frontMatter":{"title":"Scaling WebSocket in Go and beyond","tags":["websocket","go"],"description":"Scaling WebSocket in Go and beyond","author":"Alexander Emelin","authorTitle":"Creator of Centrifugo","authorImageURL":"https://github.com/FZambia.png","image":"https://i.imgur.com/QOJ1M9a.png","hide_table_of_contents":false},"prevItem":{"title":"Centrifuge \u2013 real-time messaging with Go","permalink":"/blog/2021/01/15/centrifuge-intro"},"nextItem":{"title":"Experimenting with QUIC and WebTransport","permalink":"/blog/2020/10/16/experimenting-with-quic-transport"}},"content":"![gopher-broker](https://i.imgur.com/QOJ1M9a.png)\\n\\nI believe that in 2020 WebSocket is still an entertaining technology which is not so well-known and understood like HTTP. In this blog post I\'d like to tell about state of WebSocket in Go language ecosystem, and a way we could write scalable WebSocket servers with Go and beyond Go.\\n\\n\x3c!--truncate--\x3e\\n\\nWe won\'t talk a lot about WebSocket transport pros and cons \u2013 I\'ll provide links to other resources on this topic. Most advices here are generic enough and can be easily approximated to other programming languages. Also in this post we won\'t talk about ready to use solutions (if you are looking for it \u2013 check out [Real-time Web Technologies guide](https://www.leggetter.co.uk/real-time-web-technologies-guide/) by Phil Leggetter), just general considerations. There is not so much information about scaling WebSocket on the internet so if you are interested in WebSocket and real-time messaging technologies - keep on reading.\\n\\nIf you don\'t know what WebSocket is \u2013 check out the following curious links:\\n\\n* https://hpbn.co/websocket/ \u2013 a wonderful chapter of great book by Ilya Grigorik\\n* https://lucumr.pocoo.org/2012/9/24/websockets-101/ \u2013 valuable thoughts about WebSocket from Armin Ronacher\\n\\nAs soon as you know WebSocket basics \u2013 we can proceed.\\n\\n## WebSocket server tasks\\n\\nSpeaking about scalable servers that work with many persistent WebSocket connections \u2013 I found several important tasks such a server should be able to do:\\n\\n* Maintain many active connections\\n* Send many messages to clients\\n* Support WebSocket fallback to scale to every client\\n* Authenticate incoming connections and invalidate connections\\n* Survive massive reconnect of all clients without loosing messages\\n\\n:::note\\n\\nOf course not all of these points equally important in various situations.\\n\\n:::\\n\\nBelow we will look at some tips which relate to these points.\\n\\n![one_hour_scale](https://i.imgur.com/4lYjJSP.png)\\n\\n## WebSocket libraries\\n\\nIn Go language ecosystem we have several libraries which can be used as a building block for a WebSocket server.\\n\\nPackage [golang.org/x/net/websocket](https://godoc.org/golang.org/x/net/websocket) is considered **deprecated**.\\n\\nThe default choice in the community is [gorilla/websocket](https://github.com/gorilla/websocket) library. Made by Gary Burd (who also gifted us an awesome [Redigo](https://github.com/gomodule/redigo) package to communicate with Redis) \u2013 it\'s widely used, performs well, has a very good API \u2013 so in most cases you should go with it. Some people think that library not actively maintained at moment \u2013 but this is not quite true, it implements full WebSocket RFC, so actually it can be considered done.\\n\\nIn 2018 my ex-colleague Sergey Kamardin open-sourced [gobwas/ws](https://github.com/gobwas/ws) library. It provides a bit lower-level API than `gorilla/websocket` thus allows reducing RAM usage per connection and has nice optimizations for WebSocket upgrade process. It does not support WebSocket `permessage-deflate` compression but otherwise a good alternative you can consider using. If you have not read Sergey\'s famous post [A Million WebSockets and Go](https://www.freecodecamp.org/news/million-websockets-and-go-cc58418460bb/) \u2013 make a bookmark!\\n\\nOne more library is [nhooyr/websocket](https://github.com/nhooyr/websocket). It\'s the youngest one and actively maintained. It compiles to WASM which can be a cool thing for someone. The API is a bit different from what `gorilla/websocket` offers, and one of the big advantages I see is that it solves a problem with a proper WebSocket closing handshake which is [a bit hard to do right with Gorilla WebSocket](https://github.com/gorilla/websocket/issues/448).\\n\\nYou can consider all listed libraries except one from `x/net` for your project. Take a library, follow its examples (make attention to goroutine-safety of various API operations). Personally I prefer Gorilla WebSocket at moment since it\'s feature-complete and battle tested by tons of projects around Go world.\\n\\n## OS tuning\\n\\nOK, so you have chosen a library and built a server on top of it. As soon as you put it in production the interesting things start happening.\\n\\nLet\'s start with several OS specific key things you should do to prepare for many connections from WebSocket clients.\\n\\nEvery connection will cost you an open file descriptor, so you should tune a maximum number of open file descriptors your process can use. An errors like `too many open files` raise due to OS limit on file descriptors which is usually 256-1024 by default (see with `ulimit -n` on Unix). A nice overview on how to do this on different systems can be found [in Riak docs](https://docs.riak.com/riak/kv/2.2.3/using/performance/open-files-limit.1.html). Wanna more connections? Make this limit higher.\\n\\nNice tip here is to limit a maximum number of connections your process can serve \u2013 making it less than known file descriptor limit:\\n\\n```go\\n//\xa0ulimit\xa0-n\xa0==\xa065535\\nif conns.Len() >= 65500 {\\n    return errors.New(\\"connection\xa0limit\xa0reached\\")\\n}\\nconns.Add(conn)\\n```\\n\\n\u2013 otherwise you have a risk to not even able to look at `pprof` when things go bad. And you always need monitoring of open file descriptors.\\n\\nYou can also consider using [netutil.LimitListener](https://godoc.org/golang.org/x/net/netutil#LimitListener) for this task, but don\'t forget to put pprof on another port with another HTTP server instance in this case.\\n\\nKeep attention on *Ephemeral ports* problem which is often happens between your load balancer and your WebSocket server. The problem arises due to the fact that each TCP connection uniquely identified in the OS by the 4-part-tuple:\\n\\n```\\nsource ip | source port | destination ip | destination port\\n```\\n\\nOn balancer/server boundary you are limited in 65536 possible variants by default. But actually due to some OS limits and sockets in TIME_WAIT state the number is even less. A very good explanation and how to deal with it can be found [in Pusher blog](https://making.pusher.com/ephemeral-port-exhaustion-and-how-to-avoid-it/).\\n\\nYour possible number of connections also limited by conntrack table. Netfilter framework which is part of iptables keeps information about all connections and has limited size for this information. See how to see its limits and instructions to increase [in this article](https://morganwu277.github.io/2018/05/26/Solve-production-issue-of-nf-conntrack-table-full-dropping-packet/).\\n\\nOne more thing you can do is tune your network stack for performance. Do this only if you understand that you need it. Maybe start [with this gist](https://gist.github.com/mustafaturan/47268d8ad6d56cadda357e4c438f51ca), but don\'t optimize without full understanding why you are doing this. \\n\\n## Sending many messages\\n\\nNow let\'s speak about sending many messages. The general tips follows.\\n\\n**Make payload smaller**. This is obvious \u2013 fewer data means more effective work on all layers. BTW WebSocket framing overhead is minimal and adds only 2-8 bytes to your payload. You can read detailed dedicated research in [Dissecting WebSocket\'s Overhead](https://crossbario.com/blog/Dissecting-Websocket-Overhead/) article. You can reduce an amount of data traveling over network with `permessage-deflate` WebSocket extension, so your data will be compressed. Though using `permessage-deflate` is not always a good thing for server due to [poor performance of flate](https://github.com/gorilla/websocket/issues/203), so you should be prepared for a CPU and RAM resource usage on server side. While Gorilla WebSocket has a lot of optimizations internally by reusing flate writers, overhead is still noticeable. The increase value heavily depends on your load profile.\\n\\n**Make less system calls**. Every syscall will have a constant overhead, and actually in WebSocket server under load you will mostly see read and write system calls in your CPU profiles. An advice here \u2013 try to use client-server protocol that supports message batching, so you can join individual messages together.\\n\\n**Use effective message serialization protocol**. Maybe use code generation for JSON to avoid extensive usage of reflect package done by Go std lib. Maybe use sth like [gogo/protobuf](https://github.com/gogo/protobuf) package which allows to speedup Protobuf marshalling and unmarshalling. Unfortunately Gogo Protobuf [is going through hard times\\n](https://github.com/gogo/protobuf/issues/691) at this moment. Try to serialize a message only once when sending to many subscribers.\\n\\n**Have a way to scale to several machines** - more power, more possible messages. We will talk about this very soon.\\n\\n## WebSocket fallback transport\\n\\n![ie](https://i.imgur.com/IAOyvmg.png)\\n\\nEven in 2020 there are still users which cannot establish connection with WebSocket server. Actually the problem mostly appears with browsers. Some users still use old browsers. But they have a choice \u2013 install a newer browser. Still, there could also be users behind corporate proxies. Employees can have a trusted certificate installed on their machine so company proxy can re-encrypt even TLS traffic. Also, some browser extensions can block WebSocket traffic.\\n\\nOne ready solution to this is [Sockjs-Go](https://github.com/igm/sockjs-go/) library. This is a mature library that provides fallback transport for WebSocket. If client does not succeed with WebSocket connection establishment then client can use some of HTTP transports for client-server communication: [EventSource aka Server-Sent Events](https://hpbn.co/server-sent-events-sse/), XHR-streaming, Long-Polling etc. The downside with those transports is that to achieve bidirectional communication you should use sticky sessions on your load balancer since SockJS keeps connection session state in process memory. We will talk about many instances of your WebSocket server very soon.\\n\\nYou can implement WebSocket fallback yourself, this should be simple if you have a sliding window message stream on your backend which we will discuss very soon.\\n\\nMaybe look at [GRPC](https://grpc.io/docs/what-is-grpc/introduction/), depending on application it could be better or worse than WebSocket \u2013 in general you can expect a better performance and less resource consumption from WebSocket for bidirectional communication case. My measurements for a **bidirectional** scenario showed 3x win for WebSocket (binary + GOGO protobuf) in terms of server CPU consumption and 4 times less RAM per connection. Though if you only need RPC then GRPC can be a better choice. But you need additional proxy to work with GRPC from a browser. \\n\\n## Performance is not scalability\\n\\nYou can optimize client-server protocol, tune your OS, but at some point you won\'t be able to use only one process on one server machine. You need to scale connections and work your server does over different server machines. Horizontal scaling is also good for a server high availability. Actually there are some sort of real-time applications where a single isolated process makes sense - for example multiplayer games where limited number of players play independent game rounds.\\n\\n![many_instances](https://i.imgur.com/8ElqpjI.png)\\n\\nAs soon as you distribute connections over several machines you have to find a way to deliver a message to a certain user. The basic approach here is to publish messages to all server instances. This can work but this does not scale well. You need a sort of instance discovery to make this less painful.\\n\\nHere comes PUB/SUB, where you can connect WebSocket server instances over central PUB/SUB broker. Clients that establish connections with your WebSocket server subscribe to topics (channels) in a broker, and as soon as you publish a message to that topic it will be delivered to all active subscribers on WebSocket server instances. If server node does not have interested subscriber then it won\'t get a message from a broker thus you are getting effective network communication.\\n\\nActually the main picture of this post illustrates exactly this architecture:\\n\\n![gopher-broker](https://i.imgur.com/QOJ1M9a.png)\\n\\nLet\'s think about requirements for a broker for real-time messaging application. We want a broker:\\n\\n* with reasonable performance and possibility to scale\\n* which maintains message order in topics\\n* can support millions of topics, where each topic should be ephemeral and lightweight \u2013 topics can be created when user comes to application and removed after user goes away\\n* possibility to keep a sliding window of messages inside channel to help us survive massive reconnect scenario (will talk about this later below, can be a separate part from broker actually)\\n\\nPersonally when we talk about such brokers here are some options that come into my mind:\\n\\n* [RabbitMQ](https://www.rabbitmq.com/)\\n* [Kafka](https://kafka.apache.org/) or [Pulsar](https://pulsar.apache.org/)\\n* [Nats or Nats-Streaming](https://nats.io/)\\n* [Tarantool](https://www.tarantool.io/en/)\\n* [Redis](https://redis.io/)\\n\\n**Sure there are more exist** including libraries like [ZeroMQ](https://zeromq.org/) or [nanomsg](https://nanomsg.org/).\\n\\nBelow I\'ll try to consider these solutions for the task of making scalable WebSocket server facing many user connections from Internet.\\n\\nIf you are looking for unreliable at most once PUB/SUB then any of solutions mentioned above should be sufficient. Many real-time messaging apps are ok with at most once guarantee delivery.\\n\\nIf you don\'t want to miss messages then things are a bit harder. Let\'s try to evaluate these options for a task where application has lots of different topics from which it wants to receive messages with at least once guarantee (having a personal topic per client is common thing in applications). A short analysis below can be a bit biased, but I believe thoughts are reasonable enough. I did not found enough information on the internet about scaling WebSocket beyond a single server process, so I\'ll try to fill the gap a little based on my personal knowledge without pretending to be absolutely objective in these considerations.\\n\\nIn some posts on the internet about scaling WebSocket I saw advices to use RabbitMQ for PUB/SUB stuff in real-time messaging server. While this is a great messaging server, it does not like a high rate of queue bind and unbind type of load. It will work, but you will need to use a lot of server resources for not so big number of clients (imagine having millions of queues inside RabbitMQ). I have an example from my practice where RabbitMQ consumed about 70 CPU cores to serve real-time messages for 100k online connections. After replacing it with Redis keeping the same message delivery semantics we got only 0.3 CPU consumption on broker side.\\n\\nKafka and Pulsar are great solutions, but not for this task I believe. The problem is again in dynamic ephemeral nature of our topics. Kafka also likes a more stable configuration of its topics. Keeping messages on disk can be an overkill for real-time messaging task. Also your consumers on Kafka server should pull from millions of different topics, not sure how well it performs, but my thoughts at moment - this should not perform very well. Kafka itself scales perfectly, you will definitely be able to achieve a goal but resource usage will be significant. Here is [a post from Trello](https://tech.trello.com/why-we-chose-kafka/) where they moved from RabbitMQ to Kafka for similar real-time messaging task and got about 5x resource usage improvements. Note also that the more partitions you have the more heavy failover process you get.\\n\\nNats and Nats-Streaming. Raw Nats can only provide at most once guarantee. BTW recently Nats developers [released native WebSocket support](https://github.com/nats-io/nats-server/issues/315), so you can consider it for your application. Nats-Streaming server as broker will allow you to not lose messages. To be fair I don\'t have enough information about how well Nats-Streaming scales to millions of topics. An upcoming [Jetstream](https://github.com/nats-io/jetstream) which will be a part of Nats server can also be an interesting option \u2013 like Kafka it provides a persistent stream of messages for at least once delivery semantics. But again, it involves disk storage, a nice thing for backend microservices communication but can be an overkill for real-time messaging task.\\n\\nSure Tarantool can fit to this task well too. It\'s fast, im-memory and flexible. Some possible problems with Tarantool are not so healthy state of its client libraries, complexity and the fact that it\'s heavily enterprise-oriented. You should invest enough time to benefit from it, but this can worth it actually. See [an article](https://hackernoon.com/tarantool-when-it-takes-500-lines-of-code-to-notify-a-million-users-11d340523493) on how to do a performant broker for WebSocket applications with Tarantool.\\n\\nBuilding PUB/SUB system on top of ZeroMQ will require you to build separate broker yourself. This could be an unnecessary complexity for your system. It\'s possible to implement PUB/SUB pattern with ZeroMQ and nanomsg without a central broker, but in this case messages without active subscribers on a server will be dropped on a consumer side thus all publications will travel to all server nodes. \\n\\nMy personal choice at moment is Redis. While **Redis PUB/SUB itself provides at most once guarantee**, you can build at least once delivery on top of PUB/SUB and Redis data structures (though this can be challenging enough). Redis is very fast (especially when using pipelining protocol feature), and what is more important \u2013 **very predictable**. It gives you a good understanding of operation time complexity. You can shard topics over different Redis instances running in HA setup - with Sentinel or with Redis Cluster. It allows writing LUA procedures with some advanced logic which can be uploaded over client protocol thus feels like ordinary commands. You can use Redis to keep sliding window event stream which gives you access to missed messages from a certain position. We will talk about this later.\\n\\nOK, the end of opinionated thoughts here :)\\n\\nDepending on your choice the implementation of your system will vary and will have different properties \u2013 so try to evaluate possible solutions based on your application requirements. Anyway, whatever broker will be your choice, try to follow this rules to build effective PUB/SUB system:\\n\\n* take into account message delivery guarantees of your system: at most once or at least once, ideally you should have an option to have both for different real-time features in your app\\n* make sure to use one or pool of connections between your server and a broker, don\'t create new connection per each client or topic that comes to your WebSocket server\\n* use effective serialization format between your WebSocket server and broker\\n\\n## Massive reconnect\\n\\n![mass_reconnect](https://i.imgur.com/S9koKYg.png)\\n\\nLet\'s talk about one more problem that is unique for Websocket servers compared to HTTP. Your app can have thousands or millions of active WebSocket connections. In contract to stateless HTTP APIs your application is stateful. It uses push model. As soon as you deploying your WebSocket server or reload your load balancer (Nginx maybe) \u2013 connections got dropped and all that army of users start reconnecting. And this can be like an avalanche actually. How to survive?\\n\\nFirst of all - use exponential backoff strategies on client side. I.e. reconnect with intervals like 1, 2, 4, 8, 16 seconds with some random jitter.\\n\\nTurn on various rate limiting strategies on your WebSocket server, some of them should be turned on your backend load balancer level (like controlling TCP connection establishment rate), some are application specific (maybe limit an amount of requests from certain user).\\n\\nOne more interesting technique to survive massive reconnect is using JWT (JSON Web Token) for authentication. I\'ll try to explain why this can be useful.\\n\\n![jwt](https://i.imgur.com/aaTEhXo.png)\\n\\nAs soon as your client start reconnecting you will have to authenticate each connection. In massive setups with many persistent connection this can be a very significant load on your Session backend. Since you need an extra request to your session storage for every client coming back. This can be a no problem for some infrastructures but can be really disastrous for others. JWT allows to reduce this spike in load on session storage since it can have all required authentication information inside its payload. When using JWT make sure you have chosen a reasonable JWT expiration time \u2013 expiration interval depends on your application nature and just one of trade-offs you should deal with as developer.\\n\\nDon\'t forget about making an effective connection between your WebSocket server and broker \u2013 as soon as all clients start reconnecting you should resubscribe your server nodes to all topics as fast as possible. Use techniques like smart batching at this moment.\\n\\nLet\'s look at a small piece of code that demonstrates this technique. Imagine we have a source channel from which we get items to process. We don\u2019t want to process items individually but in batch. For this we wait for first item coming from channel, then try to collect as many items from channel buffer as we want without blocking and timeouts involved. And then process slice of items we collected at once. For example build Redis pipeline from them and send to Redis in one connection write call.\\n\\n```go\\nmaxBatchSize := 50\\n\\nfor {\\n    select {\\n    case item := <-sourceCh:\\n        batch := []string{item}\\n    loop:\\n        for len(batch) < maxBatchSize {\\n            select {\\n            case item := <-sourceCh:\\n                batch = append(batch, item)\\n            default:\\n                break loop\\n            }\\n        }\\n        // Do sth with collected batch of items.\\n        println(len(batch))\\n    }\\n}\\n```\\n\\nLook at a complete example in a Go playground: https://play.golang.org/p/u7SAGOLmDke.\\n\\nI also made a repo where I demonstrate how this technique together with Redis pipelining feature allows to fully utilize connection for a good performance https://github.com/FZambia/redigo-smart-batching.\\n\\nAnother advice for those who run WebSocket services in Kubernetes. Learn how your ingress behaves \u2013 for example Nginx ingress can reload its configuration on every change inside Kubernetes services map resulting into closing all active WebSocket connections. Proxies like Envoy don\'t have this behaviour, so you can reduce number of mass disconnections in your system. You can also proxy WebSocket without using ingress at all over configured WebSocket service NodePort.\\n\\n## Message event stream benefits\\n\\nHere comes a final part of this post. Maybe the most important one.\\n\\nNot only mass client re-connections could create a significant load on a session backend but also a huge load on your main application database. Why? Because WebSocket applications are stateful. Clients rely on a stream of messages coming from a backend to maintain its state actual. As soon as connection dropped client tries to reconnect. In some scenarios it also wants to restore its actual state. What if client reconnected after 3 seconds? How many state updates it could miss? Nobody knows. So to make sure state is actual client tries to get it from application database. This is again **a significant spike in load on your main database** in massive reconnect scenario. In can be really painful with many active connections.\\n\\nSo what I think is nice to have for scenarios where we can\'t afford to miss messages (like in chat-like apps for example) is having effective and performant stream of messages inside each channel. Keep this stream in fast in-memory storage. This stream can have time retention and be limited in size (think about it as a sliding window of messages). I already mentioned that Redis can do this \u2013 it\'s possible to keep messages in Redis List or Redis Stream data structures. Other broker solutions could give you access to such a stream inside each channel out of the box.\\n\\nSo as soon as client reconnects it can restore its state from fast in-memory event stream without even querying your database. Actually to survive mass reconnect scenario you don\'t need to keep such a stream for a long time \u2013 several minutes should be enough. You can **even create your own Websocket fallback implementation (like Long-Polling) utilizing event stream with limited retention**.\\n\\n## Conclusion\\n\\nHope advices given here will be useful for a reader and will help writing a more robust and more scalable real-time application backends.\\n\\n[Centrifugo server](https://github.com/centrifugal/centrifugo/) and [Centrifuge library for Go language](https://github.com/centrifugal/centrifuge) have most of the mechanics described here including the last one \u2013 message stream for topics limited by size and retention period. Both also have techniques to prevent message loss due to at most once nature of Redis PUB/SUB giving at least once delivery guarantee inside message history window size and retention period."},{"id":"/2020/10/16/experimenting-with-quic-transport","metadata":{"permalink":"/blog/2020/10/16/experimenting-with-quic-transport","editUrl":"https://github.com/centrifugal/centrifugal.dev/edit/main/blog/2020-10-16-experimenting-with-quic-transport.md","source":"@site/blog/2020-10-16-experimenting-with-quic-transport.md","title":"Experimenting with QUIC and WebTransport","description":"Experimenting with QUIC and WebTransport in Go","date":"2020-10-16T00:00:00.000Z","formattedDate":"October 16, 2020","tags":[{"label":"quic","permalink":"/blog/tags/quic"},{"label":"webtransport","permalink":"/blog/tags/webtransport"},{"label":"go","permalink":"/blog/tags/go"}],"readingTime":14.165,"hasTruncateMarker":true,"authors":[{"name":"Alexander Emelin","title":"Creator of Centrifugo","imageURL":"https://github.com/FZambia.png"}],"frontMatter":{"title":"Experimenting with QUIC and WebTransport","tags":["quic","webtransport","go"],"description":"Experimenting with QUIC and WebTransport in Go","author":"Alexander Emelin","authorTitle":"Creator of Centrifugo","authorImageURL":"https://github.com/FZambia.png","image":"https://i.imgur.com/sH9zfhe.jpg","hide_table_of_contents":false},"prevItem":{"title":"Scaling WebSocket in Go and beyond","permalink":"/blog/2020/11/12/scaling-websocket"},"nextItem":{"title":"Million connections with Centrifugo","permalink":"/blog/2020/02/10/million-connections-with-centrifugo"}},"content":"![post-cover](https://i.imgur.com/sH9zfhe.jpg)\\n\\n**UPDATE: WebTransport spec is still evolving. Most information here is not actual anymore. For example the working group has no plan to implement both QuicTransport and HTTP3-based transports \u2013 only HTTP3 based WebTransport is going to be implemented. Maybe we will publish a follow-up of this post at some point.**\\n\\n\x3c!--truncate--\x3e\\n\\n## Overview\\n\\nWebTransport is a new browser API offering low-latency, bidirectional, client-server messaging. If you have not heard about it before I suggest to first read a post called [Experimenting with QuicTransport](https://web.dev/quictransport/) published recently on web.dev \u2013 it gives a nice overview to WebTransport and shows client-side code examples. Here we will concentrate on implementing server side.\\n\\nSome key points about WebTransport spec:\\n\\n* WebTransport standard will provide a possibility to use streaming client-server communication using modern transports such as [QUIC](https://en.wikipedia.org/wiki/QUIC) and [HTTP/3](https://en.wikipedia.org/wiki/HTTP/3)\\n* It can be a good alternative to [WebSocket](https://en.wikipedia.org/wiki/WebSocket) messaging, standard provides some capabilities that are not possible with current WebSocket spec: possibility to get rid of head-of-line blocking problems using individual streams for different data, the possibility to reuse a single connection to a server in different browser tabs\\n* WebTransport also defines an unreliable stream API using UDP datagrams (which is possible since QUIC is UDP-based) \u2013 which is what browsers did not have before without a rather complex [WebRTC](https://en.wikipedia.org/wiki/WebRTC) setup involving ICE, STUN, etc. This is sweet for in-browser real-time games.\\n\\nTo help you figure out things here are links to current WebTransport specs:\\n\\n* [WebTransport overview](https://tools.ietf.org/html/draft-vvv-webtransport-overview-01) \u2013 this spec gives an overview of WebTransport and provides requirements to transport layer\\n* [WebTransport over QUIC](https://tools.ietf.org/html/draft-vvv-webtransport-quic) \u2013 this spec describes QUIC-based transport for WebTransport\\n* [WebTransport over HTTP/3](https://tools.ietf.org/html/draft-vvv-webtransport-http3) \u2013 this spec describes HTTP/3-based transport for WebTransport (actually HTTP/3 is a protocol defined on top of QUIC)\\n\\nAt moment Chrome only implements [trial possibility](https://web.dev/quictransport/#register-for-ot) to try out WebTransport standard and only implements WebTransport over QUIC. Developers can initialize transport with code like this:\\n\\n```javascript\\nconst transport = new QuicTransport(\'quic-transport://localhost:4433/path\');\\n```\\n\\nIn case of HTTP/3 transport one will use URL like `\'https://localhost:4433/path\'` in transport constructor. All WebTransport underlying transports should support instantiation over URL \u2013 that\'s one of the spec requirements. \\n\\nI decided that this is a cool possibility to finally play with QUIC protocol and its Go implementation [github.com/lucas-clemente/quic-go](https://github.com/lucas-clemente/quic-go).\\n\\n:::danger\\n\\nPlease keep in mind that all things described in this post are work in progress. WebTransport drafts, Quic-Go library, even QUIC protocol itself are subjects to change. You should not use it in production yet.\\n\\n:::\\n\\n[Experimenting with QuicTransport](https://web.dev/quictransport/) post contains links to a [client example](https://googlechrome.github.io/samples/quictransport/client.html) and companion [Python server implementation](https://github.com/GoogleChrome/samples/blob/gh-pages/quictransport/quic_transport_server.py).\\n\\n![client example](https://i.imgur.com/Hty00aG.png)\\n\\nWe will use a linked client example to connect to a server that runs on localhost and uses [github.com/lucas-clemente/quic-go](https://github.com/lucas-clemente/quic-go) library. To make our example work we need to open client example in Chrome, and actually, at this moment we need to install Chrome Canary. The reason behind this is that the  `quic-go` library supports QUIC draft-29 while Chrome < 85 implements QuicTransport over draft-27. If you read this post at a time when Chrome stable 85 already released then most probably you don\'t need to install Canary release and just use your stable Chrome.\\n\\nWe also need to generate self-signed certificates since WebTransport only works with a TLS layer, and we should make Chrome trust our certificates. Let\'s prepare our client environment before writing a server and first install Chrome Canary.\\n\\n## Install Chrome Canary\\n\\nGo to https://www.google.com/intl/en/chrome/canary/, download and install Chrome Canary. We will use it to open [client example](https://googlechrome.github.io/samples/quictransport/client.html).\\n\\n:::note\\n\\nIf you have Chrome >= 85 then most probably you can skip this step.\\n\\n:::\\n\\n## Generate self-signed TLS certificates\\n\\nSince WebTransport based on modern network transports like QUIC and HTTP/3 security is a keystone. For our experiment we will create a self-signed TLS certificate using `openssl`. \\n\\nMake sure you have `openssl` installed:\\n\\n```bash\\n$ which openssl\\n/usr/bin/openssl\\n```\\n\\nThen run:\\n\\n```bash\\nopenssl genrsa -des3 -passout pass:x -out server.pass.key 2048\\nopenssl rsa -passin pass:x -in server.pass.key -out server.key\\nrm server.pass.key\\nopenssl req -new -key server.key -out server.csr\\n```\\n\\nSet `localhost` for Common Name when asked.\\n\\nThe self-signed TLS certificate generated from the `server.key` private key and `server.csr` files:\\n\\n```bash\\nopenssl x509 -req -sha256 -days 365 -in server.csr -signkey server.key -out server.crt\\n```\\n\\nAfter these manipulations you should have `server.crt` and `server.key` files in your working directory.\\n\\nTo help you with process here is my console output during these steps (click to open):\\n\\n??? example \\"My console output generating self-signed certificates\\"\\n    ```bash\\n    $ openssl genrsa -des3 -passout pass:x -out server.pass.key 2048\\n    Generating RSA private key, 2048 bit long modulus\\n    ...........................................................................................+++\\n    .....................+++\\n    e is 65537 (0x10001)\\n    \\n    $ ls\\n    server.pass.key\\n    \\n    $ openssl rsa -passin pass:x -in server.pass.key -out server.key\\n    writing RSA key\\n    \\n    $ ls\\n    server.key      server.pass.key\\n    \\n    $ rm server.pass.key\\n    \\n    $ openssl req -new -key server.key -out server.csr\\n    You are about to be asked to enter information that will be incorporated\\n    into your certificate request.\\n    What you are about to enter is what is called a Distinguished Name or a DN.\\n    There are quite a few fields but you can leave some blank\\n    For some fields there will be a default value,\\n    If you enter \'.\', the field will be left blank.\\n    -----\\n    Country Name (2 letter code) []:RU\\n    State or Province Name (full name) []:\\n    Locality Name (eg, city) []:\\n    Organization Name (eg, company) []:\\n    Organizational Unit Name (eg, section) []:\\n    Common Name (eg, fully qualified host name) []:localhost\\n    Email Address []:\\n    \\n    Please enter the following \'extra\' attributes\\n    to be sent with your certificate request\\n    A challenge password []:\\n    \\n    $ openssl x509 -req -sha256 -days 365 -in server.csr -signkey server.key -out server.crt\\n    Signature ok\\n    subject=/C=RU/CN=localhost\\n    Getting Private key\\n    \\n    $ ls\\n    server.crt server.csr server.key\\n    ``` \\n\\n## Run client example\\n\\nNow the last step. What we need to do is run Chrome Canary with some flags that will allow it to trust our self-signed certificates. I suppose there is an alternative way making Chrome trust your certificates, but I have not tried it.\\n\\nFirst let\'s find out a fingerprint of our cert:\\n\\n```bash\\nopenssl x509 -in server.crt -pubkey -noout | openssl pkey -pubin -outform der | openssl dgst -sha256 -binary | openssl enc -base64\\n```\\n\\nIn my case base64 fingerprint was `pe2P0fQwecKFMc6kz3+Y5MuVwVwEtGXyST5vJeaOO/M=`, yours will be different.\\n\\nThen run Chrome Canary with some additional flags that will make it trust out certs (close other Chrome Canary instances before running it):\\n\\n```bash\\n$ /Applications/Google\\\\ Chrome\\\\ Canary.app/Contents/MacOS/Google\\\\ Chrome\\\\ Canary \\\\\\n    --origin-to-force-quic-on=localhost:4433 \\\\\\n    --ignore-certificate-errors-spki-list=pe2P0fQwecKFMc6kz3+Y5MuVwVwEtGXyST5vJeaOO/M=\\n```\\n\\nThis example is for MacOS, for your system see [docs on how to run Chrome/Chromium with custom flags](https://www.chromium.org/developers/how-tos/run-chromium-with-flags).\\n\\nNow you can open https://googlechrome.github.io/samples/quictransport/client.html URL in started browser and click `Connect` button. What? Connection not established? OK, this is fine since we need to run our server :)\\n\\n## Writing a QUIC server\\n\\nMaybe in future we will have libraries that are specified to work with WebTransport over QUIC or HTTP/3, but for now we should implement server manually. As said above we will use [github.com/lucas-clemente/quic-go](https://github.com/lucas-clemente/quic-go) library to do this.\\n\\n### Server skeleton\\n\\nFirst, let\'s define a simple skeleton for our server:\\n\\n```go\\npackage main\\n\\nimport (\\n\\t\\"errors\\"\\n\\t\\"log\\"\\n\\n    \\"github.com/lucas-clemente/quic-go\\"\\n)\\n\\n// Config for WebTransportServerQuic.\\ntype Config struct {\\n\\t// ListenAddr sets an address to bind server to.\\n\\tListenAddr string\\n\\t// TLSCertPath defines a path to .crt cert file.\\n\\tTLSCertPath string\\n\\t// TLSKeyPath defines a path to .key cert file\\n\\tTLSKeyPath string\\n\\t// AllowedOrigins represents list of allowed origins to connect from.\\n\\tAllowedOrigins []string\\n}\\n\\n// WebTransportServerQuic can handle WebTransport QUIC connections according\\n// to https://tools.ietf.org/html/draft-vvv-webtransport-quic-02.\\ntype WebTransportServerQuic struct {\\n\\tconfig Config\\n}\\n\\n// NewWebTransportServerQuic creates new WebTransportServerQuic.\\nfunc NewWebTransportServerQuic(config Config) *WebTransportServerQuic {\\n\\treturn &WebTransportServerQuic{\\n\\t\\tconfig: config,\\n\\t}\\n}\\n\\n// Run server.\\nfunc (s *WebTransportServerQuic) Run() error {\\n\\treturn errors.New(\\"not implemented\\")\\n}\\n\\nfunc main() {\\n\\tserver := NewWebTransportServerQuic(Config{\\n\\t\\tListenAddr:     \\"0.0.0.0:4433\\",\\n\\t\\tTLSCertPath:    \\"server.crt\\",\\n\\t\\tTLSKeyPath:     \\"server.key\\",\\n\\t\\tAllowedOrigins: []string{\\"localhost\\", \\"googlechrome.github.io\\"},\\n\\t})\\n\\tif err := server.Run(); err != nil {\\n\\t\\tlog.Fatal(err)\\n\\t}\\n}\\n```\\n\\n### Accept QUIC connections\\n\\nLet\'s concentrate on implementing `Run` method. We need to accept QUIC client connections. This can be done by creating `quic.Listener` instance and using its `.Accept` method to accept incoming client sessions.\\n\\n```go\\n// Run server.\\nfunc (s *WebTransportServerQuic) Run() error {\\n\\tlistener, err := quic.ListenAddr(s.config.ListenAddr, s.generateTLSConfig(), nil)\\n\\tif err != nil {\\n\\t\\treturn err\\n\\t}\\n\\tfor {\\n\\t\\tsess, err := listener.Accept(context.Background())\\n\\t\\tif err != nil {\\n\\t\\t\\treturn err\\n\\t\\t}\\n\\t\\tlog.Printf(\\"session accepted: %s\\", sess.RemoteAddr().String())\\n\\t\\tgo func() {\\n\\t\\t\\tdefer func() {\\n\\t\\t\\t\\t_ = sess.CloseWithError(0, \\"bye\\")\\n\\t\\t\\t\\tlog.Println(\\"close session\\")\\n\\t\\t\\t}()\\n\\t\\t\\ts.handleSession(sess)\\n\\t\\t}()\\n\\t}\\n}\\n\\nfunc (s *WebTransportServerQuic) handleSession(sess quic.Session) {\\n    // Not implemented yet.    \\n}\\n```\\n\\nAn interesting thing to note is that QUIC allows closing connection with specific application-level integer code and custom string reason. Just like WebSocket if you worked with it.\\n\\nAlso note, that we are starting our `Listener` with TLS configuration returned by `s.generateTLSConfig()` method. Let\'s take a closer look at how this method can be implemented.\\n\\n```go\\n// https://tools.ietf.org/html/draft-vvv-webtransport-quic-02#section-3.1\\nconst alpnQuicTransport = \\"wq-vvv-01\\"\\n\\nfunc (s *WebTransportServerQuic) generateTLSConfig() *tls.Config {\\n\\tcert, err := tls.LoadX509KeyPair(s.config.TLSCertPath, s.config.TLSKeyPath)\\n\\tif err != nil {\\n\\t\\tlog.Fatal(err)\\n\\t}\\n\\treturn &tls.Config{\\n\\t\\tCertificates: []tls.Certificate{cert},\\n\\t\\tNextProtos:   []string{alpnQuicTransport},\\n\\t}\\n}\\n```\\n\\nInside `generateTLSConfig` we load x509 certs from cert files generated above. WebTransport uses ALPN ([Application-Layer Protocol Negotiation](https://en.wikipedia.org/wiki/Application-Layer_Protocol_Negotiation) to prevent handshakes with a server that does not support WebTransport spec. This is just a string `wq-vvv-01` inside `NextProtos` slice of our `*tls.Config`.\\n\\n### Connection Session handling\\n\\nAt this moment if you run a server and open a client example in Chrome then click `Connect` button \u2013 you should see that connection successfully established in event log area:\\n\\n![client example](https://i.imgur.com/PyEr9W9.png)\\n\\nNow if you try to send data to a server nothing will happen. That\'s because we have not implemented reading data from session streams. \\n\\nStreams in QUIC provide a lightweight, ordered byte-stream abstraction to an application. Streams can be unidirectional or bidirectional.\\n\\nStreams can be short-lived, streams can also be long-lived and can last the entire duration of a connection.\\n\\nClient example provides three possible ways to communicate with a server:\\n\\n* Send a datagram\\n* Open a unidirectional stream\\n* Open a bidirectional stream\\n\\nUnfortunately, `quic-go` library does not support sending UDP datagrams at this moment. To do this `quic-go` should implement one more draft called [An Unreliable Datagram Extension to QUIC](https://tools.ietf.org/html/draft-pauly-quic-datagram-05). There is already [an ongoing pull request](https://github.com/lucas-clemente/quic-go/pull/2162) that implements it. This means that it\'s too early for us to experiment with unreliable UDP WebTransport client-server communication in Go. By the way, the interesting facts about UDP over QUIC are that QUIC congestion control mechanism will [still apply](https://tools.ietf.org/html/draft-ietf-quic-datagram-00#section-5.3) and QUIC datagrams [can support acknowledgements](https://tools.ietf.org/html/draft-ietf-quic-datagram-00#section-5.1).\\n\\nImplementing a unidirectional stream is possible with `quic-go` since the library supports creating and accepting unidirectional streams, but I\'ll leave this for a reader (though we will need accepting one unidirectional stream for parsing client indication anyway \u2013 see below).\\n\\nHere we will only concentrate on implementing a server for a bidirectional case. We are in the Centrifugo blog, and this is the most interesting type of stream for me personally.\\n\\n### Parsing client indication\\n\\nAccording to [section-3.2](https://tools.ietf.org/html/draft-vvv-webtransport-quic-02#section-3.2) of Quic WebTransport spec in order to verify that the client\'s origin allowed connecting to the server, the user agent has to communicate the origin to the server. This is accomplished by sending a special message, called client indication, on stream 2, which is the first client-initiated unidirectional stream.\\n\\nHere we will implement this. In the beginning of our session handler we will accept a unidirectional stream initiated by a client.\\n\\nAt moment spec defines two client indication keys: `Origin` and `Path`. In our case an origin value will be `https://googlechrome.github.io` and path will be `/counter`.\\n\\nLet\'s define some constants and structures:\\n\\n```go\\n// client indication stream can not exceed 65535 bytes in length.\\n// https://tools.ietf.org/html/draft-vvv-webtransport-quic-02#section-3.2\\nconst maxClientIndicationLength = 65535\\n\\n// define known client indication keys.\\ntype clientIndicationKey int16\\n\\nconst (\\n\\tclientIndicationKeyOrigin clientIndicationKey = 0\\n\\tclientIndicationKeyPath                       = 1\\n)\\n\\n// ClientIndication container.\\ntype ClientIndication struct {\\n\\t// Origin client indication value.\\n\\tOrigin string\\n\\t// Path client indication value.\\n\\tPath string\\n}\\n```\\n\\nNow what we should do is accept unidirectional stream inside session handler:\\n\\n```go\\nfunc (s *WebTransportServerQuic) handleSession(sess quic.Session) {\\n    stream, err := sess.AcceptUniStream(context.Background())\\n    if err != nil {\\n        log.Println(err)\\n        return\\n    }\\n    log.Printf(\\"uni stream accepted, id: %d\\", stream.StreamID())\\n\\n    indication, err := receiveClientIndication(stream)\\n    if err != nil {\\n        log.Println(err)\\n        return\\n    }\\n    log.Printf(\\"client indication: %+v\\", indication)\\n\\n    if err := s.validateClientIndication(indication); err != nil {\\n        log.Println(err)\\n        return\\n    }\\n\\n    // this method blocks.\\n    if err := s.communicate(sess); err != nil {\\n        log.Println(err)\\n    }\\n}\\n\\nfunc receiveClientIndication(stream quic.ReceiveStream) (ClientIndication, error) {\\n    return ClientIndication{}, errors.New(\\"not implemented yet\\")\\n}\\n\\nfunc (s *WebTransportServerQuic) validateClientIndication(indication ClientIndication) error {\\n\\treturn errors.New(\\"not implemented yet\\")\\n}\\n\\nfunc (s *WebTransportServerQuic) communicate(sess quic.Session) error {\\n    return errors.New(\\"not implemented yet\\")\\n}\\n```\\n\\nAs you can see to accept a unidirectional stream with data we can use `.AcceptUniStream` method of `quic.Session`. After accepting a stream we should read client indication data from it. \\n\\nAccording to spec it will contain a client indication in the following format:\\n\\n```\\n0                   1                   2                   3\\n0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\\n|           Key (16)            |          Length (16)          |\\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\\n|                           Value (*)                         ...\\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\\n```\\n\\nThe code below parses client indication out of a stream data, we decode key-value pairs from uni stream until an end of stream (indicated by EOF):\\n\\n```go\\nfunc receiveClientIndication(stream quic.ReceiveStream) (ClientIndication, error) {\\n\\tvar clientIndication ClientIndication\\n\\n    // read no more than maxClientIndicationLength bytes.\\n\\treader := io.LimitReader(stream, maxClientIndicationLength)\\n\\n\\tdone := false\\n\\n\\tfor {\\n\\t\\tif done {\\n\\t\\t\\tbreak\\n\\t\\t}\\n\\t\\tvar key int16\\n\\t\\terr := binary.Read(reader, binary.BigEndian, &key)\\n\\t\\tif err != nil {\\n\\t\\t\\tif err == io.EOF {\\n\\t\\t\\t\\tdone = true\\n\\t\\t\\t} else {\\n\\t\\t\\t\\treturn clientIndication, err\\n\\t\\t\\t}\\n\\t\\t}\\n\\t\\tvar valueLength int16\\n\\t\\terr = binary.Read(reader, binary.BigEndian, &valueLength)\\n\\t\\tif err != nil {\\n\\t\\t\\treturn clientIndication, err\\n\\t\\t}\\n\\t\\tbuf := make([]byte, valueLength)\\n\\t\\tn, err := reader.Read(buf)\\n\\t\\tif err != nil {\\n\\t\\t\\tif err == io.EOF {\\n                // still need to process indication value.\\n\\t\\t\\t\\tdone = true\\n\\t\\t\\t} else {\\n\\t\\t\\t\\treturn clientIndication, err\\n\\t\\t\\t}\\n\\t\\t}\\n\\t\\tif int16(n) != valueLength {\\n\\t\\t\\treturn clientIndication, errors.New(\\"read less than expected\\")\\n\\t\\t}\\n\\t\\tvalue := string(buf)\\n\\n\\t\\tswitch clientIndicationKey(key) {\\n\\t\\tcase clientIndicationKeyOrigin:\\n\\t\\t\\tclientIndication.Origin = value\\n\\t\\tcase clientIndicationKeyPath:\\n\\t\\t\\tclientIndication.Path = value\\n\\t\\tdefault:\\n\\t\\t\\tlog.Printf(\\"skip unknown client indication key: %d: %s\\", key, value)\\n\\t\\t}\\n\\t}\\n\\treturn clientIndication, nil\\n}\\n```\\n\\nWe also validate Origin inside `validateClientIndication` method of our server:\\n\\n```go\\nvar errBadOrigin = errors.New(\\"bad origin\\")\\n\\nfunc (s *WebTransportServerQuic) validateClientIndication(indication ClientIndication) error {\\n\\tu, err := url.Parse(indication.Origin)\\n\\tif err != nil {\\n\\t\\treturn errBadOrigin\\n\\t}\\n\\tif !stringInSlice(u.Host, s.config.AllowedOrigins) {\\n\\t\\treturn errBadOrigin\\n\\t}\\n\\treturn nil\\n}\\n\\nfunc stringInSlice(a string, list []string) bool {\\n\\tfor _, b := range list {\\n\\t\\tif b == a {\\n\\t\\t\\treturn true\\n\\t\\t}\\n\\t}\\n\\treturn false\\n}\\n```\\n\\nDo you have `stringInSlice` function in every Go project? I do :)\\n\\n### Communicating over bidirectional streams\\n\\nThe final part here is accepting a bidirectional stream from a client, reading it, and sending responses back. Here we will just echo everything a client sends to a server back to a client. You can implement whatever bidirectional communication you want actually.\\n\\nVery similar to unidirectional case we can call `.AcceptStream` method of session to accept a bidirectional stream.\\n\\n```go\\nfunc (s *WebTransportServerQuic) communicate(sess quic.Session) error {\\n\\tfor {\\n\\t\\tstream, err := sess.AcceptStream(context.Background())\\n\\t\\tif err != nil {\\n\\t\\t\\treturn err\\n\\t\\t}\\n\\t\\tlog.Printf(\\"stream accepted: %d\\", stream.StreamID())\\n\\t\\tif _, err := io.Copy(stream, stream); err != nil {\\n\\t\\t\\treturn err\\n\\t\\t}\\n\\t}\\n}\\n```\\n\\nWhen you press `Send` button in client example it creates a bidirectional stream, sends data to it, then closes stream. Thus our code is sufficient. For a more complex communication that involves many concurrent streams you will have to write a more complex code that allows working with streams concurrently on server side.\\n\\n![client example](https://i.imgur.com/5299Vr4.png)\\n\\n### Full server example\\n\\nFull server code can be found [in a Gist](https://gist.github.com/FZambia/07dca3a7a75a264746101cd5657f1150). Again \u2013 this is a toy example based on things that all work in progress.\\n\\n## Conclusion\\n\\nWebTransport is an interesting technology that can open new possibilities in modern Web development. At this moment it\'s possible to play with it using QUIC transport \u2013 here we looked at how one can do that. Though we still have to wait a bit until all these things will be suitable for production usage.\\n\\nAlso, even when ready we will still have to think about WebTransport fallback options \u2013 since wide adoption of browsers that support some new technology and infrastructure takes time. Actually WebTransport spec authors consider fallback options in design. This was mentioned in IETF slides ([PDF, 2.6MB](https://www.ietf.org/proceedings/106/slides/slides-106-webtrans-webtrans-bof-slides-03)), but I have not found any additional information beyond that.\\n\\nPersonally, I think the most exciting thing about WebTransport is the possibility to exchange UDP datagrams, which can help a lot to in-browser gaming. Unfortunately, we can\'t test it at this moment with Go (but it\'s already possible using Python as server as shown [in the example](https://github.com/GoogleChrome/samples/blob/gh-pages/quictransport/quic_transport_server.py)).\\n\\nWebTransport could be a nice candidate for a new Centrifugo transport next to WebSocket and SockJS \u2013 time will show."},{"id":"/2020/02/10/million-connections-with-centrifugo","metadata":{"permalink":"/blog/2020/02/10/million-connections-with-centrifugo","editUrl":"https://github.com/centrifugal/centrifugal.dev/edit/main/blog/2020-02-10-million-connections-with-centrifugo.md","source":"@site/blog/2020-02-10-million-connections-with-centrifugo.md","title":"Million connections with Centrifugo","description":"Million WebSocket connections with Centrifugo","date":"2020-02-10T00:00:00.000Z","formattedDate":"February 10, 2020","tags":[{"label":"centrifuge","permalink":"/blog/tags/centrifuge"},{"label":"go","permalink":"/blog/tags/go"}],"readingTime":3.03,"hasTruncateMarker":true,"authors":[{"name":"Centrifugal team","title":"Let the Centrifugal force be with you","imageURL":"/img/logo_animated.svg"}],"frontMatter":{"title":"Million connections with Centrifugo","tags":["centrifuge","go"],"description":"Million WebSocket connections with Centrifugo","author":"Centrifugal team","authorTitle":"Let the Centrifugal force be with you","authorImageURL":"/img/logo_animated.svg","hide_table_of_contents":false},"prevItem":{"title":"Experimenting with QUIC and WebTransport","permalink":"/blog/2020/10/16/experimenting-with-quic-transport"}},"content":"In order to get an understanding about possible hardware requirements for reasonably massive Centrifugo setup we made a test stand inside Kubernetes.\\n\\nOur goal was to run server based on Centrifuge library (the core of Centrifugo server) with one million WebSocket connections and send many messages to connected clients. While sending many messages we have been looking at delivery time latency. In fact we will see that about 30 million messages per minute (500k messages per second) will be delivered to connected clients and latency won\'t be larger than 200ms in 99 percentile.\\n\\n\x3c!--truncate--\x3e\\n\\nServer nodes have been run on machines with the following configuration:\\n\\n* CPU Intel(R) Xeon(R) CPU E5-2640 v4 @ 2.40GHz\\n* Linux Debian 4.9.65-3+deb9u1 (2017-12-23) x86_64 GNU/Linux \\n\\nSome `sysctl` values:\\n\\n```\\nfs.file-max = 3276750\\nfs.nr_open = 1048576\\nnet.ipv4.tcp_mem = 3086496\\t4115330\\t6172992\\nnet.ipv4.tcp_rmem = 8192\\t8388608\\t16777216\\nnet.ipv4.tcp_wmem = 4096\\t4194394\\t16777216\\nnet.core.rmem_max = 33554432\\nnet.core.wmem_max = 33554432\\n```\\n\\nKubernetes used these machines as its nodes. \\n\\nWe started 20 Centrifuge-based server pods. Our clients connected to server pods using Centrifuge Protobuf protocol. To scale horizontally we used Redis Engine and sharded it to 5 different Redis instances (each Redis instance consumes 1 CPU max).\\n\\nTo achieve many client connections we used 100 Kubernetes pods each generating about 10k client connections to server.\\n\\nHere are some numbers we achieved:\\n\\n* 1 million WebSocket connections\\n* Each connection subscribed to 2 channels: one personal channel and one group channel (with 10 subscribers in it), i.e. we had about 1.1 million active channels at each moment.\\n* 28 million messages per minute (about 500k per second) **delivered** to clients\\n* 200k per minute constant connect/disconnect rate to simulate real-life situation where clients connect/disconnect from server\\n* 200ms delivery latency in 99 percentile\\n* The size of each published message was about 100 bytes\\n\\nAnd here are some numbers about final resource usage on server side (we don\'t actually interested in client side resource usage here):\\n\\n* 40 CPU total for server nodes when load achieved values claimed above (20 pods, ~2 CPU each)\\n* 27 GB of RAM used mostly to handle 1 mln WebSocket connections, i.e. about 30kb RAM per connection\\n* 0.32 CPU usage on every Redis instance\\n* 100 mbit/sec rx \u0438 150 mbit/sec tx of network used on each server pod\\n\\nThe picture that demonstrates experiment (better to open image in new tab):\\n\\n![Benchmark](/img/benchmark.gif)\\n\\nThis also demonstrates that to handle one million of WebSocket connections without many messages sent to clients you need about 10 CPU total for server nodes and about 5% of CPU on each of Redis instances. In this case CPU mostly spent on connect/disconnect flow, ping/pong frames, subscriptions to channels.\\n\\nIf we enable history and history message recovery features we see an increased Redis CPU usage: 64% instead of 32% on the same workload. Other resources usage is pretty the same.\\n\\nThe results mean that one can theoretically achieve the comparable numbers on single modern server machine. But numbers can vary a lot in case of different load scenarios. In this benchmark we looked at basic use case where we only connect many clients and send Publications to them. There are many features in Centrifuge library and in Centrifugo not covered by this artificial experiment. Also note that though benchmark was made for Centrifuge library for Centrifugo you can expect similar results.\\n\\nRead and write buffer sizes of websocket connections were set to 512 kb on server side (sizes of buffers affect memory usage), with Centrifugo this means that to reproduce the same configuration you need to set:\\n\\n```json\\n{\\n    ...\\n    \\"websocket_read_buffer_size\\": 512,\\n    \\"websocket_write_buffer_size\\": 512\\n}\\n```"}]}')}}]);