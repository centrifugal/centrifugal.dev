"use strict";(self.webpackChunkcentrifugal_dev=self.webpackChunkcentrifugal_dev||[]).push([[9869],{19909:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>l,default:()=>d,frontMatter:()=>o,metadata:()=>i,toc:()=>r});const i=JSON.parse('{"id":"pro/client_message_batching","title":"Message batching control","description":"Centrifugo PRO provides advanced options to tweak connection message write behaviour.","source":"@site/docs/pro/client_msg_batching.md","sourceDirName":"pro","slug":"/pro/client_message_batching","permalink":"/docs/pro/client_message_batching","draft":false,"unlisted":false,"editUrl":"https://github.com/centrifugal/centrifugal.dev/edit/main/docs/pro/client_msg_batching.md","tags":[],"version":"current","frontMatter":{"id":"client_message_batching","sidebar_label":"Message batching control","title":"Message batching control"},"sidebar":"Pro","previous":{"title":"Scalability optimizations","permalink":"/docs/pro/scalability"},"next":{"title":"Observability enhancements","permalink":"/docs/pro/observability_enhancements"}}');var s=t(74848),a=t(28453);const o={id:"client_message_batching",sidebar_label:"Message batching control",title:"Message batching control"},l=void 0,c={},r=[{value:"Client level controls",id:"client-level-controls",level:2},{value:"<code>client.write_delay</code>",id:"clientwrite_delay",level:3},{value:"<code>client.max_messages_in_frame</code>",id:"clientmax_messages_in_frame",level:3},{value:"<code>client.reply_without_queue</code>",id:"clientreply_without_queue",level:3},{value:"Channel level controls",id:"channel-level-controls",level:2},{value:"<code>batch_max_size</code> and <code>batch_max_delay</code>",id:"batch_max_size-and-batch_max_delay",level:3},{value:"<code>batch_flush_latest</code>",id:"batch_flush_latest",level:3}];function h(e){const n={a:"a",admonition:"admonition",code:"code",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.p,{children:"Centrifugo PRO provides advanced options to tweak connection message write behaviour."}),"\n",(0,s.jsx)(n.p,{children:"By default, Centrifugo tries to write messages to clients as fast as possible. Centrifugo also does best effort combining different protocol messages into one transport frame (to reduce system calls and thus reduce CPU usage) without sacrificing delivery latency."}),"\n",(0,s.jsx)(n.p,{children:"But still in this model if you have a lot of messages sent to each individual connection, you may have a lot of write system calls. These system calls have an huge impact on the server CPU utilization. Sometimes you want to trade-off delivery latency in favour of lower CPU consumption by Centrifugo node. It's possible to do by telling Centrifugo to slow down message delivery and collect messages to larger batches before sending them towards individual client. To achieve that Centrifugo PRO exposes additional configuration options."}),"\n",(0,s.jsx)(n.p,{children:"We have customer reports showing that enabling options described here reduced total CPU usage of Centrifugo cluster by half. This may be a significant cost reduction at scale."}),"\n",(0,s.jsx)(n.admonition,{type:"tip",children:(0,s.jsx)(n.p,{children:"Note, this is only useful when you have lots of messages per client. This specific feature won't be helpful with a case when the message is broadcasted towards many different connections as the feature described here only batches message writing it terms of a single socket."})}),"\n",(0,s.jsx)(n.h2,{id:"client-level-controls",children:"Client level controls"}),"\n",(0,s.jsx)(n.h3,{id:"clientwrite_delay",children:(0,s.jsx)(n.code,{children:"client.write_delay"})}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"client.write_delay"})," is a duration option, it is a time Centrifugo will try to collect messages inside each connection message write loop before sending them towards the connection."]}),"\n",(0,s.jsxs)(n.p,{children:["Enabling ",(0,s.jsx)(n.code,{children:"client.write_delay"})," may reduce CPU usage of both server and client in case of high message rate inside individual connections. The reduction happens due to the lesser number of system calls to execute. Enabling ",(0,s.jsx)(n.code,{children:"client.write_delay"})," limits the maximum throughput of messages towards the connection which may be achieved. For example, if ",(0,s.jsx)(n.code,{children:"client.write_delay"})," is 100ms then the max throughput per second will be ",(0,s.jsx)(n.code,{children:"(1000 / 100) * client.max_messages_in_frame"})," (16 by default), i.e. 160 messages per second. Though this should be more than enough for target Centrifugo use cases (frontend apps)."]}),"\n",(0,s.jsx)(n.p,{children:"Example:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-json",metastring:'title="config.json"',children:'{\n  "client": {\n    "write_delay": "100ms"\n  }\n}\n'})}),"\n",(0,s.jsx)(n.h3,{id:"clientmax_messages_in_frame",children:(0,s.jsx)(n.code,{children:"client.max_messages_in_frame"})}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"client.max_messages_in_frame"})," is an integer option which controls the maximum number of messages which may be joined by Centrifugo into one transport frame. By default, 16. Use -1 for unlimited number."]}),"\n",(0,s.jsx)(n.p,{children:"Example:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-json",metastring:'title="config.json"',children:'{\n  "client": {\n    "write_delay": "100ms",\n    "max_messages_in_frame": -1\n  }\n}\n'})}),"\n",(0,s.jsx)(n.h3,{id:"clientreply_without_queue",children:(0,s.jsx)(n.code,{children:"client.reply_without_queue"})}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"client.reply_without_queue"})," is a boolean option to not use client queue for replies to commands. When ",(0,s.jsx)(n.code,{children:"true"})," replies are written to the transport without going through the connection message queue."]}),"\n",(0,s.jsx)(n.h2,{id:"channel-level-controls",children:"Channel level controls"}),"\n",(0,s.jsxs)(n.h3,{id:"batch_max_size-and-batch_max_delay",children:[(0,s.jsx)(n.code,{children:"batch_max_size"})," and ",(0,s.jsx)(n.code,{children:"batch_max_delay"})]}),"\n",(0,s.jsx)(n.p,{children:"Centrifugo PRO provides a couple of additional channel namespace options to control message batching on the channel level."}),"\n",(0,s.jsx)(n.p,{children:"This may be useful if you want to reduce number of system calls (thus improve CPU) using latency trade-off for specific channels only."}),"\n",(0,s.jsxs)(n.p,{children:["Two available options are ",(0,s.jsx)(n.a,{href:"/docs/server/channels#batch_max_size",children:"batch_max_size"})," and ",(0,s.jsx)(n.a,{href:"/docs/server/channels#batch_max_delay",children:"batch_max_delay"}),"."]}),"\n",(0,s.jsx)(n.p,{children:"Here is an example how you can configure these options for a channel namespace:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-json",metastring:'title="config.json"',children:'{\n  "channel": {\n    "without_namespace": {\n      "batch_max_size": 10,\n      "batch_max_delay": "200ms"\n    }\n  }\n}\n'})}),"\n",(0,s.jsx)(n.p,{children:"Or for some namespace:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-json",metastring:'title="config.json"',children:'{\n  "channel": {\n    "namespaces": [\n      {\n        "name": "example",\n        "batch_max_size": 10,\n        "batch_max_delay": "200ms"\n      }\n    ]\n  }\n}\n'})}),"\n",(0,s.jsx)(n.p,{children:"These options can be set independently:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["if only ",(0,s.jsx)(n.code,{children:"batch_max_delay"})," is set \u2013 then there is no max size limit for batching algorithm, it will always flush upon reaching ",(0,s.jsx)(n.code,{children:"batch_max_delay"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:["if only ",(0,s.jsx)(n.code,{children:"batch_max_size"})," is set \u2013 then there is no max delay limit for batching algorithm, it will flush only upon reaching ",(0,s.jsx)(n.code,{children:"batch_max_size"}),". Can make sense in channels with stable high rate of messages."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Note, that channel batching is applied for each individual channel in namespace separately. Batching may introduce memory overhead, which depends on the load profile in your setup. If batching is not effective (for example due to low rate in channels) \u2013 then it can also come with CPU overhead."}),"\n",(0,s.jsx)(n.h3,{id:"batch_flush_latest",children:(0,s.jsx)(n.code,{children:"batch_flush_latest"})}),"\n",(0,s.jsxs)(n.p,{children:["One more option related to per-channel batching algorithm is ",(0,s.jsx)(n.code,{children:"batch_flush_latest"})," (boolean, default ",(0,s.jsx)(n.code,{children:"false"}),"). Once you enable it then Centrifugo only sends the latest message in the collected batch to the client connection. This is useful for channels where each message contains the entire state, so skipping intermediary messages is beneficial to reduce CPU utilization, bandwidth and the processing work required on the client side."]}),"\n",(0,s.jsx)(n.p,{children:"Example of configuration:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-json",metastring:'title="config.json"',children:'{\n  "channel": {\n    "namespaces": [\n      {\n        "name": "example",\n        "batch_max_size": 10,\n        "batch_max_delay": "200ms",\n        "batch_flush_latest": true\n      }\n    ]\n  }\n}\n'})})]})}function d(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(h,{...e})}):h(e)}},28453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>l});var i=t(96540);const s={},a=i.createContext(s);function o(e){const n=i.useContext(a);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),i.createElement(a.Provider,{value:n},e.children)}}}]);